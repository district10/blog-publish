<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta http-equiv="Content-Style-Type" content="text/css" />
    <meta name="author" content="district10" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title></title>
    <link rel="stylesheet" href="../github-markdown.css" type="text/css" />
    <link rel="stylesheet" href="../highlight.css" type="text/css" />
    <link rel="stylesheet" href="../notes.css" type="text/css" />
<!--<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>-->
    <script src="https://cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body class="markdown-body">
<a href="https://github.com/district10/notes">
    <img
        style="position: absolute; top: 0; right: 0; border: 0; width: 149px; height: 149px;"
        src="../fork-me-on-github.png" alt="Fork me on GitHub"></a>
<div id="navigator">
    <a id="gotoindex" href="index.html" title="&#12304;&#22238;&#21040;&#31508;&#35760;&#32034;&#24341; | Back to Index&#12305;">&#9763;</a></div>
<span id="help">&#25353;&#19979; "h" &#33719;&#21462;&#39029;&#38754;&#24110;&#21161;&#12290;</span>
<div id="main-body">
<h1 id="probabilies-statistics">Probabilies &amp; Statistics</h1>
<dl>
<dt>TODO: <code class="fold">@</code></dt>
<dd><ul>
<li>&#12298;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#12299;</li>
<li><a href="https://en.wikipedia.org/wiki/Kd-tree">k-d tree - Wikipedia, the free encyclopedia</a></li>
<li>cart: classification and regression tree;, gini index</li>
</ul>
</dd>
<dt>MISC Notes <code class="fold">@</code></dt>
<dd><ul>
<li><p>&#19968;&#20010;&#20998;&#24067;&#26377; mean&#65292;&#19968;&#20010;&#38543;&#26426;&#21464;&#37327;&#26377; ev&#12290;&#22914;&#26524;&#36825;&#20010;&#38543;&#26426;&#21464;&#37327; rv &#20998;&#24067;&#20026; x&#65292;&#21017; rv &#30340; ev &#23601;&#26159; x &#30340; mean&#12290;</p></li>
<li><p>&#35828; chi-squared &#21644; chi-square&#65292;&#37117;&#21487;&#20197;, &#32500;&#22522;&#19978;&#26159; chi-squared&#65292;&#29992;&#36825;&#20010;&#27604;&#36739;&#22909;&#12290;</p></li>
<li><p>&#20840;&#27010;&#29575;&#65306;&#21407;&#22240; -&gt; &#32467;&#26524;</p></li>
<li><p>&#36125;&#21494;&#26031;&#65306;&#32467;&#26524; -&gt; &#21407;&#22240;</p></li>
<li><p>P(A|B) &gt; P(A), P(A|B) = P(A), P(A|B) &lt; P(A)</p></li>
<li><p>&#30456;&#20851;&#65288;&#32447;&#24615;&#30456;&#20851;&#65289;</p></li>
<li><p>binomial, <code>[ba&#618;'nom&#618;&#601;l]</code></p></li>
<li><p>bernoulli, <code>[b&#601;:'nu:li]</code></p></li>
<li><p>poisson, <code>/&#712;pw&#593;&#720;s&#594;n/</code></p></li>
<li><p>deviation, <code>['div&#618;'e&#643;&#601;n]</code></p></li>
<li><p>cumulative, <code>['kjumj&#601;let&#618;v]</code></p></li>
<li><p>&#22343;&#26041;&#35823;&#24046;&#65288;mean square error&#65289;</p></li>
<li><p>homoscedasticity, homo-sce-das-ti-city, &#26041;&#24046;&#40784;&#24615;, <code>['h&#596;m&#601;usi,d&#230;s'tis&#601;ti]</code></p></li>
<li><p>fiducial, <code>[f&#618;'dju&#720;&#643;(&#601;)l]</code></p></li>
<li><p>bayesian, <code>['be&#658;&#601;n]</code></p></li>
<li><p>conjugate, <code>['k&#593;nd&#658;&#601;&#609;et]</code>, &#20849;&#36717;&#30340;</p>
<p>&#25104;&#23545;&#30340;&#65307;&#32467;&#21512;&#30340;&#65307;&#12304;&#21270;, &#25968;, &#29289;&#12305;&#20849;&#36717;&#30340;&#65307;&#12304;&#35821;&#12305;&#21516;&#28304; [&#26681;] &#30340; v.&#65288;&#26681;&#25454;&#25968;&#12289;&#20154;&#31216;&#12289;&#26102;&#24577;&#31561;&#65289;&#21015;&#20030;&#65288;&#21160;&#35789;&#65289;&#30340;&#21464;&#21270;&#24418;&#24335;</p></li>
<li><dl>
<dt>&#19968;&#20123;&#34507;&#30140;&#30340;&#21517;&#35789; <code class="fold">@</code></dt>
<dd><p>An <strong>independent variable</strong> is also known as a &#8220;predictor variable&#8221;, &#8220;regressor&#8221;, &#8220;controlled variable&#8221;, &#8220;manipulated variable&#8221;, &#8220;explanatory variable&#8221;, &#8220;exposure variable&#8221; (see reliability theory), &#8220;risk factor&#8221; (see medical statistics), &#8220;feature&#8221; (in machine learning and pattern recognition) or an &#8220;input variable.&#8221;</p>
<p>A <strong>dependent variable</strong> is also known as a &#8220;response variable&#8221;, &#8220;regressand&#8221;, &#8220;predicted variable&#8221;, &#8220;measured variable&#8221;, &#8220;explained variable&#8221;, &#8220;experimental variable&#8221;, &#8220;responding variable&#8221;, &#8220;outcome variable&#8221;, and &#8220;output variable&#8221;.</p>
<p>&#8220;<strong>Explanatory variable</strong>&#8221; is preferred by some authors over &#8220;independent variable&#8221; when the quantities treated as &#8220;independent variables&#8221; may not be statistically independent. If the independent variable is referred to as an &#8220;explanatory variable&#8221; then the term &#8220;response variable&#8221; is preferred by some authors for the dependent variable.</p>
<p>&#8220;<strong>Explained variable</strong>&#8221; is preferred by some authors over &#8220;dependent variable&#8221; when the quantities treated as &#8220;dependent variables&#8221; may not be statistically dependent. If the dependent variable is referred to as an &#8220;explained variable&#8221; then the term &#8220;predictor variable&#8221; is preferred by some authors for the independent variable.</p>
<p>Variables may also be referred to by their form:</p>
<ul>
<li>continuous,</li>
<li>binary/dichotomous,</li>
<li>nominal categorical, and</li>
<li>ordinal categorical, among others.</li>
</ul>
<p>A variable may be thought to alter the dependent or independent variables, but may not actually be the focus of the experiment. So that variable will be kept constant or monitored to try to minimise its effect on the experiment. Such variables may be designated (&#25351;&#23450;) as either a &#8220;controlled variable&#8221;, &#8220;control variable&#8221;, or &#8220;extraneous variable&#8221;.</p>
<p>Extraneous variables, if included in a regression as independent variables, may aid a researcher with accurate response parameter estimation, prediction, and <strong>goodness of fit</strong>, but are not of substantive interest to the hypothesis under examination. For example, in a study examining the effect of post-secondary education on lifetime earnings, some extraneous variables might be gender, ethnicity, social class, genetics, intelligence, age, and so forth. A variable is extraneous only when it can be assumed (or shown) to influence the dependent variable. If included in a regression, it can improve the fit of the model. If it is excluded from the regression and if it has a non-zero covariance with one or more of the independent variables of interest, its omission will bias the regression&#8217;s result for the effect of that independent variable of interest. This effect is called confounding or omitted variable bias; in these situations, design changes and/or statistical control is necessary.</p>
<p>Extraneous variables are often classified into three types:</p>
<ul>
<li>Subject variables, which are the characteristics of the individuals being studied that might affect their actions. These variables include age, gender, health status, mood, background, etc.</li>
<li>Blocking variables or experimental variables are characteristics of the persons conducting the experiment which might influence how a person behaves. Gender, the presence of racial discrimination, language, or other factors may qualify as such variables.</li>
<li>Situational variables are features of the environment in which the study or research was conducted, which have a bearing on the outcome of the experiment in a negative way. Included are the air temperature, level of activity, lighting, and the time of day.</li>
</ul>
<p>In quasi-experiments, differentiating between dependent and other variables may be downplayed in favour of differentiating between those variables that can be altered by the researcher and those that cannot.[citation needed] Variables in quasi-experiments may be referred to as &#8220;extraneous variables&#8221;, &#8220;subject variables&#8221;, &#8220;blocking variables&#8221;, &#8220;situational variables&#8221;, &#8220;pseudo-independent variables&#8221;, &#8220;ex post facto variables&#8221;, &#8220;natural group variables&#8221; or &#8220;non-manipulated variables&#8221;.</p>
<p>In modelling, variability that is not covered by the independent variable is designated by e_i and is known as the &#8220;residual&#8221;, &#8220;side effect&#8221;, &#8220;error&#8221;, &#8220;unexplained share&#8221;, &#8220;residual variable&#8221;, or &#8220;tolerance&#8221;.</p>
<p>refs and see also</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Dependent_and_independent_variables">Dependent and independent variables - Wikipedia, the free encyclopedia</a></li>
</ul>
</dd>
</dl></li>
</ul>
</dd>
</dl>
<p>&#20540;&#24471;&#25171;&#21360;&#20986;&#26469;&#30340;&#8220;&#23567;&#25220;&#8221;&#65306;<a href="http://www.wzchen.com/probability-cheatsheet">Probability Cheatsheet</a></p>
<dl>
<dt>Probability theory <code class="fold">@</code></dt>
<dd><p>Probability theory is the branch of mathematics concerned with probability, the analysis of random phenomena. The central objects of probability theory are <strong>random variables</strong>, <strong>stochastic processes</strong>, and <strong>events</strong>: mathematical abstractions of non-deterministic events or measured quantities that may either be single occurrences or evolve over time in an apparently random fashion.</p>
<p>Terminology (words) <code class="fold">@</code></p>
<ul>
<li>RV: Random Varible</li>
<li>CRV: Continuous Random Varaible</li>
<li>DRV: Discrete Random Varaible</li>
<li>CDF, joint CDF</li>
<li>PMF, joint PMF</li>
<li>PDF, joint PDF</li>
<li>EV: expected value</li>
<li>LOTUS: Law of the Unconscious Statistician</li>
<li>Indicator Random Variables</li>
<li>UoU: Universality of Uniform</li>
<li>MGF: Moment Generating Functions</li>
<li>CLT: Central Limit Theorem</li>
<li>LLN: Law of Large Numbers</li>
<li>RSS: Residual Sum of Squares</li>
<li>OLS, ordinary least square</li>
<li>LAD, Least absolute deviations, also known as <strong>least absolute errors (LAE)</strong>,</li>
<li>stochastic <code>[st&#601;'k&#230;st&#618;k]</code> adj.&#12304;&#25968;&#12305;&#38543;&#26426;&#30340;&#65307;&#26426;&#20250;&#30340;&#65307;&#26377;&#21487;&#33021;&#24615;&#30340;&#65307;&#38543;&#20415;&#30340;, random error -&gt; stochastic error.</li>
</ul>
<dl>
<dt>Mode, mean, median <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Visualisation_mode_median_mean.svg/150px-Visualisation_mode_median_mean.svg.png" alt="Geometric visualisation of the mode, median and mean of an arbitrary probability density function." />
<p class="caption">Geometric visualisation of the mode, median and mean of an arbitrary probability density function.</p>
</div>
<p>&#25165;&#27880;&#24847;&#21040;&#36825;&#37324; mean &#34920;&#31034;&#25104;&#20102;&#19968;&#20010;&#22825;&#24179;&#19968;&#26679;&#30340;&#19996;&#35199;&#8230;&#8230;</p>
</dd>
<dt>Moment (mathematics) <code class="fold">@</code></dt>
<dd><p>In mathematics, a moment is a specific quantitative measure, used in both mechanics and statistics, of the shape of a set of points. If the points represent mass, then the <em>zero</em>th moment is the <strong>total mass</strong>, the first moment divided by the total mass is the <strong>center of mass</strong>, and the second moment is the <strong>rotational inertia</strong>. If the points represent probability density, then the <em>zero</em>th moment is the total probability (i.e.&#160;one), the first moment is the mean, the second central moment is the variance, the third moment is the skewness, and the fourth moment (with normalization and shift) is the kurtosis. The mathematical concept is closely related to the concept of moment in physics.</p>
<p>&#23545;&#20110; bounded distribution&#65292;&#20840;&#37096;&#30340;&#30697;&#20915;&#23450;&#20102;&#20998;&#24067;&#12290;</p>
<p>For a bounded distribution of mass or probability, the collection of all the moments (of all orders, from 0 to &#8734;) uniquely determines the distribution.</p>
<p>&#30697;&#30340;&#23450;&#20041;&#65288;CRV&#65289;&#12290; The n-th moment of a real-valued continuous function f(x) of a real variable about a value c is</p>
<p><span class="math display">\[\mu_n=\int_{-\infty}^\infty (x - c)^n\,f(x)\,dx.\]</span></p>
<p>For the second and higher moments, the central moments (moments about the mean, with c being the mean) are usually used rather than the moments about zero, because they provide clearer information about the distribution&#8217;s shape.</p>
<p>Other moments may also be defined. For example, the n-th inverse moment about zero is <span class="math inline">\(\operatorname{E}\left[X^{-n}\right]\)</span> and the n-th logarithmic moment about zero is <span class="math inline">\(\operatorname{E}\left[\ln^n(X)\right]\)</span>.</p>
<p>Significance of moments (raw, central, standardised) and cumulants &#65288;&#32047;&#35745;&#35823;&#24046;&#65289; (raw, standardised), in connection with named properties of distributions:</p>
<ul>
<li><p><strong>mean</strong></p>
<p>The <strong>first raw moment</strong> is the mean.</p></li>
<li><p><strong>variance</strong></p>
<p>The <strong>second central moment</strong> is the variance. Its positive square root is the standard deviation &#963;.</p></li>
<li><p><strong>skewness</strong></p>
<p>The <strong>third central moment</strong> is a measure of the lopsidedness (&#19981;&#24179;&#34913;) of the distribution; any symmetric distribution will have a third central moment, if defined, of zero. The normalised third central moment is called the skewness, often &#947; (gamma).<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p></li>
<li><p><strong>Kurtosis</strong></p>
<p><code>[k&#604;&#720;'t&#601;&#650;s&#618;s]</code> n.&#12304;&#32479;&#12305;&#23789;&#24230;, &#23792;&#24230;&#65307;&#23792;&#24577;&#65307;&#23792;&#24230;&#31995;&#25968;</p></li>
<li><p><strong>Normalised moments</strong></p>
<p>The normalised n-th central moment or standardized moment is the n-th central moment divided by &#963;n; the normalised n-th central moment of</p>
<p><span class="math display">\[x = \frac{\operatorname{E} \left [(x - \mu)^n \right ]}{\sigma^n}.\]</span></p></li>
</ul>
</dd>
<dt>Standard error <code class="fold">@</code></dt>
<dd><p>The <strong>standard error (SE)</strong> is the standard deviation of the sampling distribution of a statistic, most commonly of the mean. The term may also be used to refer to an estimate of that standard deviation, derived from a particular sample used to compute the estimate.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/488px-Standard_deviation_diagram.svg.png" alt="For a value that is sampled with an unbiased normally distributed error, the above depicts the proportion of samples that would fall between 0, 1, 2, and 3 standard deviations above and below the actual value." />
<p class="caption">For a value that is sampled with an unbiased normally distributed error, the above depicts the proportion of samples that would fall between 0, 1, 2, and 3 standard deviations above and below the actual value.</p>
</div>
<p>For example, the sample mean is the usual estimator of a population mean. However, different samples drawn from that same population would in general have different values of the sample mean, so there is <strong>a distribution of sampled means</strong> (with its own mean and variance). <strong>The standard error of the mean (SEM)</strong> (i.e., of using the sample mean as a method of estimating the population mean) is the standard deviation of those sample means over all possible samples (of a given size) drawn from the population. Secondly, the standard error of the mean can refer to an estimate of that standard deviation, computed from the sample of data being analyzed at the time.</p>
<p>The standard error of the mean (SE or SEM) is the standard deviation of the sample-mean&#8217;s estimate of a population mean.</p>
<p><span class="math display">\[\text{SE}_\bar{x}\ = \frac{s}{\sqrt{n}}\]</span></p>
<p>where</p>
<ul>
<li>s is the sample standard deviation (i.e., the sample-based estimate of the standard deviation of the population), and</li>
<li>n is the size (number of observations) of the sample</li>
</ul>
<p>This estimate may be compared with the formula for the true standard deviation of the sample mean:</p>
<p><span class="math display">\[\text{SD}_\bar{x}\ = \frac{\sigma}{\sqrt{n}}\]</span></p>
</dd>
<dt>Independent and identically distributed random variables <code class="fold">@</code></dt>
<dd><p>The abbreviation <strong>i.i.d.</strong> is particularly common in statistics (often as iid, sometimes written IID), where observations in a sample are often assumed to be effectively i.i.d. for the purposes of statistical inference. The assumption (or requirement) that observations be i.i.d. tends to simplify the underlying mathematics of many statistical methods (see mathematical statistics and statistical theory). However, in practical applications of statistical modeling the assumption may or may not be realistic. To test how realistic the assumption is on a given data set, the autocorrelation (&#33258;&#30456;&#20851;) can be computed, lag plots drawn or turning point test performed. The generalization of <strong>exchangeable random variables</strong> is often sufficient and more easily met.</p>
<p>White noise is a simple example of IID.</p>
</dd>
<dt>Cumulative distribution function (<strong>CDF</strong>) <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/450px-Normal_Distribution_CDF.svg.png" />

</div>
<p>Every cumulative distribution function F is <strong>non-decreasing</strong> and <strong>right-continuous</strong>, which makes it a c&#224;dl&#224;g function<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a>. Furthermore,</p>
<p><span class="math display">\[\lim_{x\to -\infty}F(x)=0, \quad \lim_{x\to +\infty}F(x)=1.\]</span></p>
</dd>
<dt>Probability density function (<strong>pdf</strong>) <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Boxplot_vs_PDF.svg/525px-Boxplot_vs_PDF.svg.png" />

</div>
<p>If <span class="math inline">\(F_X\)</span> is the CDF of <span class="math inline">\(X\)</span>, then:</p>
<p><span class="math display">\[F_X(x) = \int_{-\infty}^x f_X(u) \, du ,\]</span></p>
<p>and (if <span class="math inline">\(f_X\)</span> is continuous at x)</p>
<p><span class="math display">\[f_X(x) = \frac{d}{dx} F_X(x).\]</span></p>
</dd>
<dt>Probability mass function (<strong>pmf</strong>) <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Discrete_probability_distrib.svg/330px-Discrete_probability_distrib.svg.png" />

</div>
<p><span class="math display">\[f_X(x) = \Pr(X = x) = \Pr(\{s \in S: X(s) = x\}).\]</span></p>
<p>Suppose that S is the sample space of all outcomes of a single toss of a fair coin, and X is the random variable defined on S assigning 0 to &#8220;tails&#8221; and 1 to &#8220;heads&#8221;. Since the coin is fair, the probability mass function is</p>
<p><span class="math display">\[f_X(x) = \begin{cases}\frac{1}{2}, &amp;x \in \{0, 1\},\\0, &amp;x \notin \{0, 1\}.\end{cases}\]</span></p>
</dd>
<dt>Probability space <code class="fold">@</code></dt>
<dd><p>In probability theory, a probability space or a probability triple is a <strong>mathematical construct</strong> that models a real-world process (or &#8220;experiment&#8221;) consisting of states that occur randomly. A probability space is constructed with a specific kind of situation or experiment in mind. One proposes that each time a situation of that kind arises, the set of possible outcomes is the same and the probabilities are also the same.</p>
<p>A probability space consists of three parts:</p>
<ul>
<li>A <strong>sample space, <span class="math inline">\(\Omega\)</span></strong>, which is the set of all possible outcomes.</li>
<li>A set of <strong>events <span class="math inline">\(\mathcal{F}\)</span></strong>, where each event is a set containing zero or more outcomes.</li>
<li>The <strong>assignment of probabilities to the events</strong>; that is, a function P from events to probabilities.</li>
</ul>
<p>A probability space is <strong>a mathematical triplet (<span class="math inline">\(\Omega\)</span>, <span class="math inline">\(\mathcal{F}\)</span>, P)</strong> that presents a model for a particular class of real-world situations. As with other models, its author ultimately defines which elements <span class="math inline">\(\Omega\)</span>, <span class="math inline">\(\mathcal{F}\)</span>, and P will contain.</p>
</dd>
<dt>Expected value <code class="fold">@</code></dt>
<dd><p><strong>Univariate discrete random variable, countable case</strong></p>
<p><span class="math display">\[\operatorname{E}[X] = \sum_{i=1}^\infty x_i\, p_i,\]</span></p>
<p><strong>Univariate continuous random variable</strong></p>
<p><span class="math display">\[\operatorname{E}[X] = \int_{-\infty}^\infty x f(x)\, \mathrm{d}x.\]</span></p>
<p><strong>General definition</strong></p>
<p>In general, if X is a random variable defined on a probability space (&#937;, &#931;, P), then the expected value of X, denoted by <span class="math inline">\(E[X]\)</span> (or <span class="math inline">\(&#9001;X&#9002;\)</span>, <span class="math inline">\(X\)</span>), is defined as the <a href="https://en.wikipedia.org/wiki/Lebesgue_integration">Lebesgue integral</a></p>
<p><span class="math display">\[\operatorname{E} [X] = \int_\Omega X \, \mathrm{d}P = \int_\Omega X(\omega) P(\mathrm{d}\omega)\]</span></p>
<p>When this integral exists, it is defined as the expectation of X. <strong>Not all random variables have a finite expected value, since the integral may not converge absolutely; furthermore, for some it is not defined at all (e.g., Cauchy distribution).</strong> Two variables with the same probability distribution will have the same expected value, if it is defined.</p>
<p><strong>Expectation of matrices</strong></p>
<p>If X is an m &#215; n matrix, then the expected value of the matrix is defined as the matrix of expected values:</p>
<p><span class="math display">\[
    \begin{align}
    \operatorname{E}[X] &amp;=
    \operatorname{E} \left [ \begin{pmatrix}
        x_{1,1} &amp; x_{1,2} &amp; \cdots &amp; x_{1,n} \\
        x_{2,1} &amp; x_{2,2} &amp; \cdots &amp; x_{2,n} \\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
        x_{m,1} &amp; x_{m,2} &amp; \cdots &amp; x_{m,n}
    \end{pmatrix} \right ] \\
    &amp;= \begin{pmatrix}
        \operatorname{E}[x_{1,1}] &amp; \operatorname{E}[x_{1,2}] &amp; \cdots &amp; \operatorname{E}[x_{1,n}] \\
        \operatorname{E}[x_{2,1}] &amp; \operatorname{E}[x_{2,2}] &amp; \cdots &amp; \operatorname{E}[x_{2,n}] \\
        \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
        \operatorname{E}[x_{m,1}] &amp; \operatorname{E}[x_{m,2}] &amp; \cdots &amp; \operatorname{E}[x_{m,n}]
    \end{pmatrix}
    \end{align}.
\]</span></p>
<p>This is utilized in covariance matrices.</p>
</dd>
<dt>Law of the unconscious statistician <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the <strong>law of the unconscious statistician</strong> (sometimes abbreviated <strong>LOTUS</strong>) is a theorem used to calculate the expected value of a function g(X) of a random variable X when one knows the probability distribution of X but one does not explicitly know the distribution of g(X).</p>
<p>&#22909;&#22788;&#26159;&#21487;&#20197;&#19981;&#29992;&#30693;&#36947; Y &#30340;&#20998;&#24067;&#65292;&#21482;&#35201;&#30693;&#36947; X &#30340;&#20998;&#24067;&#65292;&#20197;&#21450; Y &#20851;&#20110; X &#30340;&#20989;&#25968;&#65292;&#21363;&#21487;&#31639;&#20986; Y &#30340;&#26399;&#26395;&#12290;</p>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">Law of the unconscious statistician - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Variance <code class="fold">@</code></dt>
<dd><p>The variance of a random variable X is the expected value of the squared deviation from the mean &#956; = E[X]:</p>
<p><span class="math display">\[\operatorname{Var}(X) = \operatorname{E}\left[(X - \mu)^2 \right].\]</span></p>
<p>The variance can also be thought of as the covariance of a random variable with itself:</p>
<p><span class="math display">\[\operatorname{Var}(X) = \operatorname{Cov}(X, X).\]</span></p>
<p><strong>Continuous random variable</strong></p>
<p><span class="math display">\[\operatorname{Var}(X) =\sigma^2 =\int (x-\mu)^2 \, f(x) \, dx\, =\int x^2 \, f(x) \, dx\, - \mu^2\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the expected value,</p>
<p><span class="math display">\[\mu = \int x \, f(x) \, dx\,\]</span></p>
<p><strong>Discrete random variable</strong></p>
<p>If the generator of random variable X is discrete with probability mass function x1 &#8614; p1, &#8230;, xn &#8614; pn, then</p>
<p><span class="math display">\[\operatorname{Var}(X) = \sum_{i=1}^n p_i\cdot(x_i - \mu)^2,\]</span></p>
<p>or equivalently</p>
<p><span class="math display">\[\operatorname{Var}(X) = \sum_{i=1}^n p_i x_i ^2- \mu^2,\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the expected value, i.e.</p>
<p><span class="math display">\[\mu = \sum_{i=1}^n p_i\cdot x_i.\]</span></p>
<p><strong>Sum of uncorrelated variables (Bienaym&#233; formula)</strong></p>
<p>&#38543;&#26426;&#21464;&#37327;&#30340;&#21644;&#30340;&#26041;&#24046;&#31561;&#20110;&#21508;&#38543;&#26426;&#21464;&#37327;&#30340;&#26041;&#24046;&#30340;&#21644;&#12290;</p>
<p><i class="icon-info-sign"></i> One reason for the use of the variance in preference to other measures of dispersion is that the variance of the sum (or the difference) of uncorrelated random variables is the sum of their variances:</p>
<p><span class="math display">\[\operatorname{Var}\Big(\sum_{i=1}^n X_i\Big) = \sum_{i=1}^n \operatorname{Var}(X_i).\]</span></p>
<p>This statement is called the <strong>Bienaym&#233; formula</strong> (bienayme formula) and was discovered in 1853. It is often made with the stronger condition that the variables are independent, but being uncorrelated suffices. So if all the variables have the same variance &#963;2, then, since division by n is a linear transformation, this formula immediately implies that the variance of their mean is</p>
<p><span class="math display">\[\operatorname{Var}\left(\overline{X}\right) =
\operatorname{Var}\left(\frac {1} {n}\sum_{i=1}^n X_i\right) = \frac
{1} {n^2}\sum_{i=1}^n \operatorname{Var}\left(X_i\right) = \frac
{\sigma^2} {n}.\]</span></p>
<p>That is, ** the variance of the mean decreases when n increases**. This formula for the variance of the mean is used in the definition of the standard error of the sample mean, which is used in the central limit theorem.</p>
<p>&#36825;&#26679;&#23601;&#21487;&#20197;&#29992;&#26356;&#22810;&#30340;&#25968;&#25454;&#26469;&#20943;&#23569;&#35823;&#24046;&#12290;</p>
</dd>
<dt>Covariance <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, covariance is a measure of how much two random variables change together. If the greater values of one variable mainly correspond with the greater values of the other variable, and the same holds for the lesser values, i.e., the variables tend to show similar behavior, the covariance is positive.</p>
<p>A distinction must be made between</p>
<ol style="list-style-type: decimal">
<li>the covariance of two random variables, which is a population parameter that can be seen as a property of the joint probability distribution, and</li>
<li>the sample covariance, which serves as an estimated value of the parameter.</li>
</ol>
<p>The covariance between two jointly distributed real-valued random variables X and Y with finite second moments is defined as</p>
<p>&#21644;&#26041;&#24046;&#30340;&#23450;&#20041;&#31867;&#20284;&#12290;</p>
<p><span class="math display">\[\operatorname{cov}(X,Y) = \operatorname{E}{\big[(X - \operatorname{E}[X])(Y - \operatorname{E}[Y])\big]},\]</span></p>
<p>where E[X] is the expected value of X, also known as the mean of X. By using the linearity property of expectations, this can be simplified to</p>
<p><span class="math display">\[
\begin{align}
\operatorname{cov}(X,Y)
&amp;= \operatorname{E}\left[\left(X - \operatorname{E}\left[X\right]\right) \left(Y - \operatorname{E}\left[Y\right]\right)\right] \\
&amp;= \operatorname{E}\left[X Y - X \operatorname{E}\left[Y\right] - \operatorname{E}\left[X\right] Y + \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right]\right] \\
&amp;= \operatorname{E}\left[X Y\right] - \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right] - \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right] + \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right] \\
&amp;= \operatorname{E}\left[X Y\right] - \operatorname{E}\left[X\right] \operatorname{E}\left[Y\right]. \end{align}
\]</span></p>
<p>However, when <span class="math inline">\(\operatorname{E}[XY] \approx \operatorname{E}[X]\operatorname{E}[Y]\)</span>, this last equation is prone to <strong>catastrophic cancellation</strong> when computed with floating point arithmetic and thus should be avoided in computer programs when the data has not been centered before. Numerically stable algorithms should be preferred in this case.</p>
<p>For random vectors <span class="math inline">\(\mathbf{X} \in \mathbb{R}^m\)</span> and <span class="math inline">\(\mathbf{Y} \in \mathbb{R}^n\)</span>, <strong>the m&#215;n cross covariance matrix</strong> (also known as <strong>dispersion (<code>[d&#618;'sp&#605;&#658;n]</code>, &#31163;&#24046;) matrix</strong> or <strong>variance&#8211;covariance matrix</strong>, or simply called covariance matrix) is equal to</p>
<p><span class="math display">\[
\begin{align}
\operatorname{cov}(\mathbf{X},\mathbf{Y})
&amp;= \operatorname{E} \left[(\mathbf{X} - \operatorname{E}[\mathbf{X}]) (\mathbf{Y} - \operatorname{E}[\mathbf{Y}])^\mathrm{T}\right]\\
&amp;= \operatorname{E}\left[\mathbf{X} \mathbf{Y}^\mathrm{T}\right] - \operatorname{E}[\mathbf{X}]\operatorname{E}[\mathbf{Y}]^\mathrm{T},
\end{align}
\]</span></p>
<p>where <span class="math inline">\(m^T\)</span> is the transpose of the vector (or matrix) m.</p>
<p>For a vector <span class="math inline">\(\mathbf{X}= \begin{bmatrix}X_1 &amp; X_2 &amp; \dots &amp; X_m\end{bmatrix}^\mathrm{T}\)</span> of m jointly distributed random variables with finite second moments, its covariance matrix is defined as</p>
<p><span class="math display">\[\Sigma(\mathbf{X}) = \sigma(\mathbf{X},\mathbf{X}).\]</span></p>
</dd>
<dt>Classical definition <code class="fold">@</code></dt>
<dd><p>The probability of an event is <strong>the ratio</strong> of</p>
<ul>
<li>the number of cases favorable to it, to</li>
<li>the number of all cases possible</li>
</ul>
<p>when nothing leads us to expect that any one of these cases should occur more than any other, which renders them, for us, equally possible.</p>
<p>This definition is essentially a consequence of the principle of indifference. If elementary events are assigned equal probabilities, then the probability of a disjunction of elementary events is just the number of events in the disjunction divided by the total number of elementary events.</p>
<p>The classical definition of probability was called into question by several writers of the nineteenth century, including John Venn and George Boole. The frequentist definition of probability became widely accepted as a result of their criticism, and especially through the works of R.A. Fisher. <strong>The classical definition enjoyed a revival of sorts due to the general interest in Bayesian probability, because Bayesian methods require a prior probability distribution and the principle of indifference offers one source of such a distribution.</strong> Classical probability can offer prior probabilities that reflect ignorance which often seems appropriate before an experiment is conducted.</p>
</dd>
<dt>Modern definition <code class="fold">@</code></dt>
<dd><p>(Discrete) The modern definition starts with a finite or countable set called the <strong>sample space</strong>, which relates to the set of all possible outcomes in classical sense, denoted by <span class="math inline">\(\Omega\)</span>. It is then assumed that for each element <span class="math inline">\(x \in \Omega\,\)</span>, an intrinsic &#8220;probability&#8221; value <span class="math inline">\(f(x)\,\)</span> is attached, which satisfies the following properties:</p>
<ul>
<li><span class="math inline">\(f(x)\in[0,1]\mbox{ for all }x\in \Omega\,\)</span>;</li>
<li><span class="math inline">\(\sum_{x\in \Omega} f(x) = 1\,\)</span>.</li>
</ul>
<p>(Continuous) If the outcome space of a random variable X is the set of real numbers (<span class="math inline">\(\mathbb{R}\)</span>) or a subset thereof, then a function called the cumulative distribution function (or cdf) <span class="math inline">\(F\,\)</span> exists, defined by <span class="math inline">\(F(x) = P(X\le x) \,\)</span>. That is, <span class="math inline">\(F(x)\)</span> returns the probability that X will be less than or equal to x.</p>
<p>The cdf necessarily satisfies the following properties.</p>
<ul>
<li><span class="math inline">\(F\,\)</span> is a monotonically non-decreasing, right-continuous function;</li>
<li><span class="math inline">\(\lim_{x\rightarrow -\infty} F(x)=0\,\)</span>;</li>
<li><span class="math inline">\(\lim_{x\rightarrow \infty} F(x)=1\,\)</span>.</li>
</ul>
</dd>
<dt>Classical probability distributions <code class="fold">@</code></dt>
<dd><p>&#24120;&#35265;&#30340;&#32463;&#20856;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;</p>
<p>Certain random variables occur very often in probability theory because they well describe many natural or physical processes. Their distributions therefore have gained special importance in probability theory. Some fundamental discrete distributions are the discrete uniform, Bernoulli, binomial, negative binomial, Poisson and geometric distributions. Important continuous distributions include the continuous uniform, normal, exponential, gamma and beta distributions.</p>
</dd>
</dl>
</dd>
</dl>
<dl>
<dt>Discrete Uniform distribution <code class="fold">@</code></dt>
<dd><p>The discrete uniform distribution itself is <strong>inherently non-parametric</strong>. It is convenient, however, to represent its values generally by an integer interval [a,b], so that a,b become the main parameters of the distribution (often one simply considers the interval [1,n] with the single parameter n). With these conventions, the cumulative distribution function (CDF) of the discrete uniform distribution can be expressed, for any k &#8712; [a,b], as</p>
<p><span class="math display">\[F(k;a,b)=\frac{\lfloor k \rfloor -a + 1}{b-a+1}\]</span></p>
<p>pmf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Uniform_discrete_pmf_svg.svg/488px-Uniform_discrete_pmf_svg.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Dis_Uniform_distribution_CDF.svg/488px-Dis_Uniform_distribution_CDF.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\(\frac{1}{n}\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\frac{\lfloor k \rfloor -a+1}{n}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\frac{a+b}{2}\,\)</span></td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\frac{(b-a+1)^2-1}{12}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Bernoulli distribution &#20271;&#21162;&#21033;&#20998;&#24067; <code class="fold">@</code></dt>
<dd><p>If X is a random variable with this distribution, we have:</p>
<p><span class="math display">\[\Pr(X=1) = 1 - \Pr(X=0) = 1 - q = p.\!\]</span></p>
<p>The probability mass function f of this distribution, over possible outcomes k, is</p>
<p><span class="math display">\[f(k;p) = \begin{cases} p &amp; \text{if }k=1, \\[6pt] 1-p &amp; \text {if }k=0.\end{cases}\]</span></p>
<p>This can also be expressed as</p>
<p><span class="math display">\[f(k;p) = p^k (1-p)^{1-k}\!\quad \text{for }k\in\{0,1\}.\]</span></p>
<p>The Bernoulli distribution is a special case of the binomial distribution with n = 1.</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td align="left">0&lt;p&lt;1, <span class="math inline">\(p\in\mathbb{R}\)</span></td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(k \in \{0,1\}\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\(\begin{cases} q=(1-p) &amp; \text{for }k=0 \\ p &amp; \text{for }k=1 \end{cases}\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\begin{cases} 0 &amp; \text{for }k&lt;0 \\ 1 - p &amp; \text{for }0\leq k&lt;1 \\ 1 &amp; \text{for }k\geq 1 \end{cases}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(p\,\)</span></td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\begin{cases} 0 &amp; \text{if } q &gt; p\\ 0.5 &amp; \text{if } q=p\\ 1 &amp; \text{if } q&lt;p \end{cases}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\begin{cases} 0 &amp; \text{if } q &gt; p\\ 0, 1 &amp; \text{if } q=p\\ 1 &amp; \text{if } q &lt; p \end{cases}\)</span></td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(p(1-p) (=pq)\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\frac{1-2p}{\sqrt{pq}}\)</span></td>
</tr>
<tr class="even">
<td align="left">Ex. kurtosis</td>
<td align="left"><span class="math inline">\(\frac{1-6pq}{pq}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(-q\ln(q)-p\ln(p)\,\)</span></td>
</tr>
<tr class="even">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\(q+pe^t\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">CF</td>
<td align="left"><span class="math inline">\(q+pe^{it}\,\)</span></td>
</tr>
<tr class="even">
<td align="left">PGF</td>
<td align="left"><span class="math inline">\(q+pz\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">Fisher information</td>
<td align="left"><span class="math inline">\(\frac{1}{p(1-p)}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Binomial distribution &#20108;&#39033;&#20998;&#24067; <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent yes/no experiments, each of which yields success with probability p.&#160;A success/failure experiment is also called a <strong>Bernoulli experiment</strong> or <strong>Bernoulli trial</strong>; when n = 1, the binomial distribution is a Bernoulli distribution. The binomial distribution is the basis for the popular binomial test of statistical significance.</p>
<p>pdf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Binomial_distribution_pmf.svg/450px-Binomial_distribution_pmf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Binomial_distribution_cdf.svg/450px-Binomial_distribution_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td align="left">n &#8712; N0 &#8212; number of trials, p &#8712; [0,1] &#8212; success probability in each trial</td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(k &#8712; {&#8201;0, &#8230;, n&#8201;}\)</span> &#8212; number of successes</td>
</tr>
<tr class="odd">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\(\textstyle {n \choose k}\, p^k (1-p)^{n-k}\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\textstyle I_{1-p}(n - k, 1 + k)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(np\)</span></td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\lfloor np \rfloor or \lceil np \rceil\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\lfloor (n + 1)p \rfloor or \lceil (n + 1)p \rceil - 1\)</span></td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(np(1 - p)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\frac{1-2p}{\sqrt{np(1-p)}}\)</span></td>
</tr>
<tr class="even">
<td align="left">Ex. kurtosis</td>
<td align="left"><span class="math inline">\(\frac{1-6p(1-p)}{np(1-p)}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\frac12 \log_2 \big( 2\pi e\, np(1-p) \big) + O \left( \frac{1}{n} \right)\)</span> in shannons. For nats, use the natural log in the log.</td>
</tr>
<tr class="even">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\((1-p + pe^t)^n \!\)</span></td>
</tr>
<tr class="odd">
<td align="left">CF</td>
<td align="left"><span class="math inline">\((1-p + pe^{it})^n \!\)</span></td>
</tr>
<tr class="even">
<td align="left">PGF</td>
<td align="left"><span class="math inline">\(G(z) = \left[(1-p) + pz\right]^n.\)</span></td>
</tr>
<tr class="odd">
<td align="left">Fisher information</td>
<td align="left"><span class="math inline">\(g_n(p) = \frac{n}{p(1-p)}\)</span> (for fixed n)</td>
</tr>
</tbody>
</table>
</dd>
<dt>Poisson distribution &#27850;&#26494;&#20998;&#24067; <code class="fold">@</code></dt>
<dd><dl>
<dt>Story <code class="fold">@</code></dt>
<dd><p>There are rare events (low probability events) that occur many different ways (high possibilities of occurences) at an average rate of &#955; occurrences per unit space or time. The number of events that occur in that unit of space or time is X.</p>
<p>Example A certain busy intersection &#65288;&#21313;&#23383;&#36335;&#21475;&#65289;has an average of 2 accidents per month. Since an accident is a low probability event that can happen many different ways, it is reasonable to model the number of accidents in a month at that intersection as Pois(2). Then the number of accidents that happen in two months at that intersection is distributed Pois(4).</p>
<p>&#36895;&#29575;&#26159; &#955;, &#22312;&#26102;&#38388; n &#20869;&#21457;&#29983;&#30340;&#27425;&#25968;&#29992; X &#26469;&#34920;&#31034;&#65292;&#37027;&#20040; X ~ Poi(&#955;)</p>
</dd>
</dl>
<p>Poission &#21644;&#27888;&#21202;&#32423;&#25968;&#26159;&#30456;&#20851;&#30340;&#12290;</p>
<p>Poisson distribution (<code>/&#712;pw&#593;&#720;s&#594;n/</code>), named after French mathematician Sim&#233;on Denis Poisson, is a discrete probability distribution that expresses the probability of a given number of events <strong>occurring in a fixed interval of time and/or space if these events occur with a known average rate and independently of the time since the last event</strong>. The Poisson distribution can also be used for the number of events in other specified intervals such as distance, area or volume.</p>
<p>A discrete random variable X is said to have a Poisson distribution with parameter &#955; &gt; 0, if, for k = 0, 1, 2, &#8230;, the probability mass function of X is given by:</p>
<p><span class="math display">\[\!f(k; \lambda)= \Pr(X = k)= \frac{\lambda^k e^{-\lambda}}{k!},\]</span></p>
<p>The positive real number &#955; is equal to the expected value of X and also to its variance</p>
<p><span class="math display">\[\lambda=\operatorname{E}(X)=\operatorname{Var}(X).\]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Poisson_pmf.svg/488px-Poisson_pmf.svg.png" alt="pmf: The horizontal axis is the index k, the number of occurrences. &#955; is the expected value. The function is defined only at integer values of k. The connecting lines are only guides for the eye." />
<p class="caption"><strong>pmf</strong>: The horizontal axis is the index k, the number of occurrences. &#955; is the expected value. The function is defined only at integer values of k. The connecting lines are only guides for the eye.</p>
</div>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Poisson_cdf.svg/488px-Poisson_cdf.svg.png" alt="CDF: The horizontal axis is the index k, the number of occurrences. The CDF is discontinuous at the integers of k and flat everywhere else because a variable that is Poisson distributed takes on only integer values." />
<p class="caption"><strong>CDF</strong>: The horizontal axis is the index k, the number of occurrences. The CDF is discontinuous at the integers of k and flat everywhere else because a variable that is Poisson distributed takes on only integer values.</p>
</div>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td align="left"><span class="math inline">\(&#955; &gt; 0 (real)\)</span></td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(k &#8712; &#8484;*\)</span></td>
</tr>
<tr class="odd">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\(\frac{\lambda^k e^{-\lambda}}{k!}\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\frac{\Gamma(\lfloor k+1\rfloor, \lambda)}{\lfloor k\rfloor !}\)</span>, or</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"><span class="math inline">\(e^{-\lambda} \sum_{i=0}^{\lfloor k\rfloor} \frac{\lambda^i}{i!}\)</span>, or</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"><span class="math inline">\(Q(\lfloor k+1\rfloor,\lambda)\)</span> (for <span class="math inline">\(k\ge 0\)</span>, where</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left"><span class="math inline">\(\Gamma(x, y)\)</span> is the incomplete gamma function, <span class="math inline">\(\lfloor k\rfloor\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">is the floor function, and Q is the regularized gamma function)</td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\lambda\)</span></td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\approx\lfloor\lambda+1/3-0.02/\lambda\rfloor\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\lceil\lambda\rceil - 1, \lfloor\lambda\rfloor\)</span></td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\lambda\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\lambda^{-1/2}\)</span></td>
</tr>
<tr class="even">
<td align="left">Ex. kurtosis</td>
<td align="left"><span class="math inline">\(\lambda^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\lambda[1 - \log(\lambda)] + e^{-\lambda}\sum_{k=0}^\infty \frac{\lambda^k\log(k!)}{k!} (for large \lambda)\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"><span class="math inline">\(\frac{1}{2}\log(2 \pi e \lambda) - \frac{1}{12 \lambda} - \frac{1}{24 \lambda^2} - \qquad \frac{19}{360 \lambda^3} + O\left(\frac{1}{\lambda^4}\right)\)</span></td>
</tr>
<tr class="odd">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\(\exp(\lambda (e^{t} - 1))\)</span></td>
</tr>
<tr class="even">
<td align="left">CF</td>
<td align="left"><span class="math inline">\(\exp(\lambda (e^{it} - 1))\)</span></td>
</tr>
<tr class="odd">
<td align="left">PGF</td>
<td align="left"><span class="math inline">\(\exp(\lambda(z - 1))\)</span></td>
</tr>
<tr class="even">
<td align="left">Fisher information</td>
<td align="left"><span class="math inline">\(\lambda^{-1}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Compound Poisson distribution <code class="fold">@</code></dt>
<dd><p>In probability theory, a compound Poisson distribution is the probability distribution of the sum of a number of independent identically-distributed random variables, where the number of terms to be added is itself a Poisson-distributed variable. In the simplest cases, the result can be either a continuous or a discrete distribution.</p>
<dl>
<dt>Definition <code class="fold">@</code></dt>
<dd><p>Suppose that</p>
<p><span class="math display">\[N\sim\operatorname{Poisson}(\lambda),\]</span></p>
<p>i.e., N is a random variable whose distribution is a Poisson distribution with expected value &#955;, and that</p>
<p><span class="math display">\[X_1, X_2, X_3, \dots\]</span></p>
<p>are identically distributed random variables that are mutually independent and also independent of N. Then the probability distribution of the sum of N i.i.d. random variables conditioned on the number of these variables (N):</p>
<p><span class="math display">\[Y \mid N=\sum_{n=1}^N X_n\]</span></p>
<p>has a well-defined distribution. In the case N = 0, then the value of Y is 0, so that then Y | N = 0 has a degenerate distribution.</p>
<p>The compound Poisson distribution is obtained by marginalising the joint distribution of (Y,N) over N, where this joint distribution is obtained by combining the conditional distribution Y | N with the marginal distribution of N.</p>
</dd>
<dt>Properties</dt>
<dd><p>Mean and variance of the compound distribution derive in a simple way from law of total expectation and the law of total variance. Thus</p>
</dd>
</dl>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Compound_Poisson_distribution">Compound Poisson distribution - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Law of total expectation <code class="fold">@</code></dt>
<dd><p>The proposition in probability theory known as the law of total expectation, the law of iterated expectations, the tower rule, the smoothing theorem, and Adam&#8217;s Law among other names, states that if X is an integrable random variable (i.e., a random variable satisfying E( | X | ) &lt; &#8734;) and Y is any random variable, not necessarily integrable, on the same probability space, then</p>
<p><span class="math display">\[\operatorname{E} (X) = \operatorname{E} ( \operatorname{E} ( X \mid Y)),\]</span></p>
<p>i.e., <strong>the expected value of the conditional expected value of X given Y is the same as the expected value of X.</strong></p>
<p>The conditional expected value E( X | Y ) is a random variable in its own right, whose value depends on the value of Y. Notice that the conditional expected value of X given the event Y = y is a function of y. If we write E( X | Y = y) = g(y) then the random variable E( X | Y ) is just g(Y).</p>
<p>One special case states that if <span class="math inline">\(A_1, A_2, \ldots, A_n\)</span> is a partition of the whole outcome space, i.e.&#160;these events are <strong>mutually exclusive</strong> and <strong>exhaustive</strong>, then</p>
<p><span class="math display">\[\operatorname{E} (X) = \sum_{i=1}^{n}{\operatorname{E}(X \mid A_i) \operatorname{P}(A_i)}.\]</span></p>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Law_of_total_expectation">Law of total expectation - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Law of total variance <code class="fold">@</code></dt>
<dd><p>In probability theory, the law of total variance or variance decomposition formula, also known as Eve&#8217;s law, states that if X and Y are random variables on the same probability space, and the variance of Y is finite, then</p>
<p><span class="math display">\[\operatorname{Var}[Y]=\operatorname{E}(\operatorname{Var}[Y\mid X])+\operatorname{Var}(\operatorname{E}[Y\mid X]).\,\]</span></p>
<p>&#19981;&#20165;&#27010;&#29575;&#21487;&#20197;&#20998;&#22359;&#21152;&#65292;variance &#20063;&#21487;&#20197;&#12290;</p>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Law_of_total_variance">Law of total variance - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Poisson approximation <code class="fold">@</code></dt>
<dd><p>the Poisson distribution with parameter <strong>&#955; = np</strong> can be used as an approximation to B(n, p) of the binomial distribution if n is sufficiently large and p is sufficiently small.</p>
<p>Limiting distributions</p>
<ul>
<li><p><strong>Poisson limit theorem</strong>: As n approaches &#8734; and p approaches 0, then the Binomial(n, p) distribution approaches the Poisson distribution with expected value &#955;</p></li>
<li><p><strong>de Moivre&#8211;Laplace theorem</strong>: As n approaches &#8734; while p remains fixed, the distribution of <span class="math display">\[\frac{X-np}{\sqrt{np(1-p)}}\]</span></p>
<p>approaches the normal distribution with expected value 0 and variance 1. This result is sometimes loosely stated by saying that the distribution of X is asymptotically normal with expected value np and variance np(1 &#8722; p). This result is a specific case of the central limit theorem.</p>
<p>&#36825;&#20010;&#30475;&#25104; normalize &#23601;&#21487;&#20197;&#20102;&#12290;X<sub>normalized</sub> = (X - mean)/variance</p></li>
</ul>
</dd>
<dt>Poisson limit theorem <code class="fold">@</code></dt>
<dd><p>The law of rare events or Poisson limit theorem gives a Poisson approximation to the binomial distribution, under certain conditions. The theorem was named after Sim&#233;on Denis Poisson (1781&#8211;1840).</p>
<p>If <span class="math inline">\(n \rightarrow \infty, p \rightarrow 0, \text{such that } np \rightarrow \lambda\)</span>, then</p>
<p><span class="math display">\[\frac{n!}{(n-k)!k!} p^k (1-p)^{n-k} \rightarrow e^{-\lambda}\frac{\lambda^k}{k!}.\]</span></p>
</dd>
<dt>Negative binomial distribution <code class="fold">@</code></dt>
<dd><p>Different texts adopt slightly different definitions for the negative binomial distribution. They can be distinguished by whether the support starts at k = 0 or at k = r, whether p denotes the probability of a success or of a failure, and whether r represents success or failure, so it is crucial to identify the specific parametrization used in any given text.</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Notation</td>
<td align="left"><span class="math inline">\(\mathrm{NB}(r,\,p)\)</span></td>
</tr>
<tr class="even">
<td align="left">Parameters</td>
<td align="left">r &gt; 0 &#8212; number of failures until the experiment is stopped, p &#8712; (0,1) &#8212; success probability in each experiment (real)</td>
</tr>
<tr class="odd">
<td align="left">Support</td>
<td align="left">k &#8712; {&#8201;0, 1, 2, 3, &#8230;&#8201;} &#8212; number of successes</td>
</tr>
<tr class="even">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\({k+r-1 \choose k}\cdot (1-p)^r p^k,\!\)</span> involving a binomial coefficient<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></td>
</tr>
<tr class="odd">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(1-I_p(k+1,\,r)\)</span>, the regularized incomplete beta function</td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\frac{pr}{1-p}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\begin{cases}\big\lfloor\frac{p(r-1)}{1-p}\big\rfloor &amp; \text{if}\ r&gt;1 \\ 0 &amp; \text{if}\ r\leq 1\end{cases}\)</span></td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\frac{pr}{(1-p)^2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\frac{1+p}{\sqrt{pr}}\)</span></td>
</tr>
</tbody>
</table>
<p>Suppose there is a sequence of independent Bernoulli trials. Thus, each trial has two potential outcomes called &#8220;success&#8221; and &#8220;failure&#8221;. In each trial the probability of success is p and of failure is (1 &#8722; p). We are observing this sequence <strong>until a predefined number r of failures has occurred</strong>. Then the random number of successes we have seen, X, will have the negative binomial (or Pascal) distribution:</p>
<p><span class="math display">\[X\sim\operatorname{NB}(r; p)\]</span></p>
</dd>
</dl>
<dl>
<dt>Geometric distribution <code class="fold">@</code></dt>
<dd><dl>
<dt>Story <code class="fold">@</code></dt>
<dd><p>X is the number of &#8220;failures&#8221; that we will achieve before we achieve our first success. Our successes have probability p.</p>
<p>Example If each pokeball we throw has probability 1/10 to catch Mew, the number of failed pokeballs will be distributed Geom( 1/10 ).</p>
</dd>
</dl>
<p>These two different geometric distributions should not be confused with each other. Often, the name shifted geometric distribution is adopted for the former one (distribution of the number X); however, to avoid ambiguity, it is considered wise to indicate which is intended, by mentioning the support explicitly.</p>
<p>It&#8217;s the probability that the first occurrence of success requires k number of independent trials, each with success probability p.&#160;If the probability of success on each trial is p, then the probability that the kth trial (out of k trials) is the first success is</p>
<p><span class="math display">\[\Pr(X = k) = (1-p)^{k-1}\,p\,\]</span></p>
<p>for k = 1, 2, 3, &#8230;.</p>
<p>The above form of geometric distribution is used for modeling the number of trials up to and including the first success. By contrast, the following form of the geometric distribution is used for modeling the number of failures until the first success:</p>
<p><span class="math display">\[\Pr(Y=k) = (1 - p)^k\,p\,\]</span></p>
<p>for k = 0, 1, 2, 3, &#8230;.</p>
<p>pmf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Geometric_pmf.svg/675px-Geometric_pmf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Geometric_cdf.svg/675px-Geometric_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td align="left">0&lt; p <span class="math inline">\(\leq\)</span> 1 success probability (real)</td>
<td align="left">0&lt; p <span class="math inline">\(\leq\)</span> 1 success probability (real)</td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td align="left">k trials where <span class="math inline">\(k \in \{1,2,3,\dots\}\!\)</span></td>
<td align="left">k failures where <span class="math inline">\(k \in \{0,1,2,3,\dots\}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">pmf</td>
<td align="left"><span class="math inline">\((1 - p)^{k-1}\,p\!\)</span></td>
<td align="left"><span class="math inline">\((1 - p)^{k}\,p\!\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(1-(1 - p)^k\!\)</span></td>
<td align="left"><span class="math inline">\(1-(1 - p)^{k+1}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\frac{1}{p}\!\)</span></td>
<td align="left"><span class="math inline">\(\frac{1-p}{p}\!\)</span></td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\left\lceil \frac{-1}{\log_2(1-p)} \right\rceil\!\)</span></td>
<td align="left"><span class="math inline">\(\left\lceil \frac{-1}{\log_2(1-p)} \right\rceil\! - 1\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left">1</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\frac{1-p}{p^2}\!\)</span></td>
<td align="left"><span class="math inline">\(\frac{1-p}{p^2}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\frac{2-p}{\sqrt{1-p}}\!\)</span></td>
<td align="left"><span class="math inline">\(\frac{2-p}{\sqrt{1-p}}\!\)</span></td>
</tr>
<tr class="even">
<td align="left">Excess kurtosis</td>
<td align="left"><span class="math inline">\(6+\frac{p^2}{1-p}\!\)</span></td>
<td align="left"><span class="math inline">\(6+\frac{p^2}{1-p}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\tfrac{-(1-p)\log_2 (1-p) - p \log_2 p}{p}\!\)</span></td>
<td align="left"><span class="math inline">\(\tfrac{-(1-p)\log_2 (1-p) - p \log_2 p}{p}\!\)</span></td>
</tr>
<tr class="even">
<td align="left">mgf</td>
<td align="left"><span class="math inline">\(\frac{pe^t}{1-(1-p) e^t}\!, for t&lt;-\ln(1-p)\!\)</span></td>
<td align="left"><span class="math inline">\(\frac{p}{1-(1-p)e^t}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Characteristic function</td>
<td align="left"><span class="math inline">\(\frac{pe^{it}}{1-(1-p)\,e^{it}}\!\)</span></td>
<td align="left"><span class="math inline">\(\frac{p}{1-(1-p)\,e^{it}}\!\)</span></td>
</tr>
</tbody>
</table>
<p>The expected value of a geometrically distributed random variable X is 1/p and the variance is (1 &#8722; p)/p2:</p>
<p><span class="math display">\[\mathrm{E}(X) = \frac{1}{p}, \qquad\mathrm{var}(X) = \frac{1-p}{p^2}.\]</span></p>
</dd>
<dt>Hypergeometric distribution <code class="fold">@</code></dt>
<dd><p>A random variable X follows the hypergeometric distribution if its probability mass function (pmf) is given by</p>
<p><span class="math display">\[
    P(X = k) = \frac{\binom{K}{k} \binom{N - K}{n-k}}{\binom{N}{n}},
\]</span></p>
<p>where</p>
<ul>
<li>N is the population size,</li>
<li>K is the number of success states in the population,</li>
<li>n is the number of draws,</li>
<li>k is the number of observed successes,</li>
<li><span class="math inline">\(\textstyle {a \choose b}\)</span> is a binomial coefficient.</li>
</ul>
</dd>
<dt>Continuous Uniform distribution <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the <strong>continuous uniform distribution</strong> or <strong>rectangular distribution</strong> is a family of symmetric probability distributions such that for each member of the family, all intervals of the same length on the distribution&#8217;s support are equally probable. The support is defined by the two parameters, a and b, which are its minimum and maximum values. The distribution is often abbreviated <strong>U(a,b)</strong>. It is the maximum entropy probability distribution for a random variate X under no constraint other than that it is contained in the distribution&#8217;s support.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Uniform_Distribution_PDF_SVG.svg/375px-Uniform_Distribution_PDF_SVG.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Uniform_cdf.svg/375px-Uniform_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Notation</td>
<td><span class="math inline">\(\mathcal{U}(a, b)\)</span> or <span class="math inline">\(\mathrm{unif}(a,b)\)</span></td>
</tr>
<tr class="even">
<td align="left">Parameters</td>
<td><span class="math inline">\(-\infty &lt; a &lt; b &lt; \infty \,\)</span></td>
</tr>
<tr class="odd">
<td align="left">Support</td>
<td><span class="math inline">\(x \in [a,b]\)</span></td>
</tr>
<tr class="even">
<td align="left">PDF</td>
<td><span class="math inline">\(\begin{cases} \frac{1}{b - a} &amp; \text{for } x \in [a,b] \\ 0 &amp; \text{otherwise} \end{cases}\)</span></td>
</tr>
<tr class="odd">
<td align="left">CDF</td>
<td><span class="math inline">\(\begin{cases} 0 &amp; \text{for } x &lt; a \\ \frac{x-a}{b-a} &amp; \text{for } x \in [a,b) \\ 1 &amp; \text{for } x \ge b \end{cases}\)</span></td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td><span class="math inline">\(\tfrac{1}{2}(a+b)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td><span class="math inline">\(\tfrac{1}{2}(a+b)\)</span></td>
</tr>
<tr class="even">
<td align="left">Mode</td>
<td>any value in (a,b)</td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td><span class="math inline">\(\tfrac{1}{12}(b-a)^2\)</span></td>
</tr>
<tr class="even">
<td align="left">Skewness</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Ex. kurtosis</td>
<td><span class="math inline">\(-\tfrac{6}{5}\)</span></td>
</tr>
<tr class="even">
<td align="left">Entropy</td>
<td><span class="math inline">\(\log(b-a) \,\)</span></td>
</tr>
<tr class="odd">
<td align="left">MGF</td>
<td><span class="math inline">\(\begin{cases} \frac{\mathrm{e}^{tb}-\mathrm{e}^{ta}}{t(b-a)} &amp;\text{for } t \neq 0 \\ 1 &amp;\text{for } t = 0 \end{cases}\)</span></td>
</tr>
<tr class="even">
<td align="left">CF</td>
<td><span class="math inline">\(\frac{\mathrm{e}^{itb}-\mathrm{e}^{ita}}{it(b-a)}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Error function <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Error_Function.svg/600px-Error_Function.svg.png" alt="Plot of the error function" />
<p class="caption">Plot of the error function</p>
</div>
<p>(erf: a sigmoid)</p>
<p>In mathematics, the error function (also called the <strong>Gauss error function</strong>) is a special function (non-elementary) of sigmoid shape that occurs in probability, statistics, and partial differential equations describing diffusion. It is defined as:</p>
<p><span class="math display">\[\operatorname{erf}(x) = \frac{2}{\sqrt\pi}\int_0^x e^{-t^2}\,\mathrm dt.\]</span></p>
<p>The complementary error function, denoted <strong>erfc</strong>, is defined as</p>
<p><span class="math display">\[\begin{align} \operatorname{erfc}(x) &amp; = 1-\operatorname{erf}(x) \\ &amp; =
\frac{2}{\sqrt\pi} \int_x^{\infty} e^{-t^2}\,\mathrm dt \\ &amp; = e^{-x^2}
\operatorname{erfcx}(x), \end{align}\]</span></p>
<p>which also defines <strong>erfcx</strong>, the scaled complementary error function (which can be used instead of erfc to avoid arithmetic underflow). Another form of <span class="math inline">\(\operatorname{erfc}(x)\)</span> is known as Craig&#8217;s formula:</p>
<p><span class="math display">\[\begin{align} \operatorname{erfc}(x) &amp; = \frac{2}{\pi} \int_0^{\pi/2}
\exp \left( - \frac{x^2}{\sin^2 \theta} \right) d\theta. \end{align}\]</span></p>
<p>The error function is related to the cumulative distribution , the integral of the standard normal distribution, by</p>
<p><span class="math display">\[\Phi (x) = \frac{1}{2}+ \frac{1}{2} \operatorname{erf} \left(x/
\sqrt{2}\right) = \frac{1}{2} \operatorname{erfc} \left(-x/
\sqrt{2}\right).\]</span></p>
</dd>
<dt>Q-function <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Q-function.png/600px-Q-function.png" alt="A plot of the Q-function." />
<p class="caption">A plot of the Q-function.</p>
</div>
<p>In statistics, the Q-function is the tail probability of the standard normal distribution (x). In other words, Q(x) is the probability that a normal (Gaussian) random variable will obtain a value larger than x standard deviations above the mean.</p>
<p>If the underlying random variable is y, then the proper argument to the tail probability is derived as:</p>
<p><span class="math display">\[x=\frac{y - \mu}{\sigma}\]</span></p>
<p>which expresses <strong>the number of standard deviations away from the mean</strong>.</p>
<p>Because of its relation to the cumulative distribution function of the normal distribution, the Q-function can also be expressed in terms of the error function, which is an important function in applied mathematics and physics.</p>
<p>Formally, the Q-function is defined as</p>
<p><span class="math display">\[Q(x) = \frac{1}{\sqrt{2\pi}} \int_x^\infty \exp\left(-\frac{u^2}{2}\right) \, du.\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[Q(x) = 1 - Q(-x) = 1 - \Phi(x)\,\!,\]</span></p>
<p>where <span class="math inline">\(\Phi(x)\)</span> is the cumulative distribution function of the normal Gaussian distribution.</p>
</dd>
<dt>Normal distribution <code class="fold">@</code></dt>
<dd><p>(also, Z distribution)</p>
<p>The probability density of the normal distribution is:</p>
<p><span class="math display">\[f(x \; | \; \mu, \sigma^2) = \frac{1}{\sigma\sqrt{2\pi} } \; e^{ -\frac{(x-\mu)^2}{2\sigma^2} }\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is mean or expectation of the distribution (and also its median and mode).</li>
<li><span class="math inline">\(\sigma\)</span> is standard deviation</li>
<li><span class="math inline">\(\sigma^2\)</span> is variance</li>
</ul>
<p>pdf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Normal_Distribution_PDF.svg/525px-Normal_Distribution_PDF.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Normal_Distribution_CDF.svg/525px-Normal_Distribution_CDF.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Notation</td>
<td align="left"><span class="math inline">\(\mathcal{N}(\mu,\,\sigma^2)\)</span></td>
</tr>
<tr class="even">
<td align="left">Parameters</td>
<td align="left">&#956; &#8712; R &#8212; mean (location), &#963;2 &gt; 0 &#8212; variance (squared scale)</td>
</tr>
<tr class="odd">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(x &#8712; R\)</span></td>
</tr>
<tr class="even">
<td align="left">PDF</td>
<td align="left"><span class="math inline">\(\frac{1}{\sigma\sqrt{2\pi}}\, e^{-\frac{(x - \mu)^2}{2 \sigma^2}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\frac12\left[1 + \operatorname{erf}\left( \frac{x-\mu}{\sigma\sqrt{2}}\right)\right]\)</span></td>
</tr>
<tr class="even">
<td align="left">Quantile</td>
<td align="left"><span class="math inline">\(\mu+\sigma\sqrt{2}\,\operatorname{erf}^{-1}(2F-1)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left">&#956;</td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td align="left">&#956;</td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td align="left">&#956;</td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\sigma^2\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">Ex. kurtosis</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\tfrac12 \ln(2\pi\,e\,\sigma^2)\)</span></td>
</tr>
<tr class="even">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\(\exp\{ \mu t + \frac{1}{2}\sigma^2t^2 \}\)</span></td>
</tr>
<tr class="odd">
<td align="left">CF</td>
<td align="left"><span class="math inline">\(\exp \{ i\mu t - \frac{1}{2}\sigma^2 t^2 \}\)</span></td>
</tr>
<tr class="even">
<td align="left">Fisher information</td>
<td align="left"><span class="math inline">\(\begin{pmatrix}1/\sigma^2&amp;0\\0&amp;1/(2\sigma^4)\end{pmatrix}\)</span></td>
</tr>
</tbody>
</table>
<dl>
<dt>Standard normal distribution</dt>
<dd><p><span class="math display">\[\phi(x) = \frac{e^{- \frac{\scriptscriptstyle 1}{\scriptscriptstyle 2} x^2}}{\sqrt{2\pi}}\,\]</span></p>
</dd>
<dt>Standard deviation and tolerance intervals <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Empirical_Rule.PNG/525px-Empirical_Rule.PNG" alt="For the normal distribution, the values less than one standard deviation away from the mean account for 68.27% of the set; while two standard deviations from the mean account for 95.45%; and three standard deviations account for 99.73%." />
<p class="caption">For the normal distribution, the values less than one standard deviation away from the mean account for 68.27% of the set; while two standard deviations from the mean account for 95.45%; and three standard deviations account for 99.73%.</p>
</div>
<p>the probability that a normal deviate lies in the range &#956; &#8722; n&#963; and &#956; + n&#963; is given by</p>
<p><span class="math display">\[F(\mu+n\sigma) - F(\mu-n\sigma) = \Phi(n)-\Phi(-n) = \mathrm{erf}\left(\frac{n}{\sqrt{2}}\right),\]</span></p>
</dd>
<dt>Cumulative distribution function <code class="fold">@</code></dt>
<dd><p>The cumulative distribution function (CDF) of the standard normal distribution, usually denoted with the capital Greek letter (phi), is the integral</p>
<p><span class="math display">\[\Phi(x)\; = \;\frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-t^2/2} \, dt\]</span></p>
<p>In statistics one often uses the related error function, or <strong>erf(x)</strong>, defined as the probability of a random variable with normal distribution of mean 0 and variance 1/2 falling in the range [-x, x]; that is</p>
<p><span class="math display">\[\operatorname{erf}(x)\; =\; \frac{1}{\sqrt{\pi}} \int_{-x}^x e^{-t^2} \, dt\]</span></p>
<p>These integrals cannot be expressed in terms of elementary functions, and are often said to be special functions. However, many numerical approximations are known; see below.</p>
<p>&#27491;&#22826;&#20998;&#24067;&#30340; CDF &#21644; erf &#24456;&#20687;&#12290;&#28385;&#36275;&#22914;&#19979;&#20851;&#31995;&#12290;</p>
<p>The two functions are closely related, namely</p>
<p><span class="math display">\[\Phi(x)\; =\; \frac12\left[1 + \operatorname{erf}\left(\frac{x}{\sqrt{2}}\right)\right]\]</span></p>
<p>For a generic normal distribution f with mean &#956; and deviation &#963;, the cumulative distribution function is</p>
<p><span class="math display">\[F(x)\;=\;\Phi\left(\frac{x-\mu}{\sigma}\right)\;=\; \frac12\left[1 +
\operatorname{erf}\left(\frac{x-\mu}{\sigma\sqrt{2}}\right)\right]\]</span></p>
</dd>
<dt>Standard score <code class="fold">@</code></dt>
<dd><p>Z-&#20998;&#25968;&#65292;&#25152;&#20197;&#27491;&#22826;&#20998;&#24067;&#20063;&#21483; z &#20998;&#24067;&#12290;&#26631;&#20934;&#20998;&#24067;&#65292;&#22312;&#32771;&#35797;&#27979;&#39564;&#35780;&#20998;&#37324;&#24120;&#29992;&#12290;</p>
<p>Standard scores are also called z-values, z-scores, normal scores, and standardized variables; the use of &#8220;Z&#8221; is because the normal distribution is also known as the &#8220;Z distribution&#8221;. They are most frequently used to compare a sample to a standard normal deviate, though they can be defined without assumptions of normality.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Normal_distribution_and_scales.gif/525px-Normal_distribution_and_scales.gif" alt="Compares the various grading methods in a normal distribution. Includes: Standard deviations, cumulative percentages, percentile equivalents, Z-scores, T-scores, standard nine, percent in stanine" />
<p class="caption">Compares the various grading methods in a normal distribution. Includes: Standard deviations, cumulative percentages, percentile equivalents, Z-scores, T-scores, standard nine, percent in stanine</p>
</div>
<p>The standard score of a raw score x is</p>
<p><span class="math display">\[z = {x- \mu \over \sigma}\]</span></p>
<p>In mathematical statistics, a random variable X is standardized by subtracting its expected value <span class="math inline">\(\operatorname{E}[X]\)</span> and dividing the difference by its standard deviation <span class="math inline">\(\sigma(X) = \sqrt{\operatorname{Var}(X)}\)</span>:</p>
<p><span class="math display">\[Z = {X - \operatorname{E}[X] \over \sigma(X)}\]</span></p>
<dl>
<dt>Stanine</dt>
<dd><p>&#26631;&#20934;&#20061;&#12290;</p>
<p>Stanine (STAndard NINE) is a method of scaling test scores on a nine-point standard scale with a mean of five and a standard deviation of two.</p>
<p>Calculating Stanines</p>
<table>
<tbody>
<tr class="odd">
<td align="left">Result Ranking</td>
<td align="left">4%</td>
<td align="left">7%</td>
<td align="left">12%</td>
<td align="left">17%</td>
<td align="center">20%</td>
<td align="center">17%</td>
<td align="left">12%</td>
<td align="left">7%</td>
<td align="center">4%</td>
</tr>
<tr class="even">
<td align="left">Stanine</td>
<td align="left">1</td>
<td align="left">2</td>
<td align="left">3</td>
<td align="left">4</td>
<td align="center">5</td>
<td align="center">6</td>
<td align="left">7</td>
<td align="left">8</td>
<td align="center">9</td>
</tr>
<tr class="odd">
<td align="left">Standard score</td>
<td align="left">below -1.75</td>
<td align="left">-1.75 to -1.25</td>
<td align="left">-1.25 to -.75</td>
<td align="left">-.75 to -.25</td>
<td align="center">-.25 to +.25</td>
<td align="center">+.25 to +.75</td>
<td align="left">+.75 to +1.25</td>
<td align="left">+1.25 to +1.75</td>
<td align="center">above +1.75</td>
</tr>
<tr class="even">
<td align="left">Wechsler scale score</td>
<td align="left">below 74</td>
<td align="left">74 to 81</td>
<td align="left">81 to 89</td>
<td align="left">89 to 96</td>
<td align="center">96 to 104</td>
<td align="center">104 to 111</td>
<td align="left">111 to 119</td>
<td align="left">119 to 126</td>
<td align="center">above 126</td>
</tr>
</tbody>
</table>
<p>Today stanines are mostly used in educational assessment.</p>
</dd>
</dl>
</dd>
<dt>t-statistic <code class="fold">@</code></dt>
<dd><p>notional, <code>['no&#650;&#643;&#601;n(&#601;)l]</code> adj.&#29468;&#27979;&#30340;&#65307;&#20272;&#35745;&#30340;&#65307;&#29702;&#35770;&#19978;&#30340;&#65307;&#24819;&#35937;&#30340;</p>
<p>&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#12290;</p>
<p>In statistics, the t-statistic is a ratio of the <strong>departure of an estimated parameter from its notional value</strong> and its standard error. It is used in <strong>hypothesis testing</strong>, for example in the Student&#8217;s t-test, in the augmented Dickey&#8211;Fuller test, and in bootstrapping.</p>
<p>Let <span class="math inline">\(\scriptstyle\hat\beta\)</span> be an estimator of parameter &#946; in some statistical model. Then a t-statistic for this parameter is any quantity of the form</p>
<p><span class="math display">\[t_{\hat{\beta}} = \frac{\hat\beta - \beta_0}{\mathrm{s.e.}(\hat\beta)}\]</span></p>
<p>where &#946;0 is a non-random, known constant, and <span class="math inline">\(\scriptstyle s.e.(\hat\beta)\)</span> is the standard error of the estimator <span class="math inline">\(\scriptstyle\hat\beta\)</span>. By default, statistical packages report t-statistic with &#946;0 = 0 (these t-statistics are used to test the significance of corresponding regressor). However, when t-statistic is needed to test the hypothesis of the form H0: &#946; = &#946;0, then a non-zero &#946;0 may be used.</p>
<p>If <span class="math inline">\(\scriptstyle\hat\beta\)</span> is an ordinary least squares estimator in the classical linear regression model (that is, with normally distributed and homoskedastic error terms), and if the true value of parameter &#946; is equal to &#946;0, then <strong>the sampling distribution of the t-statistic is the Student&#8217;s t-distribution with (n &#8722; k) degrees of freedom</strong>, where n is the number of observations, and k is the number of regressors (including the intercept).</p>
<p>In the majority of models the estimator is consistent for &#946; and distributed asymptotically normally. If the true value of parameter &#946; is equal to &#946;0 and the quantity <span class="math inline">\(\scriptstyle s.e.(\hat\beta)\)</span> correctly estimates the asymptotic variance of this estimator, then the t-statistic will have asymptotically the standard normal distribution.</p>
<p>In some models the distribution of t-statistic is different from normal, even asymptotically. For example, when a time series with unit root is regressed in the augmented Dickey&#8211;Fuller test, the test t-statistic will asymptotically have one of the Dickey&#8211;Fuller distributions (depending on the test setting).</p>
</dd>
</dl>
</dd>
<dt>Exponential distribution <code class="fold">@</code></dt>
<dd><dl>
<dt>Story <code class="fold">@</code></dt>
<dd><p>You&#8217;re sitting on an open meadow right before the break of dawn, wishing that airplanes in the night sky were shooting stars, because you could really use a wish right now. You know that shooting stars come on average every 15 minutes, but a shooting star is not &#8220;due&#8221; to come just because you&#8217;ve waited so long. Your waiting time is <strong>memoryless</strong>; the additional time until the next shooting star comes does not depend on how long you&#8217;ve waited already.</p>
<p><strong>Example</strong> The waiting time until the next shooting star is distributed Expo(4) hours. Here &#955; = 4 is the rate parameter, since shooting stars arrive at a rate of 1 per 1/4 hour on average. The expected time until the next shooting star is 1/&#955; = 1/4 hour.</p>
<p>Expo(&#955;)&#65292;&#955; &#26159;&#21333;&#20301;&#26102;&#38388;&#27969;&#26143;&#30340;&#20010;&#25968;&#65292;1/&#955; &#26159;&#20320;&#31561;&#21040;&#19979;&#19968;&#20010;&#27969;&#26143;&#38656;&#35201;&#31561;&#24453;&#30340;&#26102;&#38388;&#65288;&#30340;&#26399;&#26395;&#65289;&#12290;</p>
</dd>
</dl>
<p>The exponential distribution (a.k.a. negative exponential distribution) is the probability distribution that describes the time between events in a Poisson process, i.e.&#160;a process in which events occur continuously and independently at a constant average rate. It is a particular case of the gamma distribution. It is the continuous analogue of the geometric distribution, and it has the key property of being <strong>memoryless</strong>. In addition to being used for the analysis of Poisson processes, it is found in various other contexts.</p>
<p>The exponential distribution is not the same as the class of exponential families of distributions, which is a large class of probability distributions that includes the exponential distribution as one of its members, but also includes the normal distribution, binomial distribution, gamma distribution, Poisson, and many others.</p>
<p>pdf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Exponential_pdf.svg/488px-Exponential_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/Exponential_cdf.svg/488px-Exponential_cdf.svg.png" style="width:45.0%" /></p>
<p>The probability density function (pdf) of an exponential distribution is</p>
<p><span class="math display">\[
    f(x;\lambda) = \begin{cases} \lambda e^{-\lambda x} &amp; x \ge 0, \\ 0 &amp; x &lt; 0. \end{cases}
\]</span></p>
<p>Alternatively, this can be defined using the right-continuous Heaviside step function, H(x) where H(0)=1:</p>
<p><span class="math display">\[
    f(x;\lambda) = \mathrm \lambda e^{-\lambda x} H(x)
\]</span></p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Heaviside_step_function">Heaviside step function - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>The Heaviside (<code>[&#712;hevisaid]</code>) step function, or the unit step function, usually denoted by &#952; (but sometimes u or &#120793;), is a discontinuous function whose value is zero for negative argument and one for positive argument. It is an example of the general class of step functions, all of which can be represented as linear combinations of translations of this one.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Dirac_distribution_CDF.svg/488px-Dirac_distribution_CDF.svg.png" alt="The Heaviside step function, using the half-maximum convention" />
<p class="caption">The Heaviside step function, using the half-maximum convention</p>
</div>
<p>The simplest definition of the Heaviside function is as the derivative of the ramp function:</p>
<p><span class="math display">\[H(x) := \frac{d}{dx} \max \{ x, 0 \}\]</span></p>
<p>The Heaviside function can also be defined as the integral of the Dirac delta function: H&#8242; = &#948;. This is sometimes written as</p>
<p><span class="math display">\[H(x) := \int_{-\infty}^x { \delta(s)} \, \mathrm{d}s\]</span></p>
</dd>
</dl>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td>&#955; &gt; 0 rate, or inverse scale</td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td><span class="math inline">\(x &#8712; [0, &#8734;)\)</span></td>
</tr>
<tr class="odd">
<td align="left">PDF</td>
<td><span class="math inline">\(&#955;&#8201;e&#8722;&#955;x\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td><span class="math inline">\(1 &#8722; e&#8722;&#955;x\)</span></td>
</tr>
<tr class="odd">
<td align="left">Quantile</td>
<td><span class="math inline">\(-ln(1-F)/&#955;\)</span></td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td><span class="math inline">\(&#955;&#8722;1 (=&#946;)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td><span class="math inline">\(&#955;&#8722;1&#8201;ln(2)\)</span></td>
</tr>
<tr class="even">
<td align="left">Mode</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td><span class="math inline">\(&#955;&#8722;2 (=&#946;2)\)</span></td>
</tr>
<tr class="even">
<td align="left">Skewness</td>
<td>2</td>
</tr>
<tr class="odd">
<td align="left">Ex. kurtosis</td>
<td>6</td>
</tr>
<tr class="even">
<td align="left">Entropy</td>
<td><span class="math inline">\(log(e/&#955;)\)</span></td>
</tr>
<tr class="odd">
<td align="left">MGF</td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-t}, \text{ for } t &lt; \lambda\)</span></td>
</tr>
<tr class="even">
<td align="left">CF</td>
<td><span class="math inline">\(\frac{\lambda}{\lambda-it}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Fisher information</td>
<td>$^{-2} $</td>
</tr>
</tbody>
</table>
</dd>
<dt>Gamma distribution <code class="fold">@</code></dt>
<dd><dl>
<dt>Story <code class="fold">@</code></dt>
<dd><p>You sit waiting for shooting stars, where the waiting time for a star is distributed Expo(&#955;). You want to see n shooting stars before you go home. The total waiting time for the nth shooting star is Gamma(n,&#955;).</p>
<p>Example You are at a bank, and there are 3 people ahead of you. The serving time for each person is Exponential with mean 2 minutes. Only one person at a time can be served. The distribution of your waiting time until it&#8217;s your turn to be served is Gamma(3, 1/2 ).</p>
<p>&#36824;&#26159;&#31561;&#27969;&#26143;&#65292;Expo(&#955;)&#65292;&#24847;&#24605;&#26159;&#21333;&#20301;&#26102;&#38388;&#21487;&#20197;&#26377; &#955; &#20010;&#27969;&#26143;&#65292;1/&#955; &#30340;&#26102;&#38388;&#39044;&#26399;&#21487;&#20197;&#31561;&#21040;&#19968;&#20010;&#12290;&#20320;&#24819;&#30475;&#21040; n &#20010;&#27969;&#26143;&#20877;&#22238;&#23478;&#65292;&#37027;&#20040;&#20320;&#30340;&#31561;&#24453;&#26102;&#38388;&#28385;&#36275; Gamma(n,&#955;) &#20998;&#24067;&#12290;&#25490;&#38431;&#20063;&#26159;&#19968;&#26679;&#30340;&#12290;</p>
<p>&#65288;&#20294;&#26159;&#24863;&#35273;&#36825;&#20004;&#31181;&#19981;&#22826;&#19968;&#26679;&#65292;&#22240;&#20026;&#27969;&#26143;&#20043;&#38388;&#26159;&#26080;&#20851;&#30340;&#65292;&#32780;&#25490;&#38431;&#30340;&#20154;&#26159;&#26377;&#24207;&#30340;&#12290;&#65289;</p>
</dd>
</dl>
<p>In probability theory and statistics, the gamma distribution is a two-parameter family of continuous probability distributions. <strong>The common exponential distribution and chi-squared distribution are special cases of the gamma distribution.</strong> There are three different parametrizations in common use:</p>
<ul>
<li>With a <strong>shape</strong> parameter k and a <strong>scale</strong> parameter &#952;.</li>
<li>With a shape parameter &#945; = k and an inverse scale parameter &#946; = 1/&#952;, called a rate parameter.</li>
<li>With a shape parameter k and a mean parameter &#956; = k/&#946;.</li>
</ul>
<p>pdf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e6/Gamma_distribution_pdf.svg/488px-Gamma_distribution_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Gamma_distribution_cdf.svg/488px-Gamma_distribution_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td align="left">k &gt; 0 shape, &#952; &gt; 0 scale</td>
<td align="left">&#945; &gt; 0 shape, &#946; &gt; 0 rate</td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(\scriptstyle x \;\in\; (0,\, \infty)\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle x \;\in\; (0,\, \infty)\)</span></td>
</tr>
<tr class="odd">
<td align="left">pdf</td>
<td align="left"><span class="math inline">\(\frac{1}{\Gamma(k) \theta^k} x^{k \,-\, 1} e^{-\frac{x}{\theta}}\)</span></td>
<td align="left"><span class="math inline">\(\frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha \,-\, 1} e^{- \beta x }\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\frac{1}{\Gamma(k)} \gamma\left(k,\, \frac{x}{\theta}\right)\)</span></td>
<td align="left"><span class="math inline">\(\frac{1}{\Gamma(\alpha)} \gamma(\alpha,\, \beta x)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\scriptstyle \mathbf{E}[ X] = k \theta\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle\mathbf{E}[ X] = \frac{\alpha}{\beta}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"><span class="math inline">\(\scriptstyle \mathbf{E}[\ln X] = \psi(k) +\ln(\theta)\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle \mathbf{E}[\ln X] = \psi(\alpha) -\ln(\beta)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td align="left">No simple closed form</td>
<td align="left">No simple closed form</td>
</tr>
<tr class="even">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\scriptstyle (k \,-\, 1)\theta \text{ for } k \;{\geq}\; 1\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle \frac{\alpha \,-\, 1}{\beta} \text{ for } \alpha \;{\geq}\; 1\)</span></td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\scriptstyle\operatorname{Var}[ X] = k \theta^2\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle \operatorname{Var}[ X] = \frac{\alpha}{\beta^2}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left"><span class="math inline">\(\scriptstyle\operatorname{Var}[\ln X] = \psi_1(k)\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle\operatorname{Var}[\ln X] = \psi_1(\alpha)\)</span></td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\scriptstyle \frac{2}{\sqrt{k}}\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle \frac{2}{\sqrt{\alpha}}\)</span></td>
</tr>
<tr class="even">
<td align="left">Excess kurtosis</td>
<td align="left"><span class="math inline">\(\scriptstyle \frac{6}{k}\)</span></td>
<td align="left"><span class="math inline">\(\scriptstyle \frac{6}{\alpha}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Beta distribution <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the beta distribution is a family of continuous probability distributions defined on the interval <code>[0, 1]</code> parametrized by two positive shape parameters, denoted by &#945; and &#946;, that appear as exponents of the random variable and control the shape of the distribution.</p>
<p>The beta distribution has been applied to model the behavior of random variables limited to intervals of finite length in a wide variety of disciplines. For example, it has been used as a statistical description of allele frequencies in population genetics; time allocation in project management / control systems; sunshine data; variability of soil properties; proportions of the minerals in rocks in stratigraphy; and heterogeneity in the probability of HIV transmission.</p>
<p>In Bayesian inference, the beta distribution is the conjugate prior probability distribution for the Bernoulli, binomial, negative binomial and geometric distributions. For example, the beta distribution can be used in Bayesian analysis to describe initial knowledge concerning probability of success such as the probability that a space vehicle will successfully complete a specified mission. The beta distribution is a suitable model for the random behavior of percentages and proportions.</p>
<p>The usual formulation of the beta distribution is also known as the beta distribution of the first kind, whereas beta distribution of the second kind is an alternative name for the beta prime distribution.</p>
<p>pdf &amp; CDF</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Beta_distribution_pdf.svg/488px-Beta_distribution_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Beta_distribution_cdf.svg/488px-Beta_distribution_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Notation</td>
<td align="left">Beta(&#945;, &#946;)</td>
</tr>
<tr class="even">
<td align="left">Parameters</td>
<td align="left">&#945; &gt; 0 shape (real), &#946; &gt; 0 shape (real)</td>
</tr>
<tr class="odd">
<td align="left">Support</td>
<td align="left"><span class="math inline">\(x \in (0, 1)\!\)</span></td>
</tr>
<tr class="even">
<td align="left">PDF</td>
<td align="left"><span class="math inline">\(\frac{x^{\alpha-1}(1-x)^{\beta-1}} {\operatorname{Beta}(\alpha,\beta)}\!\)</span> where <span class="math inline">\(\operatorname{Beta}(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}\)</span></td>
</tr>
<tr class="odd">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(I_x(\alpha,\beta)\!\)</span></td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="left"><span class="math inline">\(\operatorname{E}[X] = \frac{\alpha}{\alpha+\beta}\!\)</span>, <span class="math inline">\(\operatorname{E}[\ln X] = \psi(\alpha) - \psi(\alpha + \beta)\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\begin{matrix}I_{\frac{1}{2}}^{[-1]}(\alpha,\beta)\text{ (in general) }\\[0.5em] \approx \frac{ \alpha - \tfrac{1}{3} }{ \alpha + \beta - \tfrac{2}{3} }\text{ for }\alpha, \beta &gt;1\end{matrix}\)</span></td>
</tr>
<tr class="even">
<td align="left">Mode</td>
<td align="left"><span class="math inline">\(\frac{\alpha-1}{\alpha+\beta-2}\!\)</span> for &#945;, &#946; &gt;1</td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td align="left"><span class="math inline">\(\operatorname{var}[X] = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\!\)</span>, <span class="math inline">\(\operatorname{var}[\ln X] = \psi_1(\alpha) - \psi_1(\alpha + \beta)\!\)</span></td>
</tr>
<tr class="even">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\frac{2\,(\beta-\alpha)\sqrt{\alpha+\beta+1}}{(\alpha+\beta+2)\sqrt{\alpha\beta}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Ex. kurtosis</td>
<td align="left"><span class="math inline">\(\frac{6[(\alpha - \beta)^2 (\alpha +\beta + 1) - \alpha \beta (\alpha + \beta + 2)]}{\alpha \beta (\alpha + \beta + 2) (\alpha + \beta + 3)}\)</span></td>
</tr>
<tr class="even">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\begin{matrix}\ln\operatorname{Beta}(\alpha,\beta)-(\alpha-1)\psi(\alpha)-(\beta-1)\psi(\beta)\\[0.5em] +(\alpha+\beta-2)\psi(\alpha+\beta)\end{matrix}\)</span></td>
</tr>
<tr class="odd">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\(1 +\sum_{k=1}^{\infty} \left( \prod_{r=0}^{k-1} \frac{\alpha+r}{\alpha+\beta+r} \right) \frac{t^k}{k!}\)</span></td>
</tr>
<tr class="even">
<td align="left">CF</td>
<td align="left"><span class="math inline">\({}_1F_1(\alpha; \alpha+\beta; i\,t)\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Fisher information</td>
<td align="left"><span class="math inline">\(\begin{matrix}\\ \operatorname{var}[\ln X] &amp;\operatorname{cov}[\ln X, \ln(1-X)] \\ \operatorname{cov}[\ln X, \ln(1-X)] &amp; \operatorname{var}[\ln (1-X)]\end{matrix}\)</span></td>
</tr>
</tbody>
</table>
</dd>
<dt>Tolerance interval <code class="fold">@</code></dt>
<dd><p>A tolerance interval is a statistical interval within which, with some confidence level, a specified proportion of a sampled population falls.</p>
<p>&#8220;More speci&#64257;cally, a <strong>100&#215;p%/100&#215;(1&#8722;&#945;) tolerance interval</strong> provides limits within which at least a certain proportion (p) of the population falls with a given level of confidence (1&#8722;&#945;).&#8221;</p>
<p>&#8220;A (p, 1&#8722;&#945;) tolerance interval (TI) based on a sample is constructed so that it would include at least a proportion p of the sampled population with confidence 1&#8722;&#945;; such a TI is usually referred to as p-content &#8722;(1&#8722;&#945;) coverage TI.&#8221;</p>
<p>&#8220;A (p, 1&#8722;&#945;) upper tolerance limit (TL) is simply an 1&#8722;&#945;upper confidence limit for the 100 p percentile of the population.&#8221;</p>
<p>A tolerance interval can be seen as a statistical version of a probability interval. &#8220;In the parameters-known case, a 95% tolerance interval and a 95% prediction interval are the same.&#8221; If we knew a population&#8217;s exact parameters, we would be able to compute a range within which a certain proportion of the population falls. For example, if we know a population is normally distributed with mean and standard deviation , then the interval 1.96includes 95% of the population (1.96 is the z-score for 95% coverage of a normally distributed population).</p>
</dd>
<dt>Gamma function <code class="fold">@</code></dt>
<dd><p>In mathematics, the gamma function (represented by the capital Greek letter &#915;) is an extension of the factorial function, with its argument shifted down by 1, to real and complex numbers. That is, if n is a positive integer:</p>
<p><span class="math display">\[\Gamma(n) = (n-1)!.\]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Gamma_plot.svg/488px-Gamma_plot.svg.png" />

</div>
<p>The gamma function is defined for all complex numbers except the non-positive integers. For complex numbers with a positive real part, it is defined via a convergent improper integral:</p>
<p><span class="math display">\[\Gamma(t) = \int_0^\infty x^{t-1} e^{-x}\,dx.\]</span></p>
<p>This integral function is extended by analytic continuation to all complex numbers except the non-positive integers (where the function has simple poles), yielding the meromorphic (<code>[,mer&#601;'m&#596;&#720;f&#618;k]</code>, &#20122;&#32431;&#30340;) function we call the gamma function. In fact the gamma function corresponds to the Mellin transform of the negative exponential function:</p>
<p><span class="math display">\[\Gamma(t) = \{ \mathcal M e^{-x} \} (t).\]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Gamma_abs_3D.png/330px-Gamma_abs_3D.png" alt="The gamma function is meromorphic in the whole complex plane." />
<p class="caption">The gamma function is meromorphic in the whole complex plane.</p>
</div>
<p>The gamma function is a component in various probability-distribution functions, and as such it is applicable in the fields of probability and statistics, as well as combinatorics.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Factorial_Interpolation.svg/375px-Factorial_Interpolation.svg.png" alt="It is easy graphically to interpolate the factorial function to non-integer values, but is there a formula that describes the resulting curve?" />
<p class="caption">It is easy graphically to interpolate the factorial function to non-integer values, but is there a formula that describes the resulting curve?</p>
</div>
<p>Properties</p>
<ul>
<li><span class="math inline">\(\Gamma(t+1)=t \Gamma(t)\,\)</span>, &#915;(t) = &#915;(t + 1)/t, <span class="math inline">\(\Gamma(t)=\frac{\Gamma(t+n)}{t(t+1)\cdots(t+n-1)},\)</span></li>
<li><span class="math inline">\(\Gamma(n) = 1 \cdot 2 \cdot 3 \cdots (n-1) = (n-1)!\,\)</span></li>
<li><span class="math inline">\(\Gamma\left(\tfrac{1}{2}\right)=\sqrt{\pi},\)</span></li>
<li><span class="math inline">\(\Gamma\left(\tfrac{1}{2}+n\right) = {(2n)! \over 4^n n!} \sqrt{\pi} = \frac{(2n-1)!!}{2^n} \sqrt{\pi} = \sqrt{\pi} \left[ {n-\frac{1}{2}\choose n} n! \right]\)</span></li>
<li><span class="math inline">\(\Gamma\left(\tfrac{1}{2}-n\right) = {(-4)^n n! \over (2n)!} \sqrt{\pi} = \frac{(-2)^n}{(2n-1)!!} \sqrt{\pi} = \frac{\sqrt{\pi}}{{-\frac{1}{2} \choose n} n!}\)</span></li>
</ul>
<dl>
<dt>Pi function</dt>
<dd><p>An alternative notation which was originally introduced by Gauss and which was sometimes used is the pi function, which in terms of the gamma function is</p>
<p><span class="math display">\[\Pi(z) = \Gamma(z+1) = z \Gamma(z) = \int_0^\infty e^{-t} t^z\, dt,\]</span></p>
</dd>
</dl>
<p>For Re(x) &gt; 0 the nth derivative of the gamma function is:</p>
<p><span class="math display">\[\frac{{\rm d}^n}{{\rm d}x^n}\,\Gamma(x) = \int_0^\infty t^{x-1} e^{-t} (\ln t)^{n} dt.\]</span></p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Stirling%27s_approximation">Stirling&#8217;s formula</a></dt>
<dd><p>Asymptotically (&#36880;&#28176;&#22320;) as t &#8594; &#8734;, the magnitude of the gamma function is given by <strong>Stirling&#8217;s formula</strong></p>
<p><span class="math display">\[\Gamma(t+1)\sim\sqrt{2\pi t}\left(\frac{t}{e}\right)^{t},\]</span></p>
<p>where the symbol <code>~</code> means that the quotient of both sides converges to 1.</p>
</dd>
<dt>Euler&#8217;s <a href="https://en.wikipedia.org/wiki/Reflection_formula">reflection formula</a></dt>
<dd><p><span class="math display">\[\Gamma(1-z) \Gamma(z) = {\pi \over \sin{(\pi z)}}, \qquad z \not\in \mathbf Z\]</span></p>
</dd>
<dt>Duplication formula</dt>
<dd><p><span class="math display">\[\Gamma(z) \Gamma\left(z + \tfrac{1}{2}\right) = 2^{1-2z} \; \sqrt{\pi} \; \Gamma(2z).\]</span></p>
<p>The duplication formula is a special case of the <a href="https://en.wikipedia.org/wiki/Multiplication_theorem">multiplication theorem</a></p>
<p><span class="math display">\[\prod_{k=0}^{m-1}\Gamma\left(z + \frac{k}{m}\right) = (2 \pi)^{\frac{m-1}{2}} \; m^{\frac{1}{2} - mz} \; \Gamma(mz).\]</span></p>
</dd>
<dt>Meromorphic function</dt>
<dd><p>In the mathematical field of complex analysis, a meromorphic function on an open subset D of the complex plane is a function that is holomorphic on all D except a set of isolated points (the poles of the function), at each of which the function must have a Laurent series. <strong>This terminology comes from the Ancient Greek meros (&#956;&#941;&#961;&#959;&#962;), meaning part, as opposed to holos (&#8005;&#955;&#959;&#962;), meaning whole.</strong></p>
</dd>
<dt>Mellin transform</dt>
<dd><p>In mathematics, the Mellin transform is an integral transform that may be regarded as the multiplicative version of the two-sided Laplace transform. This integral transform is closely connected to the theory of Dirichlet series, and is often used in number theory, mathematical statistics, and the theory of asymptotic expansions; it is closely related to the Laplace transform and the Fourier transform, and the theory of the gamma function and allied special functions.</p>
<p>The Mellin transform of a function f is</p>
<p><span class="math display">\[\left\{\mathcal{M}f\right\}(s) = \varphi(s)=\int_0^{\infty} x^{s-1} f(x)dx.\]</span></p>
<p>The inverse transform is</p>
<p><span class="math display">\[\left\{\mathcal{M}^{-1}\varphi\right\}(x) = f(x)=\frac{1}{2 \pi i} \int_{c-i \infty}^{c+i \infty} x^{-s} \varphi(s)\, ds.\]</span></p>
<p>refs and see also</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Mellin_transform">Mellin transform - Wikipedia, the free encyclopedia</a></li>
</ul>
</dd>
</dl>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Gamma_function">Gamma function - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Digamma function <code class="fold">@</code></dt>
<dd><p>&#36825;&#20010;&#23450;&#20041;&#21644;&#36825;&#20010;&#24076;&#33098;&#23383;&#27597;&#20063;&#22826;&#36148;&#20999;&#20102;&#8230;&#8230;</p>
<p>In mathematics, the digamma function is defined as the <strong>logarithmic derivative of the gamma function</strong>:</p>
<p><span class="math display">\[\psi(x)=\frac{d}{dx}\ln\Big(\Gamma(x)\Big)=\frac{\Gamma&#39;(x)}{\Gamma(x)}.\]</span></p>
<p>It is the first of the polygamma functions.</p>
<p>The digamma function is often denoted as &#968;0(x), &#968;0(x) or <span class="math inline">\(\digamma\)</span> (after the archaic Greek letter &#988; digamma).</p>
<p>Psi (uppercase &#936;, lowercase &#968;; Greek: &#936;&#953; Psi)</p>
<dl>
<dt>Relation to harmonic numbers <code class="fold">@</code></dt>
<dd><p>The gamma function obeys the equation</p>
<p><span class="math display">\[\Gamma(z+1)=z\Gamma(z).\]</span></p>
<p>Taking the derivative with respect to z gives:</p>
<p><span class="math display">\[\Gamma&#39;(z+1)=z\Gamma&#39;(z)+\Gamma(z)\]</span></p>
<p>Dividing by &#915;(z+1) or the equivalent z&#915;(z) gives:</p>
<p><span class="math display">\[\frac{\Gamma&#39;(z+1)}{\Gamma(z+1)}=\frac{\Gamma&#39;(z)}{\Gamma(z)}+\frac 1z\]</span></p>
<p>or:</p>
<p><span class="math display">\[\psi(z+1)=\psi(z)+\frac 1z\]</span></p>
<p>Since the harmonic numbers are defined as</p>
<p><span class="math display">\[H_n=\sum_{k=1}^n\frac 1k\]</span></p>
<p>the digamma function is related to it by:</p>
<p><span class="math display">\[\psi(n)=H_{n-1}-\gamma\]</span></p>
<p>where <span class="math inline">\(H_n\)</span> is the n-th harmonic number, and &#947; is the Euler-Mascheroni constant. For half-integer values, it may be expressed as</p>
<p><span class="math display">\[\psi\left(n+{\frac{1}{2}}\right)=-\gamma-2\ln(2)+\sum_{k=1}^n \frac{2}{2k-1}\]</span></p>
<dl>
<dt>Euler&#8211;Mascheroni constant <code class="fold">@</code></dt>
<dd><p>The Euler&#8211;Mascheroni constant (also called Euler&#8217;s constant) is a mathematical constant recurring in analysis and number theory, usually denoted by the lowercase Greek letter gamma (&#947;).</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Gamma-area.svg/330px-Gamma-area.svg.png" alt="The area of the blue region converges to the Euler&#8211;Mascheroni constant." />
<p class="caption">The area of the blue region converges to the Euler&#8211;Mascheroni constant.</p>
</div>
<p>It is defined as the limiting difference between the harmonic series and the natural logarithm:</p>
<p><span class="math display">\[\begin{align} \gamma &amp;= \lim_{n\to\infty}\left(-\ln n +
\sum_{k=1}^n \frac1{k}\right)\\ &amp;=\int_1^\infty\left(\frac1{\lfloor
x\rfloor}-\frac1{x}\right)\,dx. \end{align}\]</span></p>
<p>The numerical value of the Euler&#8211;Mascheroni constant, to 50 decimal places, is</p>
<p>0.57721566490153286060651209008240243104215933593992&#8230;.</p>
<dl>
<dt>Regularization</dt>
<dd><p>The Digamma function appears in the regularization of divergent integrals</p>
<p><span class="math display">\[\int_{0}^{\infty} \frac{dx}{x+a},\]</span></p>
<p>this integral can be approximated by a divergent general Harmonic series, but the following value can be attached to the series</p>
<p><span class="math display">\[\sum_{n=0}^{\infty} \frac{1}{n+a}= - \psi (a).\]</span></p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>Integral representations <code class="fold">@</code></dt>
<dd><p>If the real part of x is positive then the digamma function has the following integral representation</p>
<p><span class="math display">\[\psi(x)=\int\limits_0^\infty \left(\frac{e^{-t}}{t}-\frac{e^{-xt}}{1-e^{-t}}\right)dt.\]</span></p>
</dd>
</dl>
</dd>
<dt>Beta function <code class="fold">@</code></dt>
<dd><p>In mathematics, the beta function, also called the Euler integral of the first kind, is a special function defined by</p>
<p><span class="math display">\[{\operatorname{Beta}}(x,y) = \int_0^1t^{x-1}(1-t)^{y-1}\,\mathrm{d}t \!\]</span></p>
<p>for <span class="math inline">\(\textrm{Re}(x), \textrm{Re}(y) &gt; 0.\,\)</span></p>
<p>The beta function was studied by Euler and Legendre and was given its name by Jacques Binet; its symbol &#914; is a Greek capital &#946; rather than the similar Latin capital B.</p>
<p>&#20854;&#23454;&#26159;&#20004;&#20010;&#21442;&#25968;&#25511;&#21046;&#20102;&#24418;&#29366;&#12290;&#36825;&#20010;&#24418;&#29366;&#21487;&#33021;&#26159;&#26576;&#20010; rv &#30340;&#27010;&#29575;&#23494;&#24230;&#12290;&#22914;&#26524; x = y = 1, &#20110;&#26159;&#21464;&#25104;&#20102; 0-1 &#36830;&#32493;&#22343;&#21248;&#20998;&#24067;&#12290;&#22240;&#20026;&#23545;&#31216;&#24615;&#65292;a&#65292;b &#22823;&#20110; 1 &#30340;&#26102;&#20505;&#65292;&#24418;&#29366;&#26159; bell shape&#65292;&#22914;&#26524; a &#26356;&#22823;&#65292;&#25972;&#20307;&#36234;&#21491;&#20559;&#12290;</p>
<p>properties</p>
<ul>
<li><p><strong>symmetric</strong>: <span class="math inline">\({\operatorname{Beta}}(x,y) = {\operatorname{Beta}}(y,x). \!\)</span></p></li>
<li><p><strong>relationship between gamma function and beta function</strong>: <span class="math inline">\({\operatorname{Beta}}(x,y)=\dfrac{\Gamma(x)\,\Gamma(y)}{\Gamma(x+y)} \!\)</span></p>
<p>When x and y are positive integers, it follows from the definition of the gamma function <span class="math inline">\(\Gamma\)</span> that:</p>
<ul>
<li><span class="math inline">\({\operatorname{Beta}}(x,y)=\dfrac{(x-1)!\,(y-1)!}{(x+y-1)!} \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) = 2\int_0^{\pi/2}(\sin\theta)^{2x-1}(\cos\theta)^{2y-1}\,\mathrm{d}\theta, \qquad \mathrm{Re}(x)&gt;0,\ \mathrm{Re}(y)&gt;0 \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) = \int_0^\infty\dfrac{t^{x-1}}{(1+t)^{x+y}}\,\mathrm{d}t, \qquad \mathrm{Re}(x)&gt;0,\ \mathrm{Re}(y)&gt;0 \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) = \sum_{n=0}^\infty \dfrac{{n-y \choose n}} {x+n}, \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) = \frac{x+y}{x y} \prod_{n=1}^\infty \left( 1+ \dfrac{x y}{n (x+y+n)}\right)^{-1}, \!\)</span></li>
</ul></li>
<li><p>The Beta function satisfies several interesting identities, including</p>
<ul>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) = {\operatorname{Beta}}(x, y+1) + {\operatorname{Beta}}(x+1, y) \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x+1,y) = {\operatorname{Beta}}(x, y) \cdot \dfrac{x}{x+y} \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y+1) = {\operatorname{Beta}}(x, y) \cdot \dfrac{y}{x+y} \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y)\cdot(t \mapsto t_+^{x+y-1}) = (t \to t_+^{x-1}) * (t \to t_+^{y-1}) \qquad x\ge 1, y\ge 1, \!\)</span></li>
<li><span class="math inline">\({\operatorname{Beta}}(x,y) \cdot {\operatorname{Beta}}(x+y,1-y) = \dfrac{\pi}{x \sin(\pi y)}, \!\)</span></li>
</ul>
<p>where <span class="math inline">\(t \mapsto t_+^x\)</span> is a truncated power function and the star denotes convolution. The lowermost identity above shows in particular <span class="math inline">\(\Gamma(\tfrac12) = \sqrt \pi\)</span>. Some of these identities, e.g.&#160;the <strong>trigonometric formula</strong>, can be applied to deriving the volume of an n-ball in Cartesian coordinates.</p></li>
</ul>
<p>Euler&#8217;s integral for the beta function may be converted into an integral over the Pochhammer contour C as</p>
<p><span class="math display">\[\displaystyle (1-e^{2\pi i\alpha})(1-e^{2\pi i\beta}){\operatorname{Beta}}(\alpha,\beta) =\int_C t^{\alpha-1}(1-t)^{\beta-1} \, \mathrm{d}t.\]</span></p>
<dl>
<dt>Relationship between gamma function and beta function <code class="fold">@</code></dt>
<dd><p>To derive the integral representation of the beta function, write the product of two factorials as</p>
<p><span class="math display">\[
    \begin{align} \Gamma(x)\Gamma(y) &amp;= \int_0^\infty\ e^{-u}
    u^{x-1}\,\mathrm{d}u \int_0^\infty\ e^{-v} v^{y-1}\,\mathrm{d}v \\[6pt]
    &amp;=\int_0^\infty\int_0^\infty\ e^{-u-v} u^{x-1}v^{y-1}\,\mathrm{d}u
    \,\mathrm{d}v. \end{align}
\]</span></p>
<p>Changing variables by u = f(z,t) = zt and v = g(z,t) = z(1-t) shows that this is</p>
<p><span class="math display">\[\begin{align} \Gamma(x)\Gamma(y) &amp;= \int_{z=0}^\infty\int_{t=0}^1 e^{-z} (zt)^{x-1}(z(1-t))^{y-1}|J(z,t)|\,\mathrm{d}t \,\mathrm{d}z \\[6pt] &amp;= \int_{z=0}^\infty\int_{t=0}^1 e^{-z} (zt)^{x-1}(z(1-t))^{y-1}z\,\mathrm{d}t \,\mathrm{d}z \\[6pt] &amp;= \int_{z=0}^\infty e^{-z}z^{x+y-1} \,\mathrm{d}z\int_{t=0}^1t^{x-1}(1-t)^{y-1}\,\mathrm{d}t\\ &amp;=\Gamma(x+y){\operatorname{Beta}}(x,y), \end{align}\]</span></p>
<p>where |J(z,t)| is the absolute value of the Jacobian determinant of u = f(z,t) and v = g(z,t).</p>
<p>The stated identity may be seen as a particular case of the identity for the integral of a convolution. Taking</p>
<p><span class="math inline">\(f(u):=e^{-u} u^{x-1} 1_{{\operatorname{R}}_+}\)</span> and <span class="math inline">\(g(u):=e^{-u} u^{y-1} 1_{{\operatorname{R}}_+}\)</span>, one has:</p>
<p><span class="math display">\[\Gamma(x) \Gamma(y) = \left(\int_{{\operatorname{R}}}f(u)\mathrm{d}u\right) \left( \int_{{\operatorname{R}}} g(u) \mathrm{d}u \right) = \int_{{\operatorname{R}}}(f*g)(u)\mathrm{d}u ={\operatorname{Beta}}(x, y)\,\Gamma(x+y).\]</span></p>
</dd>
<dt>Derivatives <code class="fold">@</code></dt>
<dd><p>We have</p>
<p><span class="math display">\[{\partial \over \partial x} \mathrm{B}(x, y) = \mathrm{B}(x, y)
\left( {\Gamma&#39;(x) \over \Gamma(x)} - {\Gamma&#39;(x + y) \over \Gamma(x +
y)} \right) = \mathrm{B}(x, y) (\psi(x) - \psi(x + y)),\]</span></p>
<p>where <span class="math inline">\(\psi(x)\)</span> is the digamma function.</p>
</dd>
<dt>Approximation <code class="fold">@</code></dt>
<dd><p>Stirling&#8217;s approximation gives the asymptotic formula</p>
<p><span class="math display">\[{\operatorname{Beta}}(x,y) \sim \sqrt {2\pi } \frac{{x^{x - \frac{1}{2}} y^{y -
\frac{1}{2}} }}{{\left( {x + y} \right)^{x + y - \frac{1}{2}} }}\]</span></p>
<p>for large x and large y. If on the other hand x is large and y is fixed, then</p>
<p><span class="math display">\[{\operatorname{Beta}}(x,y) \sim \Gamma(y)\,x^{-y}.\]</span></p>
</dd>
</dl>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Beta_function">Beta function - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Chi-squared distribution <code class="fold">@</code></dt>
<dd><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Chi-square_pdf.svg/482px-Chi-square_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Chi-square_cdf.svg/482px-Chi-square_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Notation</td>
<td align="left"><span class="math inline">\(\chi^2(k)\!\)</span> or <span class="math inline">\(\chi^2_k\!\)</span></td>
</tr>
<tr class="even">
<td align="left">Parameters</td>
<td align="left"><span class="math inline">\(k \in \mathbb{N}_{&gt;0}\)</span> (known as &#8220;degrees of freedom&#8221;)</td>
</tr>
<tr class="odd">
<td align="left">Support</td>
<td align="left">x &#8712; [0, +&#8734;)</td>
</tr>
<tr class="even">
<td align="left">pdf</td>
<td align="left"><span class="math inline">\(\frac{1}{2^{\frac{k}{2}}\Gamma\left(\frac{k}{2}\right)}\; x^{\frac{k}{2}-1} e^{-\frac{x}{2}}\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">CDF</td>
<td align="left"><span class="math inline">\(\frac{1}{\Gamma\left(\frac{k}{2}\right)}\;\gamma\left(\tfrac{k}{2},\,\frac{x}{2}\right)\)</span></td>
</tr>
<tr class="even">
<td align="left">Mean</td>
<td align="left">k</td>
</tr>
<tr class="odd">
<td align="left">Median</td>
<td align="left"><span class="math inline">\(\approx k\bigg(1-\frac{2}{9k}\bigg)^3\)</span></td>
</tr>
<tr class="even">
<td align="left">Mode</td>
<td align="left">max{&#8201;k &#8722; 2, 0&#8201;}</td>
</tr>
<tr class="odd">
<td align="left">Variance</td>
<td align="left">2k</td>
</tr>
<tr class="even">
<td align="left">Skewness</td>
<td align="left"><span class="math inline">\(\scriptstyle\sqrt{8/k}\,\)</span></td>
</tr>
<tr class="odd">
<td align="left">Ex. kurtosis</td>
<td align="left">12&#8201;/&#8201;k</td>
</tr>
<tr class="even">
<td align="left">Entropy</td>
<td align="left"><span class="math inline">\(\begin{align}\tfrac{k}{2}&amp;+\ln(2\Gamma(\tfrac{k}{2})) \\ &amp;\!+(1-\tfrac{k}{2})\psi(\tfrac{k}{2}) \,{\scriptstyle\text{(nats)}} \end{align}\)</span></td>
</tr>
<tr class="odd">
<td align="left">MGF</td>
<td align="left"><span class="math inline">\((1 &#8722; 2&#8201;t )&#8722;k/2 for &#8201;t&#8201; &lt; &#189;\)</span></td>
</tr>
<tr class="even">
<td align="left">CF</td>
<td align="left"><span class="math inline">\((1 &#8722; 2&#8201;i&#8201;t )&#8722;k/2\)</span></td>
</tr>
</tbody>
</table>
<p>The pdf of the chi-squared distribution is</p>
<p><span class="math display">\[f(x;\,k) = \begin{cases} \frac{x^{(k/2-1)} e^{-x/2}}{2^{k/2} \Gamma\left(\frac{k}{2}\right)}, &amp; x &gt; 0; \\ 0, &amp; \text{otherwise}. \end{cases}\]</span></p>
<p>where &#915;(k/2) denotes the Gamma function, which has closed-form values for integer k.</p>
<p>Its CDF is:</p>
<p><span class="math display">\[F(x;\,k) = \frac{\gamma(\frac{k}{2},\,\frac{x}{2})}{\Gamma(\frac{k}{2})} = P\left(\frac{k}{2},\,\frac{x}{2}\right),\]</span></p>
<p>where &#947;(s,t) is the lower incomplete Gamma function and P(s,t) is the regularized Gamma function.</p>
<p>In a special case of k = 2 this function has a simple form:</p>
<p><span class="math display">\[F(x;\,2) = 1 - e^{-\frac{x}{2}}\]</span></p>
</dd>
<dt>Student&#8217;s t-distribution <code class="fold">@</code></dt>
<dd><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Student_t_pdf.svg/488px-Student_t_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Student_t_cdf.svg/488px-Student_t_cdf.svg.png" style="width:45.0%" /></p>
<table>
<tbody>
<tr class="odd">
<td align="left">Parameters</td>
<td><span class="math inline">\(\nu\)</span> &gt; 0 degrees of freedom (real)</td>
</tr>
<tr class="even">
<td align="left">Support</td>
<td>x &#8712; (&#8722;&#8734;; +&#8734;)</td>
</tr>
<tr class="odd">
<td align="left">pdf</td>
<td><span class="math inline">\(\textstyle\frac{\Gamma \left(\frac{\nu+1}{2} \right)} {\sqrt{\nu\pi}\,\Gamma \left(\frac{\nu}{2} \right)} \left(1+\frac{x^2}{\nu} \right)^{-\frac{\nu+1}{2}}\!\)</span></td>
</tr>
<tr class="even">
<td align="left">CDF</td>
<td><span class="math inline">\(\begin{matrix} \frac{1}{2} + x \Gamma \left( \frac{\nu+1}{2} \right) \times\\[0.5em] \frac{\,_2F_1 \left ( \frac{1}{2},\frac{\nu+1}{2};\frac{3}{2}; -\frac{x^2}{\nu} \right)} {\sqrt{\pi\nu}\,\Gamma \left(\frac{\nu}{2}\right)} \end{matrix}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td>0 for <span class="math inline">\(\nu\)</span> &gt; 1, otherwise undefined</td>
</tr>
<tr class="even">
<td align="left">Median</td>
<td>0</td>
</tr>
<tr class="odd">
<td align="left">Mode</td>
<td>0</td>
</tr>
<tr class="even">
<td align="left">Variance</td>
<td><span class="math inline">\(\textstyle\frac{\nu}{\nu-2}\)</span> for <span class="math inline">\(\nu\)</span> &gt; 2, &#8734; for <span class="math inline">\(1 &lt; \nu \le 2\)</span>, otherwise undefined</td>
</tr>
<tr class="odd">
<td align="left">Skewness</td>
<td>0 for <span class="math inline">\(\nu\)</span> &gt; 3, otherwise undefined</td>
</tr>
<tr class="even">
<td align="left">Ex. kurtosis</td>
<td><span class="math inline">\(\textstyle\frac{6}{\nu-4}\)</span> for <span class="math inline">\(\nu\)</span> &gt; 4, &#8734; for <span class="math inline">\(2 &lt; \nu \le 4\)</span>, otherwise undefined</td>
</tr>
</tbody>
</table>
<p>Student&#8217;s t-distribution has the pdf given by</p>
<p><span class="math display">\[f(t) = \frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} \left(1+\frac{t^2}{\nu} \right)^{\!-\frac{\nu+1}{2}},\!\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\nu\)</span> is the number of degrees of freedom and</li>
<li><span class="math inline">\(\Gamma\)</span> is the gamma function.</li>
</ul>
<p>This may also be written as</p>
<p><span class="math display">\[f(t) = \frac{1}{\sqrt{\nu}\,\mathrm{B} (\frac{1}{2}, \frac{\nu}{2})} \left(1+\frac{t^2}{\nu} \right)^{\!-\frac{\nu+1}{2}}\!,\]</span></p>
<p>where B is the Beta function.</p>
<p>For <span class="math inline">\(\nu\)</span> even,</p>
<p><span class="math display">\[\frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} = \frac{(\nu -1)(\nu -3)\cdots 5 \cdot 3} {2\sqrt{\nu}(\nu -2)(\nu -4)\cdots 4 \cdot 2\,}\cdot\]</span></p>
<p>For <span class="math inline">\(\nu\)</span> odd,</p>
<p><span class="math display">\[\frac{\Gamma(\frac{\nu+1}{2})} {\sqrt{\nu\pi}\,\Gamma(\frac{\nu}{2})} = \frac{(\nu -1)(\nu -3)\cdots 4 \cdot 2} {\pi \sqrt{\nu}(\nu -2)(\nu -4)\cdots 5 \cdot 3\,}\cdot\!\]</span></p>
</dd>
<dt>F-distribution <code class="fold">@</code></dt>
<dd><p>The F-distribution, also known as Snedecor&#8217;s F distribution or the Fisher&#8211;Snedecor distribution (after Ronald Fisher and George W. Snedecor) is, in probability theory and statistics, a continuous probability distribution.</p>
<p>The F-distribution arises frequently as the null distribution of a test statistic, most notably in the analysis of variance; see F-test.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/F_pdf.svg/488px-F_pdf.svg.png" style="width:45.0%" /> <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/F_dist_cdf.svg/488px-F_dist_cdf.svg.png" style="width:45.0%" /></p>
<p>If a random variable X has an F-distribution with parameters d1 and d2, we write X ~ F(d1, d2). Then the probability density function (pdf) for X is given by</p>
<p><span class="math display">\[\begin{align} f(x; d_1,d_2) &amp;=
\frac{\sqrt{\frac{(d_1\,x)^{d_1}\,\,d_2^{d_2}} {(d_1\,x+d_2)^{d_1+d_2}}}}
{x\,\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)} \\
&amp;=\frac{1}{\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)}
\left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1}
\left(1+\frac{d_1}{d_2}\,x\right)^{-\frac{d_1+d_2}{2}} \end{align}\]</span></p>
<p>for real x &#8805; 0. Here <span class="math inline">\(\mathrm{B}\)</span> is the beta function. In many applications, the parameters d1 and d2 are positive integers, but the distribution is well-defined for positive real values of these parameters.</p>
<p>The cumulative distribution function is</p>
<p><span class="math display">\[F(x; d_1,d_2)=I_{\frac{d_1 x}{d_1 x + d_2}}\left (\tfrac{d_1}{2}, \tfrac{d_2}{2} \right) ,\]</span></p>
<p>where I is the regularized incomplete beta function.</p>
<p>The expectation, variance, and other details about the F(d1, d2) are given in the sidebox; for d2 &gt; 8, the excess kurtosis is</p>
<p><span class="math display">\[\gamma_2 = 12\frac{d_1(5d_2-22)(d_1+d_2-2)+(d_2-4)(d_2-2)^2}{d_1(d_2-6)(d_2-8)(d_1+d_2-2)}.\]</span></p>
<table>
<tbody>
<tr class="odd">
<td>Parameters</td>
<td align="left">d1, d2 &gt; 0 deg. of freedom</td>
</tr>
<tr class="even">
<td>Support</td>
<td align="left">x &#8712; [0, +&#8734;)</td>
</tr>
<tr class="odd">
<td>pdf</td>
<td align="left"><span class="math inline">\(\frac{\sqrt{\frac{(d_1\,x)^{d_1}\,\,d_2^{d_2}} {(d_1\,x+d_2)^{d_1+d_2}}}} {x\,\mathrm{B}\!\left(\frac{d_1}{2},\frac{d_2}{2}\right)}\!\)</span></td>
</tr>
<tr class="even">
<td>CDF</td>
<td align="left"><span class="math inline">\(I_{\frac{d_1 x}{d_1 x + d_2}} \left(\tfrac{d_1}{2}, \tfrac{d_2}{2} \right)\)</span></td>
</tr>
</tbody>
</table>
<dl>
<dt>Characterization <code class="fold">@</code></dt>
<dd><p>A random variate of the F-distribution with parameters d1 and d2 arises as the ratio of two appropriately scaled chi-squared variates:</p>
<p><span class="math display">\[X = \frac{U_1/d_1}{U_2/d_2}\]</span></p>
<p>where</p>
<ul>
<li>U1 and U2 have chi-squared distributions with d1 and d2 degrees of freedom respectively, and</li>
<li>U1 and U2 are independent.</li>
</ul>
</dd>
</dl>
</dd>
<dt>Marginal distribution <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="http://whudoc.qiniudn.com/2016/marginal-distribution.png" alt="Joint and marginal distributions of a pair of discrete, random variables X,Y having nonzero mutual information I(X; Y). The values of the joint distribution are in the 4&#215;4 square, and the values of the marginal distributions are along the right and bottom margins." />
<p class="caption">Joint and marginal distributions of a pair of discrete, random variables X,Y having nonzero mutual information I(X; Y). The values of the joint distribution are in the 4&#215;4 square, and the values of the marginal distributions are along the right and bottom margins.</p>
</div>
<p>The term marginal variable is used to refer to those variables in the subset of variables <strong>being retained</strong>. These terms are dubbed &#8220;marginal&#8221; because they used to be found by summing values in a table along rows or columns, and writing the sum in the margins of the table. The distribution of the marginal variables (the marginal distribution) is obtained by marginalizing over the distribution of the variables being discarded, and the discarded variables are said to have been marginalized out.</p>
</dd>
<dt>Joint probability distribution <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Multivariate_normal_sample.svg/450px-Multivariate_normal_sample.svg.png" alt="Many sample observations (black) are shown from a joint probability distribution. The marginal densities are shown as well." />
<p class="caption">Many sample observations (black) are shown from a joint probability distribution. The marginal densities are shown as well.</p>
</div>
<p>The joint probability distribution can be expressed either in terms of a joint cumulative distribution function or in terms of a joint probability density function (in the case of continuous variables) or joint probability mass function (in the case of discrete variables). These in turn can be used to find two other types of distributions: the marginal distribution giving the probabilities for any one of the variables with no reference to any specific ranges of values for the other variables, and the conditional probability distribution giving the probabilities for any subset of the variables conditional on particular values of the remaining variables.</p>
<p>Discrete case</p>
<p><span class="math display">\[\begin{align} \mathrm{P}(X=x\ \mathrm{and}\ Y=y) = \mathrm{P}(Y=y \mid X=x) \cdot \mathrm{P}(X=x) = \mathrm{P}(X=x \mid Y=y) \cdot \mathrm{P}(Y=y) \end{align}\]</span></p>
<p>Continuous case</p>
<p><span class="math display">\[f_{X,Y}(x,y) = f_{Y\mid X}(y\mid x)f_X(x) = f_{X\mid Y}(x\mid y)f_Y(y)\;\]</span></p>
<p>Mixed case</p>
<p><span class="math display">\[\begin{align} f_{X,Y}(x,y) = f_{X \mid Y}(x \mid y)\mathrm{P}(Y=y)= \mathrm{P}(Y=y \mid X=x) f_X(x) \end{align}\]</span></p>
<p>Joint distribution for independent variables</p>
<ul>
<li><span class="math inline">\(\ P(X = x \ \mbox{and} \ Y = y ) = P( X = x) \cdot P( Y = y)\)</span></li>
<li><span class="math inline">\(\ f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)\)</span></li>
</ul>
</dd>
<dt>Sampling (statistics) <code class="fold">@</code></dt>
<dd><p>In statistics, quality assurance, and survey methodology, sampling is concerned with the selection of a <strong>subset</strong> of individuals from within a statistical population to estimate characteristics of the whole population. Each observation measures one or more properties (such as weight, location, color) of observable bodies distinguished as independent objects or individuals. In survey sampling, weights can be applied to the data to adjust for the sample design, particularly stratified sampling. Results from probability theory and statistical theory are employed to guide the practice. In business and medical research, sampling is widely used for gathering information about a population.</p>
<p>The sampling process comprises several stages:</p>
<ul>
<li>Defining the population of concern</li>
<li>Specifying a sampling frame, a set of items or events possible to measure</li>
<li>Specifying a sampling method for selecting items or events from the frame</li>
<li>Determining the sample size</li>
<li>Implementing the sampling plan</li>
<li>Sampling and data collecting</li>
<li>Data which can be selected</li>
</ul>
</dd>
<dt>Survey methodology <code class="fold">@</code></dt>
<dd><p>Statistical surveys are undertaken with a view towards making statistical inferences about the population being studied, and this depends strongly on the survey questions used. Polls about public opinion, public health surveys, market research surveys, government surveys and censuses are all examples of quantitative research that use contemporary survey methodology to answer questions about a population. Although censuses do not include a &#8220;sample&#8221;, they do include other aspects of survey methodology, like questionnaires, interviewers, and nonresponse follow-up techniques. Surveys provide important information for all kinds of public information and research fields, e.g., marketing research, psychology, health professionals and sociology.</p>
</dd>
<dt>Confidence interval <code id="confidence-interval" class="anchor">@</code> <code class="fold">@</code></dt>
<dd><p>In statistics, a <strong>confidence interval (CI)</strong> is a type of interval estimate of a population parameter. It is an observed interval (i.e., it is calculated from the observations), in principle different from sample to sample, that frequently includes the value of an unobservable parameter of interest if the experiment is repeated. How frequently the observed interval contains the parameter is determined by the confidence level or confidence coefficient. More specifically, the meaning of the term &#8220;confidence level&#8221; is that, if CI are constructed across many separate data analyses of replicated (and possibly different) experiments, the proportion of such intervals that contain the true value of the parameter will match the given confidence level. Whereas two-sided confidence limits form a confidence interval, their one-sided counterparts are referred to as lower/upper confidence bounds (or limits).</p>
<p>Let X be a random sample from a probability distribution with statistical parameters &#952;, which is a quantity to be estimated, and &#981;, representing quantities that are not of immediate interest. A confidence interval for the parameter &#952;, with confidence level or confidence coefficient &#947;, is an interval with random endpoints (u(X), v(X)), determined by the pair of random variables u(X) and v(X), with the property:</p>
<p><span class="math display">\[{\Pr}_{\theta,\phi}(u(X)&lt;\theta&lt;v(X))=\gamma\text{ for all }(\theta,\phi).\]</span></p>
</dd>
<dt>Fiducial inference <code class="fold">@</code></dt>
<dd><p>Fiducial inference is one of a number of different types of statistical inference. These are rules, intended for general application, by which conclusions can be drawn from samples of data. In modern statistical practice, attempts to work with fiducial inference have fallen out of fashion in favour of frequentist inference, Bayesian inference and decision theory. However, fiducial inference is important in the history of statistics since its development led to the parallel development of concepts and tools in theoretical statistics that are widely used. Some current research in statistical methodology is either explicitly linked to fiducial inference or is closely connected to it.</p>
<p>Fiducial inference can be interpreted as an attempt to perform <strong>inverse probability</strong> without calling on prior probability distributions. Fiducial inference quickly attracted controversy and was never widely accepted. Indeed, counter-examples to the claims of Fisher for fiducial inference were soon published. These counter-examples cast doubt on the coherence of &#8220;fiducial inference&#8221; as a system of statistical inference or inductive logic. Other studies showed that, where the steps of fiducial inference are said to lead to &#8220;fiducial probabilities&#8221; (or &#8220;fiducial distributions&#8221;), these probabilities lack the property of additivity, and so cannot constitute a probability measure.</p>
<p>The concept of fiducial inference can be outlined by comparing its treatment of the problem of interval estimation in relation to other modes of statistical inference.</p>
<p>Fisher required the existence of a sufficient statistic for the fiducial method to apply. Suppose there is a single sufficient statistic for a single parameter. That is, suppose that the conditional distribution of the data given the statistic does not depend on the value of the parameter. For example suppose that n independent observations are uniformly distributed on the interval <span class="math inline">\([0,\omega]\)</span>. The maximum, X, of the n observations is a sufficient statistic for &#969;. If only X is recorded and the values of the remaining observations are forgotten, these remaining observations are equally likely to have had any values in the interval [0,X]. This statement does not depend on the value of &#969;. Then X contains all the available information about &#969; and the other observations could have given no further information.</p>
<p>The CDF of X is</p>
<p><span class="math display">\[F(x) = P(X \leq x) = P\left(\mathrm{all\ observations} \leq x\right) = \left(\frac{x}{\omega}\right)^n.\]</span></p>
<p>Probability statements about X/&#969; may be made. For example, given &#945;, a value of a can be chosen with 0 &lt; a &lt; 1 such that</p>
<p><span class="math display">\[P\left(X &gt; \frac{\omega }{a}\right) = 1-a^n = \alpha.\]</span></p>
<p>Thus</p>
<p><span class="math display">\[a = (1-\alpha)^{\frac{1}{n}}.\]</span></p>
<p>Then Fisher might say that this statement may be inverted into the form</p>
<p><span class="math display">\[P\left(\omega &lt; \frac{X}{a}\right) = \alpha.\]</span></p>
</dd>
<dt>Pivotal quantity <code class="fold">@</code></dt>
<dd><p>In statistics, a pivotal quantity or pivot is a function of observations and unobservable parameters whose probability distribution does not depend on the unknown parameters (also referred to as nuisance parameters). Note that a pivot quantity need not be a statistic&#8212;the function and its value can depend on the parameters of the model, but its distribution must not. If it is a statistic, then it is known as an ancillary statistic.</p>
<p>More formally, let <span class="math inline">\(X = (X_1,X_2,\ldots,X_n)\)</span> be a random sample from a distribution that depends on a parameter (or vector of parameters) <span class="math inline">\(\theta\)</span>. Let <span class="math inline">\(g(X,\theta)\)</span> be a random variable whose distribution is the same for all <span class="math inline">\(\theta\)</span>. Then g is called a pivotal quantity (or simply a pivot).</p>
<p>Pivotal quantities are commonly used for normalization to allow data from different data sets to be compared. It is relatively easy to construct pivots for location and scale parameters: for the former we form differences so that location cancels, for the latter ratios so that scale cancels.</p>
<p>Pivotal quantities are fundamental to the construction of test statistics, as they allow the statistic to not depend on parameters &#8211; for example, Student&#8217;s t-statistic is for a normal distribution with unknown variance (and mean). They also provide one method of constructing confidence intervals, and the use of pivotal quantities improves performance of the bootstrap. In the form of ancillary statistics, they can be used to construct frequentist prediction intervals (predictive confidence intervals).</p>
<p>One of the simplest pivotal quantities is the z-score; given a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, and an observation x, the z-score:</p>
<p><span class="math display">\[z = \frac{x - \mu}{\sigma},\]</span></p>
<p>has distribution N(0,1).</p>
</dd>
<dt>Regression analysis <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/330px-Linear_regression.svg.png" />

</div>
<dl>
<dt>Least squares <code class="fold">@</code></dt>
<dd><p>The minimum of the sum of squares is found by setting the gradient to zero. Since the model contains m parameters, there are m gradient equations:</p>
<p><span class="math display">\[\frac{\partial S}{\partial \beta_j}=2\sum_i r_i\frac{\partial r_i}{\partial \beta_j}=0,\ j=1,\ldots,m,\]</span></p>
<p>and since <span class="math inline">\(r_i=y_i-f(x_i,\boldsymbol \beta)\)</span>, the gradient equations become</p>
<p><span class="math display">\[-2\sum_i r_i\frac{\partial f(x_i,\boldsymbol \beta)}{\partial \beta_j}=0,\ j=1,\ldots,m.\]</span></p>
<p>The gradient equations apply to all least squares problems. Each particular problem requires particular expressions for the model and its partial derivatives.</p>
<ul>
<li>Linear least squares</li>
<li>Non-linear least squares</li>
<li>Weighted least squares</li>
</ul>
</dd>
</dl>
<p>Gauss&#8211;Markov theorem</p>
<dl>
<dt>Linear regression <code class="fold">@</code></dt>
<dd><p>In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X. The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. (This term should be distinguished from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.)</p>
<p>Given a data set <span class="math inline">\(\{y_i,\, x_{i1}, \ldots, x_{ip}\}_{i=1}^n\)</span> of n statistical units, a linear regression model assumes that the relationship between the dependent variable yi and the p-vector of regressors xi is linear. This relationship is modeled through a disturbance term or error variable <span class="math inline">\(&#949;_i\)</span> &#8212; an unobserved random variable that adds noise to the linear relationship between the dependent variable and regressors. Thus the model takes the form</p>
<p><span class="math display">\[y_i = \beta_1 x_{i1} + \cdots + \beta_p x_{ip} + \varepsilon_i = \mathbf{x}^{\rm T}_i\boldsymbol\beta + \varepsilon_i, \qquad i = 1, \ldots, n,\]</span></p>
<p>where T denotes the transpose, so that xiT&#946; is the inner product between vectors xi and &#946;.</p>
<p>Often these n equations are stacked together and written in vector form as</p>
<p><span class="math display">\[\mathbf{y} = \mathbf{X}\boldsymbol\beta + \boldsymbol\varepsilon, \,\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{y} = \begin{pmatrix} y_1 \\ y_2 \\ \vdots \\ y_n \end{pmatrix}, \quad\)</span></li>
<li><span class="math inline">\(\mathbf{X} = \begin{pmatrix} \mathbf{x}^{\rm T}_1 \\ \mathbf{x}^{\rm T}_2 \\ \vdots \\ \mathbf{x}^{\rm T}_n \end{pmatrix} = \begin{pmatrix} x_{11} &amp; \cdots &amp; x_{1p} \\ x_{21} &amp; \cdots &amp; x_{2p} \\ \vdots &amp; \ddots &amp; \vdots \\ x_{n1} &amp; \cdots &amp; x_{np} \end{pmatrix},\)</span></li>
<li><span class="math inline">\(\boldsymbol\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \vdots \\ \beta_p \end{pmatrix}, \quad \boldsymbol\varepsilon = \begin{pmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_n \end{pmatrix}.\)</span></li>
</ul>
</dd>
<dt>Nonlinear regression <code class="fold">@</code></dt>
<dd><p>In statistics, nonlinear regression is a form of regression analysis in which observational data are modeled by a function which is a nonlinear combination of the model parameters and depends on one or more independent variables. The data are fitted by a method of successive approximations.</p>
<p>For example, the Michaelis&#8211;Menten model for enzyme kinetics</p>
<p><span class="math display">\[v = \frac{V_\max\ [\mbox{S}]}{K_m + [\mbox{S}]}\]</span></p>
<p>can be written as</p>
<p><span class="math display">\[f(x,\boldsymbol\beta)= \frac{\beta_1 x}{\beta_2 + x}\]</span></p>
<p>where <span class="math inline">\(\beta_1\)</span> is the parameter <span class="math inline">\(V_\max\)</span>, <span class="math inline">\(\beta_2\)</span> is the parameter <span class="math inline">\(K_m\)</span> and <span class="math inline">\([S]\)</span> is the independent variable, x. This function is nonlinear because it cannot be expressed as a linear combination of the two <span class="math inline">\(\beta\)</span>s.</p>
<p>Other examples of nonlinear functions include exponential functions, logarithmic functions, trigonometric functions, power functions, Gaussian function, and Lorenz curves. Some functions, such as the exponential or logarithmic functions, can be transformed so that they are linear. When so transformed, standard linear regression can be performed but must be applied with caution. See Linearization, below, for more details.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Michaelis-Menten_saturation_curve_of_an_enzyme_reaction.svg/450px-Michaelis-Menten_saturation_curve_of_an_enzyme_reaction.svg.png" alt="See Michaelis-Menten kinetics for details." />
<p class="caption">See <a href="https://en.wikipedia.org/wiki/Michaelis-Menten_kinetics">Michaelis-Menten kinetics</a> for details.</p>
</div>
</dd>
</dl>
</dd>
<dt>Residual sum of squares <code class="fold">@</code></dt>
<dd><p>In a model with a single explanatory variable, RSS is given by:</p>
<p><span class="math display">\[RSS = \sum_{i=1}^n (y_i - f(x_i))^2,\]</span></p>
<p>where yi is the i th value of the variable to be predicted, xi is the i th value of the explanatory variable, and f(x_i) is the predicted value of yi (also termed ). In a standard linear simple regression model, <span class="math inline">\(y_i = a+bx_i+\varepsilon_i\,\)</span>, where a and b are coefficients, y and x are the regressand and the regressor, respectively, and &#949; is the error term. The sum of squares of residuals is the sum of squares of estimates of <span class="math inline">\(&#949;_i\)</span>; that is</p>
<p><span class="math display">\[RSS = \sum_{i=1}^n (\varepsilon_i)^2 = \sum_{i=1}^n (y_i - (\alpha + \beta x_i))^2,\]</span></p>
<p>where is the estimated value of the constant term a and is the estimated value of the slope coefficient b.</p>
<dl>
<dt>Matrix expression for the OLS residual sum of squares</dt>
<dd><p>The general regression model with n observations and k explanators, the first of which is a constant unit vector whose coefficient is the regression intercept, is</p>
<p><span class="math display">\[y = X \beta + e\]</span></p>
<p>where y is an n &#215; 1 vector of dependent variable observations, each column of the n &#215; k matrix X is a vector of observations on one of the k explanators, is a k &#215; 1 vector of true coefficients, and e is an n&#215; 1 vector of the true underlying errors. The ordinary least squares estimator for is</p>
<p><span class="math display">\[\hat \beta = (X^T X)^{-1}X^T y.\]</span></p>
<p>The residual vector e is y - X = y - X (X^T X)<sup>{-1}X</sup>T y, so the residual sum of squares is:</p>
<p><span class="math display">\[RSS = \hat e ^T \hat e = \| e \|^2,\]</span></p>
<p>(equivalent to the square-root of the norm of residuals); in full:</p>
<p><span class="math display">\[RSS = y^T y - y^T X(X^T X)^{-1} X^T y = y^T [I - X(X^T X)^{-1} X^T] y = y^T [I - H] y,\]</span></p>
<p>where H is the <a href="https://en.wikipedia.org/wiki/Hat_matrix">hat matrix</a>, or the prediction matrix in linear regression.</p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Projection_matrix">Projection matrix - Wikipedia, the free encyclopedia</a></dt>
<dd><p>In statistics, the projection matrix <span class="math inline">\(\mathbf{P}\)</span>, sometimes also called the influence matrix or hat matrix <span class="math inline">\(\mathbf{H}\)</span>, maps the vector of response values (dependent variable values) to the vector of fitted values (or predicted values). It describes the influence each response value has on each fitted value. The diagonal elements of the projection matrix are the leverages, which describe the influence each response value has on the fitted value for that same observation.</p>
<p>If the vector of response values is denoted by <span class="math inline">\(\mathbf{y}\)</span> and the vector of fitted values by <span class="math inline">\(\mathbf{\hat{y}}\)</span>,</p>
<p><span class="math display">\[
    \mathbf{\hat{y}} = \mathbf{P} \mathbf{y}.
\]</span></p>
<p>As <span class="math inline">\(\mathbf{\hat{y}}\)</span> is usually pronounced &#8220;y-hat&#8221;, the projection matrix is also named hat matrix as it &#8220;puts a hat on <span class="math inline">\(\mathbf{y}\)</span>&#8221;. The formula for the vector of residuals <span class="math inline">\(\mathbf{u}\)</span> can also be expressed compactly using the projection matrix:</p>
<p><span class="math display">\[
    \mathbf{u} = \mathbf{y} - \mathbf{\hat{y}} = \mathbf{y} -
    \mathbf{P} \mathbf{y} = \left( \mathbf{I} - \mathbf{P} \right)
    \mathbf{y}.
\]</span></p>
<p>where <span class="math inline">\(\mathbf{I}\)</span> is the identity matrix. The matrix <span class="math inline">\(\mathbf{M} \equiv \left( \mathbf{I} - \mathbf{P} \right)\)</span> is sometimes referred to as annihilator. Moreover, the element in the ith row and jth column of <span class="math inline">\(\mathbf{P}\)</span> is equal to the covariance between the jth response value and the ith fitted value, divided by the variance of the former:</p>
<p><span class="math display">\[
    \begin{align} p_{ij} = \operatorname{Cov}\left[ \hat{y}_i, y_j
    \right] / \operatorname{Var}\left[y_j \right] \end{align}
\]</span></p>
<p>Therefore, the covariance matrix of the residuals, by error propagation, equals <span class="math inline">\(\left( \mathbf{I}-\mathbf{P} \right)^{\mathsf{T}} \mathbf{\Sigma} \left( \mathbf{I}-\mathbf{P} \right)\)</span>, where <span class="math inline">\(\mathbf{\Sigma}\)</span> is the covariance matrix of the error vector (and by extension, the response vector as well). For the case of linear models with independent and identically distributed errors in which <span class="math inline">\(\mathbf{\Sigma} = \sigma^{2} \mathbf{I}\)</span>, this reduces to <span class="math inline">\(\left( \mathbf{I} - \mathbf{P} \right) \sigma^{2}\)</span>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>Ordinary least squares <code class="fold">@</code></dt>
<dd><p>&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;</p>
<p>In statistics, <strong>ordinary least squares (OLS)</strong> or linear least squares is a method for estimating the unknown parameters in a linear regression model, with the goal of minimizing the differences between the observed responses in some arbitrary dataset and the responses predicted by the linear approximation of the data (visually this is seen as the sum of the vertical distances between each data point in the set and the corresponding point on the regression line - the smaller the differences, the better the model fits the data). The resulting estimator can be expressed by a simple formula, especially in the case of a single regressor on the right-hand side.</p>
<p><span class="math display">\[y = X\beta + \varepsilon, \,\]</span></p>
<p>where y and &#949; are n&#215;1 vectors, and X is an n&#215;p matrix of regressors, which is also sometimes called the design matrix.</p>
<p>regressors, &#22238;&#24402;&#22240;&#23376;&#36873;&#25321;&#65307;&#22238;&#24402;&#25968;&#20540;&#12290;</p>
<p>Classical linear regression model</p>
<ul>
<li><p><strong>Correct specification</strong>. The linear functional form is correctly specified.</p></li>
<li><p><strong>Strict exogeneity (&#22806;&#29983;&#24615;)</strong>. The errors in the regression should have conditional mean zero:</p>
<p><span class="math display">\[\operatorname{E}[\,\varepsilon|X\,] = 0.\]</span></p></li>
<li><p>No linear dependence. The regressors in X must all be <strong>linearly independent</strong>. Mathematically, this means that the matrix X must have full column rank almost surely: &#65288;&#24847;&#24605;&#26159;&#25152;&#36873;&#21442;&#25968;&#37117;&#26159;&#26377;&#25928;&#30340;&#12290;&#65289;</p>
<p><span class="math display">\[\Pr\!\big[\,\operatorname{rank}(X) = p\,\big] = 1.\]</span></p></li>
<li><p><strong>Spherical errors</strong>:&#65288;&#24847;&#24605;&#26159;&#35823;&#24046;&#22343;&#21248;&#20998;&#24067;&#22312;&#21508;&#20010;&#26041;&#21521;&#19978;&#65289;</p>
<p><span class="math display">\[\operatorname{Var}[\,\varepsilon \mid X\,] = \sigma^2 I_n,\]</span></p></li>
<li><p><strong>Normality</strong>. It is sometimes additionally assumed that the errors have normal distribution conditional on the regressors:</p>
<p><span class="math display">\[\varepsilon \mid X\sim \mathcal{N}(0, \sigma^2I_n).\]</span></p></li>
</ul>
<p>The sum of squared residuals (SSR) (also called the error sum of squares (ESS) or residual sum of squares (RSS)) is a measure of <strong>the overall model fit</strong>:</p>
<p><span class="math display">\[
    S(b) = \sum_{i=1}^n (y_i - x_i ^T b)^2 = (y-Xb)^T(y-Xb),
\]</span></p>
<p>where T denotes the matrix transpose.</p>
<dl>
<dt>Geometric approach</dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/OLS_geometric_interpretation.svg/987px-OLS_geometric_interpretation.svg.png" alt="OLS estimation can be viewed as a projection onto the linear space spanned by the regressors." />
<p class="caption">OLS estimation can be viewed as a projection onto the linear space spanned by the regressors.</p>
</div>
<p><span class="math display">\[\hat\beta = {\rm arg}\min_\beta\,\lVert y - X\beta \rVert,\]</span></p>
</dd>
<dt>Maximum likelihood</dt>
<dd><p><strong>The OLS estimator is identical to the maximum likelihood estimator (MLE) under the normality assumption for the error terms.</strong></p>
<p>see at <a href="#maximum-likelihood" class="uri">#maximum-likelihood</a>.</p>
</dd>
<dt>Generalized method of moments</dt>
<dd><p>In iid case the OLS estimator can also be viewed as a GMM estimator arising from the moment conditions</p>
<p><span class="math display">\[\mathrm{E}\big[\, x_i(y_i - x_i ^T \beta) \,\big] = 0.\]</span></p>
</dd>
</dl>
<p>First of all, under the strict exogeneity assumption the OLS estimators <span class="math inline">\(\scriptstyle\hat\beta\)</span> and <span class="math inline">\(s^2\)</span> are unbiased, meaning that their expected values coincide with the true values of the parameters:</p>
<p><span class="math display">\[\operatorname{E}[\, \hat\beta \mid X \,] = \beta, \quad \operatorname{E}[\,s^2 \mid X\,] = \sigma^2.\]</span></p>
<p><i class="icon-info-sign"></i> The estimator <span class="math inline">\(\scriptstyle\hat\beta\)</span> is normally distributed, with mean and variance as given before:</p>
<p><span class="math display">\[\hat\beta\ \sim\ \mathcal{N}\big(\beta,\ \sigma^2(X ^T X)^{-1}\big)\]</span></p>
<p>The estimator <span class="math inline">\(s^2\)</span> will be proportional to the chi-squared distribution:</p>
<p><span class="math display">\[s^2\ \sim\ \frac{\sigma^2}{n-p} \cdot \chi^2_{n-p}\]</span></p>
</dd>
<dt>Generalized method of moments <code id="gmm" class="anchor">@</code> <code class="fold">@</code></dt>
<dd><p>In econometrics, the generalized method of moments (GMM) is a generic method for estimating parameters in statistical models. Usually it is applied in the context of semiparametric models, where the parameter of interest is finite-dimensional, whereas the full shape of the distribution function of the data may not be known, and therefore maximum likelihood estimation is not applicable.</p>
<p>The method requires that a certain number of <strong>moment conditions</strong> were specified for the model. These moment conditions are functions of the model parameters and the data, such that their expectation is zero at the true values of the parameters. The GMM method then minimizes a certain norm of the sample averages of the moment conditions.</p>
<p>The GMM estimators are known to be consistent, asymptotically (&#28176;&#36827;&#22320;) normal, and efficient in the class of all estimators that do not use any extra information aside from that contained in the moment conditions.</p>
<p>GMM was developed by Lars Peter Hansen in 1982 as a generalization of the method of moments which was introduced by Karl Pearson in 1894. Hansen shared the 2013 Nobel Prize in Economics in part for this work.</p>
<p>&#36825;&#20040;&#21500;&#8230;&#8230;&#19977;&#21313;&#24180;&#21069;&#30340;&#24037;&#20316;&#8230;&#8230;&#12290;</p>
</dd>
<dt>Nonparametric regression <code class="fold">@</code></dt>
<dd><dl>
<dt>Gaussian process regression or Kriging <code class="fold">@</code></dt>
<dd><p>see <a href="https://en.wikipedia.org/wiki/Kriging">Kriging - Wikipedia, the free encyclopedia</a>.</p>
<p>In statistics, originally in geostatistics, Kriging or Gaussian process regression is a method of interpolation for which the interpolated values are modeled by a Gaussian process governed by prior covariances, as opposed to a piecewise-polynomial spline chosen to optimize smoothness of the fitted values. Under suitable assumptions on the priors, Kriging gives the best linear unbiased prediction of the intermediate values. Interpolating methods based on other criteria such as smoothness need not yield the most likely intermediate values. The method is widely used in the domain of spatial analysis and computer experiments. The technique is also known as Wiener&#8211;Kolmogorov prediction, after Norbert Wiener and Andrey Kolmogorov.</p>
<p>The theoretical basis for the method was developed by the French mathematician Georges Matheron based on the Master&#8217;s thesis of Danie G. Krige, the pioneering plotter of distance-weighted average gold grades at the Witwatersrand reef complex in South Africa. Krige sought to estimate the most likely distribution of gold based on samples from a few boreholes. The English verb is to krige and the most common noun is Kriging; both are often pronounced with a hard &#8220;g&#8221;, following the pronunciation of the name &#8220;Krige&#8221;.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/en/thumb/f/f5/Example_of_kriging_interpolation_in_1D.png/600px-Example_of_kriging_interpolation_in_1D.png" alt="Example of one-dimensional data interpolation by Kriging, with confidence intervals. Squares indicate the location of the data. The Kriging interpolation, shown in red, runs along the means of the normally distributed confidence intervals shown in gray. The dashed curve shows a spline that while smooth nevertheless departs significantly from the expected intermediate values given by those means." />
<p class="caption">Example of one-dimensional data interpolation by Kriging, with confidence intervals. Squares indicate the location of the data. The Kriging interpolation, shown in red, runs along the means of the normally distributed confidence intervals shown in gray. The dashed curve shows a spline that while smooth nevertheless departs significantly from the expected intermediate values given by those means.</p>
</div>
</dd>
</dl>
<p>Kernel regression</p>
<p>Nonparametric multiplicative regression (NPMR) is a form of nonparametric regression based on multiplicative kernel estimation. Like other regression methods, the goal is to estimate a response (dependent variable) based on one or more predictors (independent variables). NPMR can be a good choice for a regression method if the following are true:</p>
<ul>
<li>The shape of the response surface is unknown.</li>
<li>The predictors are likely to interact in producing the response; in other words, the shape of the response to one predictor is likely to depend on other predictors.</li>
<li>The response is either a quantitative or binary (0/1) variable.</li>
</ul>
<p>This is a smoothing technique that can be cross-validated and applied in a predictive way.</p>
<p>NPMR behaves like an organism:</p>
<ul>
<li>The local model</li>
<li>Overfitting controls</li>
</ul>
<p>Regression trees</p>
</dd>
<dt>Least absolute deviations <code class="fold">@</code></dt>
<dd><p><strong>Least absolute deviations (LAD)</strong>, also known as <strong>least absolute errors (LAE)</strong>, least absolute value (LAV), least absolute residual (LAR), sum of absolute deviations, or the L1 norm condition, is a statistical optimality criterion and the statistical optimization technique that relies on it. Similar to the popular least squares technique, it attempts to find a function which closely approximates a set of data. In the simple case of a set of (x,y) data, the approximation function is a simple &#8220;trend line&#8221; in two-dimensional Cartesian coordinates. The method minimizes the sum of absolute errors (SAE) (the sum of the absolute values of the vertical &#8220;residuals&#8221; between points generated by the function and corresponding points in the data). The least absolute deviations estimate also arises as the maximum likelihood estimate if the errors have a Laplace distribution.</p>
<p>We now seek estimated values of the unknown parameters that minimize the sum of the absolute values of the residuals:</p>
<p><span class="math display">\[S = \sum_{i=1}^n |y_i - f(x_i)|. \]</span></p>
<table style="width:89%;">
<colgroup>
<col width="38%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Least squares regression</th>
<th>Least absolute deviations regression</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Not very robust</td>
<td>Robust</td>
</tr>
<tr class="even">
<td>Stable solution</td>
<td>Unstable solution</td>
</tr>
<tr class="odd">
<td>Always one solution</td>
<td>Possibly multiple solutions</td>
</tr>
</tbody>
</table>
</dd>
<dt>Bias of an estimator <code class="fold">@</code></dt>
<dd><p>TODO: <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">Bias of an estimator - Wikipedia, the free encyclopedia</a></p>
<p>In statistics, the bias (or bias function) of an estimator is the difference between this estimator&#8217;s expected value and the true value of the parameter being estimated. <strong>An estimator or decision rule with zero bias is called unbiased</strong>. Otherwise the estimator is said to be <strong>biased</strong>.</p>
<p>In statistics, &#8220;bias&#8221; is an objective statement about a function, and while not a desired property, it is not pejorative, unlike the ordinary English use of the term &#8220;bias&#8221;. (&#36825;&#36824;&#35299;&#37322;&#65292;&#26174;&#31034;&#22909;&#20154;&#25991;&#20851;&#24576;&#12290;)</p>
<p>Bias can also be measured with respect to the median, rather than the mean (expected value), in which case one distinguishes <strong>median-unbiased</strong> from the usual mean-unbiasedness property. Bias is related to consistency in that consistent estimators are convergent and asymptotically unbiased (hence converge to the correct value), though individual estimators in a consistent sequence may be biased (so long as the bias converges to zero); see <a href="https://en.wikipedia.org/wiki/Consistent_estimator#Bias_versus_consistency">bias versus consistency</a>.</p>
<p>All else equal, an unbiased estimator is preferable to a biased estimator, but in practice all else is not equal, and biased estimators are frequently used, generally with small bias. When a biased estimator is used, the bias is also estimated. A biased estimator may be used for various reasons: because an unbiased estimator does not exist without further assumptions about a population or is difficult to compute (as in unbiased estimation of standard deviation); because an estimator is median-unbiased but not mean-unbiased (or the reverse); because a biased estimator reduces some loss function (particularly mean squared error) compared with unbiased estimators (notably in shrinkage &#25910;&#32553;&#31243;&#24230; estimators); or because in some cases being unbiased is too strong a condition, and the only unbiased estimators are not useful. Further, mean-unbiasedness is not preserved under non-linear transformations, though median-unbiasedness is (see effect of transformations); for example, the sample variance is an unbiased estimator for the population variance, but its square root, the sample standard deviation, is a biased estimator for the population standard deviation.</p>
<p><span class="math display">\[
    \operatorname{Bias}_\theta[\,\hat\theta\,] =
    \operatorname{E}_\theta[\,\hat{\theta}\,]-\theta =
    \operatorname{E}_\theta[\, \hat\theta - \theta \,],
\]</span></p>
<p>If the sample mean and uncorrected sample variance are defined as</p>
<p><span class="math display">\[
    \overline{X}=\frac{1}{n}\sum_{i=1}^nX_i, \qquad S^2=\frac{1}{n}\sum_{i=1}^n\left(X_i-\overline{X}\,\right)^2,
\]</span></p>
<p>then <span class="math inline">\(S^2\)</span> is a biased estimator of &#963;2.</p>
</dd>
<dt>Efficient estimator <code class="fold">@</code></dt>
<dd><p>In statistics, an efficient estimator is an estimator that estimates the quantity of interest <strong>in some &#8220;best possible&#8221; manner</strong>. The notion of &#8220;best possible&#8221; relies upon the <strong>choice of a particular loss function</strong> &#8212; the function which quantifies the relative degree of undesirability of estimation errors of different magnitudes. The most common choice of the loss function is quadratic, resulting in the mean squared error criterion of optimality.</p>
<p>&#26377;&#25928;&#20272;&#35745;&#37327;&#26159;&#30456;&#23545;&#30340;&#65292;&#21487;&#20197;&#35828;&#19968;&#20010;&#20272;&#35745;&#37327;&#27604;&#21478;&#19968;&#20010;&#26377;&#25928;&#65292;&#37027;&#20040;&#23427;&#26159;&#26377;&#25928;&#20272;&#35745;&#37327;&#12290;&#20063;&#21487;&#20197;&#35828;&#22312;&#26576;&#19968;&#25439;&#22833;&#20989;&#25968;&#19979;&#26368;&#26377;&#25928;&#30340;&#37027;&#20010;&#20272;&#35745;&#37327;&#26159;&#26377;&#25928;&#20272;&#35745;&#37327;&#65288;&#27604;&#20854;&#20182;&#37117;&#26377;&#25928;&#65289;&#12290;</p>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Efficient_estimator">Efficient estimator - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Consistent estimator <code class="fold">@</code></dt>
<dd><p>In statistics, a consistent estimator or asymptotically consistent estimator is an estimator&#8212;a rule for computing estimates of a parameter &#952;0&#8212; having the property that as the number of data points used increases indefinitely, the resulting sequence of estimates converges in probability to &#952;0. This means that the distributions of the estimates become more and more concentrated near the true value of the parameter being estimated, so that the probability of the estimator being arbitrarily close to &#952;0 converges to one.</p>
<p>&#24456;&#22810;&#32479;&#35745;&#20070;&#37324;&#20250;&#32763;&#35793;&#25104;&#8220;&#19968;&#33268;&#32479;&#35745;&#37327;&#8221;&#65292;&#20854;&#23454;&#26159;&#8220;&#25345;&#32493;&#8221;&#32479;&#35745;&#37327;&#12290;&#24847;&#24605;&#26159;&#33021;&#22815;&#19981;&#26029;&#36924;&#36817;&#26399;&#26395;&#65292;&#38543;&#30528;&#26679;&#26412;&#25968;&#37327;&#30340;&#22686;&#22810;&#65292;&#36825;&#20010;&#20272;&#35745;&#31574;&#30053;&#19968;&#23450;&#20250;&#36234;&#26469;&#36234;&#38752;&#35889;&#12290;</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Consistency_of_estimator.svg/375px-Consistency_of_estimator.svg.png" alt="{T1, T2, T3, &#8230;} is a sequence of estimators for parameter &#952;0, the true value of which is 4. This sequence is consistent: the estimators are getting more and more concentrated near the true value &#952;0; at the same time, these estimators are biased. The limiting distribution of the sequence is a degenerate random variable which equals &#952;0 with probability 1." />
<p class="caption"><code>{T1, T2, T3, &#8230;}</code> is a sequence of estimators for parameter &#952;0, the true value of which is 4. This sequence is consistent: the estimators are getting more and more concentrated near the true value &#952;0; at the same time, these estimators are biased. The limiting distribution of the sequence is a degenerate random variable which equals &#952;0 with probability 1.</p>
</div>
<dl>
<dt>Bias versus consistency</dt>
<dd><p>Bias is related to consistency as follows: a sequence of estimators is consistent if and only if it converges to a value and the bias converges to zero.</p>
<p>Unbiased but not consistent</p>
<p>Biased but consistent</p>
</dd>
</dl>
</dd>
<dt>Observational error <code class="fold">@</code></dt>
<dd><p><strong>Observational error</strong> (or <strong>measurement error</strong>) is the difference between a measured value of quantity and its true value. In statistics, an error is not a &#8220;mistake&#8221;. Variability is an inherent part of things being measured and of the measurement process.</p>
<p>Measurement errors can be divided into two components: <strong>random error</strong> and <strong>systematic error</strong>. Random errors are errors in measurement that lead to measurable values being inconsistent when repeated measures of a constant attribute or quantity are taken. Systematic errors are errors that are not determined by chance but are introduced by an inaccuracy (as of observation or measurement) inherent in the system. Systematic error may also refer to an error having a nonzero mean, so that its effect is not reduced when observations are averaged.</p>
<dl>
<dt>Systematic versus random error</dt>
<dd><p>Sources of systematic error</p>
<ul>
<li><p>Imperfect calibration</p></li>
<li><p>Quantity</p>
<p>Systematic errors can be either constant, or related (e.g.&#160;proportional or a percentage) to the actual value of the measured quantity, or even to the value of a different quantity</p></li>
<li><p>Drift</p></li>
</ul>
<dl>
<dt>Sources of random error <code class="fold">@</code></dt>
<dd><p>The random or <strong>stochastic error</strong> in a measurement is the error that is random from one measurement to the next. Stochastic errors tend to be normally distributed when the stochastic error is the sum of many independent random errors because of the central limit theorem. Stochastic errors added to a regression equation account for the variation in Y that cannot be explained by the included Xs.</p>
<p>The term &#8220;observational error&#8221; is also sometimes used to refer to response errors and some other types of non-sampling error. In survey-type situations, these errors can be mistakes in the collection of data, including both the incorrect recording of a response and the correct recording of a respondent&#8217;s inaccurate response. These sources of non-sampling error are discussed in Salant and Dillman (1995) and Bland and Altman (1996).</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Stochastic_process">Stochastic process - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>In probability theory, a stochastic (<code>/sto&#650;&#712;k&#230;st&#618;k/</code>) process, or often random process, is a collection of random variables representing the evolution of some system of random values over time. This is the probabilistic counterpart to a deterministic process (or deterministic system). Instead of describing a process which can only evolve in one way (as in the case, for example, of solutions of an ordinary differential equation), in a stochastic, or random process, there is some indeterminacy: even if the initial condition (or starting point) is known, there are several (often infinitely many) directions in which the process may evolve.</p>
<p>In the simple case of discrete time, as opposed to continuous time, a stochastic process is a sequence of random variables. (For example, see Markov chain, also known as discrete-time Markov chain.) The random variables corresponding to various times may be completely different, the only requirement being that these different random quantities all take values in the same space (the codomain of the function). One approach may be to model these random variables as random functions of one or several deterministic arguments (in most cases, the time parameter). Although the random values of a stochastic process at different times may be independent random variables, in most commonly considered situations they exhibit complicated statistical dependence.</p>
<p>Familiar examples of stochastic processes include stock market and exchange rate fluctuations; signals such as speech; audio and video; medical data such as a patient&#8217;s EKG, EEG, blood pressure or temperature; and random movement such as Brownian motion or random walks.</p>
<p>A generalization, the random field, is defined by letting the variables be parametrized by members of a topological space instead of time. Examples of random fields include static images, random terrain (landscapes), wind waves and composition variations of a heterogeneous material.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/IE_Real_SandP_Prices%2C_Earnings%2C_and_Dividends_1871-2006.png/525px-IE_Real_SandP_Prices%2C_Earnings%2C_and_Dividends_1871-2006.png" alt="Stock market fluctuations have been modeled by stochastic processes." />
<p class="caption">Stock market fluctuations have been modeled by stochastic processes.</p>
</div>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>Estimator <code class="fold">@</code></dt>
<dd><p>In statistics, an estimator is a rule for calculating an estimate of a given quantity based on observed data: <strong>thus the rule (the estimator)</strong>, <strong>the quantity of interest (the estimand)</strong> and its <strong>result (the estimate)</strong> are distinguished.</p>
<p>There are point and interval estimators. The point estimators yield <strong>single-valued results</strong>, although this includes the possibility of single vector-valued results and results that can be expressed as a single function. This is in contrast to an interval estimator, where the result would be <strong>a range of plausible values</strong> (or vectors or functions).</p>
<p>Estimation theory is concerned with the <strong>properties of estimators</strong>; that is, with defining properties that can be used to compare different estimators (different rules for creating estimates) for the same quantity, based on the same data. Such properties can be used to determine the best rules to use under given circumstances. However, in robust statistics, statistical theory goes on to consider the balance between having good properties, if tightly defined assumptions hold, and having less good properties that hold under wider conditions.</p>
<dl>
<dt>Point estimation <code class="fold">@</code></dt>
<dd><p>In statistics, point estimation involves the use of sample data to calculate a single value (known as a statistic) which is to serve as a &#8220;<strong>best guess</strong>&#8221; or &#8220;<strong>best estimate</strong>&#8221; of an unknown (fixed or random) population parameter.</p>
<p>More formally, it is the application of a point estimator to the data.</p>
<p>In general, point estimation should be contrasted with interval estimation: such interval estimates are typically either confidence intervals in the case of frequentist inference, or credible intervals in the case of Bayesian inference.</p>
<p>Point estimators</p>
<ul>
<li><p><strong>minimum-variance mean-unbiased estimator (MVUE)</strong></p>
<p>minimizes the risk (expected loss) of the squared-error loss-function.</p>
<p>In statistics a uniformly minimum-variance unbiased estimator or minimum-variance unbiased estimator (UMVUE or MVUE) is an unbiased estimator that has lower variance than any other unbiased estimator for all possible values of the parameter.</p>
<p>For a normal distribution with unknown mean and variance, the sample mean and (unbiased) sample variance are the MVUEs for the population mean and population variance.</p></li>
<li><p><strong>best linear unbiased estimator (BLUE)</strong></p>
<p>In statistics, the Gauss&#8211;Markov theorem, named after Carl Friedrich Gauss and Andrey Markov, states that in a linear regression model in which the errors have expectation zero and are uncorrelated and have equal variances, the best linear unbiased estimator (BLUE) of the coefficients is given by the ordinary least squares (OLS) estimator. Here &#8220;best&#8221; means giving the lowest variance of the estimate, as compared to other unbiased, linear estimators. The errors do not need to be normal, nor do they need to be independent and identically distributed (only uncorrelated with mean zero and homoscedastic with finite variance). The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the James&#8211;Stein estimator (which also drops linearity) or ridge regression.</p>
<p>The Gauss&#8211;Markov assumptions are</p>
<ul>
<li><span class="math inline">\(E(\varepsilon_i)=0\)</span>,</li>
<li><span class="math inline">\(V(\varepsilon_i)= \sigma^2 &lt; \infty\)</span>,</li>
</ul>
<p>(i.e., all disturbances have the same variance; that is &#8220;homoscedasticity&#8221;<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a>), and</p>
<p><span class="math display">\[{\rm cov}(\varepsilon_i,\varepsilon_j) = 0, \forall i \neq j\]</span></p></li>
<li><p><strong>minimum mean squared error (MMSE)</strong></p>
<p>In statistics and signal processing, a minimum mean square error (MMSE) estimator is an estimation method which minimizes the mean square error (MSE), which is a common measure of estimator quality, of the fitted values of a dependent variable. In the Bayesian setting, the term MMSE more specifically refers to estimation with quadratic cost function. In such case, the MMSE estimator is given by the posterior mean of the parameter to be estimated. Since the posterior mean is cumbersome to calculate, the form of the MMSE estimator is usually constrained to be within a certain class of functions. Linear MMSE estimators are a popular choice since they are easy to use, calculate, and very versatile. It has given rise to many popular estimators such as the Wiener-Kolmogorov filter and Kalman filter.</p>
<p>Let x be a n <span class="math inline">\(\times\)</span> 1 hidden random vector variable, and let y be a m <span class="math inline">\(\times\)</span> 1 known random vector variable (the measurement or observation), both of them not necessarily of the same dimension. An estimator <span class="math inline">\(\hat{x}(y)\)</span> of x is any function of the measurement y. The estimation error vector is given by <span class="math inline">\(e = \hat{x} - x\)</span> and its mean squared error (MSE) is given by the trace of error covariance matrix</p>
<p><span class="math display">\[\mathrm{MSE} = \mathrm{tr} \left\{ \mathrm{E}\{(\hat{x} - x)(\hat{x} - x)^T \}\right\},\]</span></p>
<p>where the expectation <span class="math inline">\(\mathrm{E}\)</span> is taken over both x and y. When x is a scalar variable, the MSE expression simplifies to <span class="math inline">\(\mathrm{E}\)</span> <span class="math inline">\(\left\{ (\hat{x} - x)^2 \right\}\)</span>. Note that MSE can equivalently be defined in other ways, since</p>
<p><span class="math display">\[\mathrm{tr} \left\{ \mathrm{E}\{ee^T \} \right\} = \mathrm{E} \left\{ \mathrm{tr}\{ee^T \} \right\} = \mathrm{E}\{e^T e \} = \sum_{i=1}^n \mathrm{E}\{e_i^2\}.\]</span></p>
<p>The MMSE estimator is then defined as the estimator achieving minimal MSE:</p>
<p><span class="math display">\[\hat{x}_{\mathrm{MMSE}}(y) = \arg \min_{\hat{x}} \mathrm{MSE}.\]</span></p></li>
<li><p><strong>median-unbiased estimator</strong></p>
<p>Any mean-unbiased estimator minimizes the risk (expected loss) with respect to the squared-error loss function, as observed by Gauss. A median-unbiased estimator <strong>minimizes the risk with respect to the absolute-deviation loss function</strong>, as observed by Laplace. Other loss functions are used in statistical theory, particularly in robust statistics.</p></li>
<li><p><strong>maximum likelihood (ML)</strong></p>
<p>see more at <a href="#maximum-likelihood" class="uri">#maximum-likelihood</a>.</p></li>
<li><p><a href="#gmm"><strong>method of moments, generalized method of moments</strong></a></p></li>
</ul>
<dl>
<dt>Bayesian point-estimation <code class="fold">@</code></dt>
<dd><p>Bayesian inference is typically based on the posterior distribution. Many Bayesian point-estimators are the posterior distribution&#8217;s statistics of central tendency, e.g., its mean, median, or mode:</p>
<ul>
<li>Posterior mean, which minimizes the (posterior) risk (expected loss) for a squared-error loss function; in Bayesian estimation, the risk is defined in terms of the posterior distribution.</li>
<li>Posterior median, which minimizes the posterior risk for the absolute-value loss function.</li>
<li>maximum a posteriori (MAP), which finds a maximum of the posterior distribution; for a uniform prior probability, the MAP estimator coincides with the maximum-likelihood estimator;</li>
</ul>
<p>The MAP estimator has good asymptotic properties, even for many difficult problems, on which the maximum-likelihood estimator has difficulties. For regular problems, where the maximum-likelihood estimator is consistent, the maximum-likelihood estimator ultimately agrees with the MAP estimator. Bayesian estimators are admissible, by Wald&#8217;s theorem.</p>
<p>The Minimum Message Length (MML) point estimator is based in Bayesian information theory and is not so directly related to the posterior distribution.</p>
<p>Special cases of Bayesian estimators are important:</p>
<ul>
<li>Kalman filter</li>
<li>Wiener filter</li>
</ul>
<p>Several methods of computational statistics have close connections with Bayesian analysis:</p>
<ul>
<li>particle filter Markov chain Monte Carlo (MCMC)</li>
</ul>
</dd>
</dl>
<p>Properties of point estimates</p>
<ul>
<li>bias of an estimator<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></li>
<li>Cram&#233;r&#8211;Rao bound</li>
</ul>
</dd>
<dt>Interval estimation <code class="fold">@</code></dt>
<dd><p>In statistics, interval estimation is the use of sample data to calculate an interval of possible (or probable) values of an unknown population parameter, in contrast to point estimation, which is a single number. Jerzy Neyman (1937) identified interval estimation (&#8220;estimation by interval&#8221;) as distinct from point estimation (&#8220;estimation by unique estimate&#8221;). In doing so, he recognised that then-recent work quoting results in the form of an estimate plus-or-minus a standard deviation indicated that interval estimation was actually the problem statisticians really had in mind.</p>
<p>The most prevalent forms of interval estimation are:</p>
<ul>
<li><strong><a href="#confidence-interval">confidence intervals</a></strong> (a frequentist method); and</li>
<li><strong>credible intervals</strong> (a Bayesian method).</li>
</ul>
<p>Other common approaches to interval estimation, which are encompassed by statistical theory, are:</p>
<ul>
<li>Tolerance intervals</li>
<li>Prediction intervals - used mainly in Regression Analysis</li>
<li>Likelihood intervals</li>
</ul>
<p>There is another approach to statistical inference, namely <a href="#fiducial-inference"><strong>fiducial inference</strong></a>, that also considers interval estimation. Non-statistical methods that can lead to interval estimates include fuzzy logic.</p>
<p>An interval estimate is one type of outcome of a statistical analysis. Some other types of outcome are point estimates and decisions.</p>
</dd>
</dl>
</dd>
</dl>
<dl>
<dt>Kalman filter <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Basic_concept_of_Kalman_filtering.svg/600px-Basic_concept_of_Kalman_filtering.svg.png" alt="The Kalman filter keeps track of the estimated state of the system and the variance or uncertainty of the estimate. The estimate is updated using a state transition model and measurements. \hat{x}_{k\mid k-1} denotes the estimate of the system&#8217;s state at time step k before the k-th measurement yk has been taken into account; P_{k\mid k-1} is the corresponding uncertainty." />
<p class="caption">The Kalman filter keeps track of the estimated state of the system and the variance or uncertainty of the estimate. The estimate is updated using a state transition model and measurements. <span class="math inline">\(\hat{x}_{k\mid k-1}\)</span> denotes the estimate of the system&#8217;s state at time step k before the k-th measurement yk has been taken into account; <span class="math inline">\(P_{k\mid k-1}\)</span> is the corresponding uncertainty.</p>
</div>
<p>TODO</p>
</dd>
<dt>Wiener filter <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt>Bayesian statistics <code class="fold">@</code></dt>
<dd><p>Bayesian statistics, named for Thomas Bayes (1701-1761), is a theory in the field of statistics in which the evidence about the true state of the world is expressed in terms of &#8216;<strong>degrees of belief</strong>&#8217; called Bayesian probabilities. Such an interpretation is only one of a number of interpretations of probability and there are other statistical techniques that are not based on &#8216;degrees of belief&#8217;. One of the key ideas of Bayesian statistics is that &#8220;<strong>probability is orderly opinion, and that inference from data is nothing other than the revision of such opinion in the light of relevant new information.</strong>&#8221;</p>
<dl>
<dt>Bayesian linear regression <code class="fold">@</code></dt>
<dd><p>In statistics, Bayesian linear regression is an approach to linear regression in which the statistical analysis is undertaken within the context of Bayesian inference. When the regression model has errors that have a normal distribution, and if a particular form of prior distribution is assumed, explicit results are available for the posterior probability distributions of the model&#8217;s parameters.</p>
<dl>
<dt>Model setup <code class="fold">@</code></dt>
<dd><p>Consider a standard linear regression problem, in which for <span class="math inline">\(i=1,...,n\)</span> we specify the conditional distribution of <span class="math inline">\(y_i\)</span> given a k <span class="math inline">\(\times\)</span> 1 predictor vector <span class="math inline">\(\mathbf{x}_i\)</span>:</p>
<p><span class="math display">\[y_{i} = \mathbf{x}_{i}^{\rm T} \boldsymbol\beta + \epsilon_{i},\]</span></p>
<p>where <span class="math inline">\(\boldsymbol\beta\)</span> is a k <span class="math inline">\(\times\)</span> 1 vector, and the <span class="math inline">\(\epsilon_i\)</span> are iid, and <span class="math inline">\(\epsilon_{i} \sim N(0, \sigma^2).\)</span></p>
<p>This corresponds to the following likelihood function:</p>
<p><span class="math display">\[\rho(\mathbf{y}|\mathbf{X},\boldsymbol\beta,\sigma^{2}) \propto
(\sigma^{2})^{-n/2} \exp\left(-\frac{1}{2{\sigma}^{2}}(\mathbf{y}-
\mathbf{X} \boldsymbol\beta)^{\rm T}(\mathbf{y}- \mathbf{X}
\boldsymbol\beta)\right).\]</span></p>
<p>The ordinary least squares solution is to estimate the coefficient vector using the Moore-Penrose pseudoinverse:</p>
<p><span class="math display">\[\hat{\boldsymbol\beta} = (\mathbf{X}^{\rm T}\mathbf{X})^{-1}\mathbf{X}^{\rm T}\mathbf{y}\]</span></p>
<p>where <span class="math inline">\(\mathbf{X}\)</span> is the n <span class="math inline">\(\times\)</span> k design matrix, each row of which is a predictor vector <span class="math inline">\(\mathbf{x}_{i}^{\rm T}\)</span>; and <span class="math inline">\(\mathbf{y}\)</span> is the column n-vector <span class="math inline">\([y_1 \; \cdots \; y_n]^{\rm T}\)</span>.</p>
<p>This is a frequentist approach, and it assumes that there are enough measurements to say something meaningful about <span class="math inline">\(\boldsymbol\beta\)</span>. In the Bayesian approach, the data are supplemented with additional information in the form of a prior probability distribution. The prior belief about the parameters is combined with the data&#8217;s likelihood function according to Bayes theorem to yield the posterior belief about the parameters <span class="math inline">\(\boldsymbol\beta\)</span> and <span class="math inline">\(\sigma\)</span>. The prior can take different functional forms depending on the domain and the information that is available a priori.</p>
</dd>
<dt>With conjugate priors <code class="fold">@</code></dt>
<dd><p>For an arbitrary prior distribution, there may be no analytical solution for the posterior distribution. In this section, we will consider a so-called conjugate prior for which the posterior distribution can be derived analytically.</p>
<p>A prior <span class="math inline">\(\rho\)</span>(<span class="math inline">\(\boldsymbol\beta,\sigma^{2}\)</span>) is conjugate to this likelihood function if it has the same functional form with respect to <span class="math inline">\(\boldsymbol\beta\)</span> and <span class="math inline">\(\sigma\)</span>. Since the log-likelihood is quadratic in <span class="math inline">\(\boldsymbol\beta\)</span>, the log-likelihood is re-written such that the likelihood becomes normal in (<span class="math inline">\(\boldsymbol\beta-\hat{\boldsymbol\beta}\)</span>).</p>
<p>TODO</p>
<p><a href="https://en.wikipedia.org/wiki/Bayesian_linear_regression">Bayesian linear regression - Wikipedia, the free encyclopedia</a></p>
<dl>
<dt>Model evidence</dt>
<dd><p>The model evidence p(<span class="math inline">\(\mathbf{y}|m\)</span>) is the probability of the data given the model m. It is also known as the marginal likelihood, and as the prior predictive density.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>Statistical modeling <code class="fold">@</code></dt>
<dd><p>The formulation of statistical models using Bayesian statistics has the unique feature of requiring the specification of prior distributions for any unknown parameters. These prior distributions are as integral to a Bayesian approach to statistical modelling as the expression of probability distributions. Prior distributions can be either hyperparameters or hyperprior distributions.</p>
</dd>
<dt>Bayesian inference <code class="fold">@</code></dt>
<dd><p>Bayesian inference is a method of statistical inference in which Bayes&#8217; theorem is used to update the probability for a hypothesis as more evidence or information becomes available. Bayesian inference is an important technique in statistics, and especially in mathematical statistics. Bayesian updating is particularly important in the dynamic analysis of a sequence of data. Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called &#8220;Bayesian probability&#8221;.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Bayes_theorem_visualisation.svg/450px-Bayes_theorem_visualisation.svg.png" alt="A geometric visualisation of Bayes&#8217; theorem. In the table, the values w, x, y and z give the relative weights of each corresponding condition and case. The figures denote the cells of the table involved in each metric, the probability being the fraction of each figure that is shaded. This shows that P(A|B) P(B) = P(B|A) P(A) i.e.&#160;P(A|B) = P(B|A) P(A)/P(B) . Similar reasoning can be used to show that P(&#256;|B) = P(B|&#256;) P(&#256;)/P(B) etc." />
<p class="caption">A geometric visualisation of Bayes&#8217; theorem. In the table, the values w, x, y and z give the relative weights of each corresponding condition and case. The figures denote the cells of the table involved in each metric, the probability being the fraction of each figure that is shaded. This shows that P(A|B) P(B) = P(B|A) P(A) i.e.&#160;P(A|B) = P(B|A) P(A)/P(B) . Similar reasoning can be used to show that P(&#256;|B) = P(B|&#256;) P(&#256;)/P(B) etc.</p>
</div>
<dl>
<dt>Formal <code class="fold">@</code></dt>
<dd><p>Bayesian inference derives the posterior probability as a consequence of two antecedents, a prior probability and a &#8220;likelihood function&#8221; derived from a statistical model for the observed data. Bayesian inference computes the posterior probability according to Bayes&#8217; theorem:</p>
<p><span class="math display">\[P(H\mid E) = \frac{P(E\mid H) \cdot P(H)}{P(E)}\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\textstyle \mid\)</span> denotes a conditional probability;</li>
<li><span class="math inline">\(\textstyle H\)</span> stands for any hypothesis whose probability may be affected by data (called evidence below). Often there are competing hypotheses, from which one chooses the most probable. the evidence <span class="math inline">\(\textstyle E\)</span> corresponds to new data that were not used in computing the prior probability.</li>
<li><span class="math inline">\(\textstyle P(H)\)</span>, the prior probability</li>
<li><span class="math inline">\(\textstyle P(H\mid E)\)</span>, the posterior probability</li>
<li><span class="math inline">\(\textstyle P(E\mid H)\)</span> is the probability of observing <span class="math inline">\(\textstyle E\)</span> given <span class="math inline">\(\textstyle H\)</span>.</li>
<li><span class="math inline">\(\textstyle P(E)\)</span> is sometimes termed the marginal likelihood or &#8220;model evidence&#8221;. This factor is the same for all possible hypotheses being considered. (This can be seen by the fact that the hypothesis <span class="math inline">\(\textstyle H\)</span> does not appear anywhere in the symbol, unlike for all the other factors.) This means that this factor does not enter into determining the relative probabilities of different hypotheses.</li>
</ul>
<p>Note that Bayes&#8217; rule can also be written as follows:</p>
<p><span class="math display">\[P(H\mid E) = \frac{P(E\mid H)}{P(E)} \cdot P(H)\]</span></p>
<p>where the factor <span class="math inline">\(\textstyle \frac{P(E\mid H)}{P(E)}\)</span> represents the impact of E on the probability of H.</p>
</dd>
<dt>Informal <code class="fold">@</code></dt>
<dd><p>If the evidence does not match up with a hypothesis, one should reject the hypothesis. But if a hypothesis is extremely unlikely a priori, one should also reject it, even if the evidence does appear to match up.</p>
</dd>
</dl>
<p>The critical point about Bayesian inference, then, is that it provides a principled way of combining new evidence with prior beliefs, through the application of Bayes&#8217; rule. (Contrast this with frequentist inference, which relies only on the evidence as a whole, with no reference to prior beliefs.) Furthermore, Bayes&#8217; rule can be applied iteratively: after observing some evidence, the resulting posterior probability can then be treated as a prior probability, and a new posterior probability computed from new evidence. This allows for Bayesian principles to be applied to various kinds of evidence, whether viewed all at once or over time. This procedure is termed &#8220;<strong>Bayesian updating</strong>&#8221;.</p>
<dl>
<dt>Alternatives to Bayesian updating</dt>
<dd><ul>
<li>Dutch book</li>
<li>&#8220;probability kinematics&#8221;</li>
</ul>
<p>TODO</p>
</dd>
<dt>Formal description of Bayesian inference <code class="fold">@</code></dt>
<dd><p>Definitions</p>
<ul>
<li>x, a data point in general. This may in fact be a vector of values.</li>
<li><span class="math inline">\(\theta\)</span>, the parameter of the data point&#8217;s distribution, i.e., <span class="math inline">\(x \sim p(x \mid \theta)\)</span>. This may in fact be a vector of parameters.</li>
<li><span class="math inline">\(\alpha\)</span>, the hyperparameter<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> of the parameter, i.e., <span class="math inline">\(\theta \sim p(\theta \mid \alpha)\)</span>. This may in fact be a vector of hyperparameters.</li>
<li><span class="math inline">\(\mathbf{X}\)</span>, a set of n observed data points, i.e., <span class="math inline">\(x_1,\ldots,x_n\)</span>.</li>
<li><span class="math inline">\(\tilde{x}\)</span>, a new data point whose distribution is to be predicted.</li>
</ul>
<p><a href="#bayesian-inference">Bayesian inference</a></p>
<p>Bayesian prediction</p>
<ul>
<li><p>The <strong>posterior predictive distribution</strong> is the distribution of a new data point, marginalized over the posterior:</p>
<p><span class="math display">\[p(\tilde{x} \mid \mathbf{X},\alpha) = \int_{\theta} p(\tilde{x} \mid \theta) p(\theta \mid \mathbf{X},\alpha) \operatorname{d}\!\theta\]</span></p></li>
<li><p>The <strong>prior predictive distribution</strong> is the distribution of a new data point, marginalized over the prior:</p>
<p><span class="math display">\[p(\tilde{x} \mid \alpha) = \int_{\theta} p(\tilde{x} \mid \theta) p(\theta \mid \alpha) \operatorname{d}\!\theta\]</span></p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt>Bayesian inference <code id="bayesian-inference" class="anchor">@</code> <code class="fold">@</code></dt>
<dd><p>The prior distribution is the distribution of the parameter(s) before any data is observed, i.e.&#160;p() .</p>
</dd>
<dt>Naive Bayes spam filtering <code class="fold">@</code></dt>
<dd><p>TODO, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering">Naive Bayes spam filtering - Wikipedia, the free encyclopedia</a></p>
<p><span class="math display">\[\Pr(S|W) = \frac{\Pr(W|S) \cdot \Pr(S)}{\Pr(W|S) \cdot \Pr(S) + \Pr(W|H) \cdot \Pr(H)}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\Pr(S|W)\)</span> is the probability that a message is a spam, knowing that the word &#8220;replica&#8221; is in it;</li>
<li><span class="math inline">\(\Pr(S)\)</span> is the overall probability that any given message is spam;</li>
<li><span class="math inline">\(\Pr(W|S)\)</span> is the probability that the word &#8220;replica&#8221; appears in spam messages;</li>
<li><span class="math inline">\(\Pr(H)\)</span> is the overall probability that any given message is not spam (is &#8220;ham&#8221;);</li>
<li><span class="math inline">\(\Pr(W|H)\)</span> is the probability that the word &#8220;replica&#8221; appears in ham messages.</li>
</ul>
<p>The spamicity of a word</p>
<ul>
<li>&#8220;what percentage of occurrences of the word&#8221;replica&quot; appear in spam messages?&quot;</li>
<li>This quantity is called &#8220;spamicity&#8221; (or &#8220;spaminess&#8221;) of the word &#8220;replica&#8221;, and can be computed.</li>
</ul>
</dd>
<dt>Statistical hypothesis testing <code id="statistical-hypothesis-testing" class="anchor">@</code> <code class="fold">@</code></dt>
<dd><p>Statistical hypothesis testing is a key technique of both frequentist inference and Bayesian inference, although the two types of inference have notable differences. Statistical hypothesis tests define a procedure that controls (fixes) the probability of incorrectly deciding that a default position (null hypothesis) is incorrect. The procedure is based on how likely it would be for a set of observations to occur if the null hypothesis were true. Note that this probability of making an incorrect decision is not the probability that the null hypothesis is true, nor whether any specific alternative hypothesis is true. This contrasts with other possible techniques of decision theory in which the null and alternative hypothesis are treated on a more equal basis.</p>
<p>The testing process</p>
<ul>
<li>null and alternative hypotheses</li>
<li>consider the statistical assumptions</li>
<li>state the relevant test statistic T</li>
<li>significance level (&#945;)</li>
<li>Compute from the observations the observed value tobs of the test statistic T</li>
</ul>
<p>An alternative process is commonly used:</p>
<ul>
<li>Calculate the p-value</li>
</ul>
<p>If the p-value is less than the required significance level (equivalently, if the observed test statistic is in the critical region), then we say the null hypothesis is rejected at the given level of significance. Rejection of the null hypothesis is a conclusion. This is like a &#8220;guilty&#8221; verdict in a criminal trial: the evidence is sufficient to reject innocence, thus proving guilt. We might accept the alternative hypothesis (and the research hypothesis).</p>
<p>Fisher popularized the &#8220;significance test&#8221;. He required a null-hypothesis (corresponding to a population frequency distribution) and a sample. His (now familiar) calculations determined whether to reject the null-hypothesis or not. Significance testing did not utilize an alternative hypothesis so there was no concept of a Type II error.</p>
</dd>
<dt>Significance test <code class="fold">@</code></dt>
<dd><p>see <a href="#statistical-hypothesis-testing">Statistical hypothesis testing</a></p>
</dd>
<dt>Z-test <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt>Student&#8217;s t-test <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt>Bootstrapping (statistics) <code class="fold">@</code></dt>
<dd><p>In statistics, bootstrapping can refer to any test or metric that relies on <strong>random sampling with replacement</strong>. Bootstrapping allows assigning measures of accuracy (defined in terms of bias, variance, confidence intervals, prediction error or some other such measure) to sample estimates. This technique allows estimation of the sampling distribution of almost any statistic using random sampling methods. Generally, it falls in the broader class of resampling methods.</p>
<p>A great advantage of bootstrap is its <strong>simplicity</strong>. It is a straightforward way to derive estimates of standard errors and confidence intervals for complex estimators of complex parameters of the distribution, such as percentile points, proportions, odds ratio, and correlation coefficients. Bootstrap is also an appropriate way to control and check the stability of the results. Although for most problems it is impossible to know the true confidence interval, bootstrap is asymptotically more accurate than the standard intervals obtained using sample variance and assumptions of normality.</p>
<p>Although bootstrapping is (under some conditions) <strong>asymptotically (&#36880;&#28176;&#22320;) consistent</strong>, it does not provide general finite-sample guarantees. The apparent simplicity may conceal the fact that important assumptions are being made when undertaking the bootstrap analysis (e.g.&#160;independence of samples) where these would be more formally stated in other approaches.</p>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Percentile">Percentile - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>A percentile (or a centile) is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations fall. For example, the 20th percentile is the value (or score) below which 20% of the observations may be found.</p>
<p>The 25th percentile is also known as the first quartile (Q1), the 50th percentile as the median or second quartile (Q2), and the 75th percentile as the third quartile (Q3). In general, percentiles and quartiles are specific types of quantiles.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/488px-Standard_deviation_diagram.svg.png" alt="Representation of the three-sigma rule. The dark blue zone represents observations within one standard deviation (&#963;) to either side of the mean (&#956;), which accounts for about 68.2% of the population. Two standard deviations from the mean (dark and medium blue) account for about 95.4%, and three standard deviations (dark, medium, and light blue) for about 99.7%." />
<p class="caption">Representation of the three-sigma rule. The dark blue zone represents observations within one standard deviation (&#963;) to either side of the mean (&#956;), which accounts for about 68.2% of the population. Two standard deviations from the mean (dark and medium blue) account for about 95.4%, and three standard deviations (dark, medium, and light blue) for about 99.7%.</p>
</div>
<dl>
<dt><a href="https://en.wikipedia.org/wiki/Percentage_point">Percentage point - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>A percentage point (pp) is the unit for the arithmetic difference of two percentages. For example, going from 40% to 44% is a 4 percentage point increase. In the literature, the percentage point unit is usually either written out, or abbreviated as pp, p.p.&#160;or %. Consider the following hypothetical example: In 1980, 40 percent of the population smoked, and in 1990 only 30 percent smoked. One can thus say that from 1980 to 1990, the prevalence of smoking decreased by 10 percentage points although smoking did not decrease by 10 percent (actually it decreased by 25 percent) &#8211; percentages indicate ratios, not differences.</p>
</dd>
</dl>
<p>refs and see also</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule">68&#8211;95&#8211;99.7 rule - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Number_needed_to_treat">Number needed to treat - Wikipedia, the free encyclopedia</a></li>
</ul>
</dd>
</dl>
</dd>
<dt>Maximum likelihood <code id="maximum-likelihood" class="anchor">@</code> <code class="fold">@</code></dt>
<dd><p>In statistics, maximum-likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given data.</p>
<p><span class="math display">\[f(x_1,x_2,\ldots,x_n\mid\theta) = f(x_1\mid \theta)\times f(x_2|\theta) \times \cdots \times f(x_n\mid \theta).\]</span></p>
<p>likelihood:</p>
<p><span class="math display">\[
    \mathcal{L}(\theta\,;\,x_1,\ldots,x_n)
        = f(x_1,x_2,\ldots,x_n\mid\theta)
        = \prod_{i=1}^n f(x_i\mid\theta).
\]</span></p>
<p>In practice it is often more convenient to work with the logarithm of the likelihood function, called the log-likelihood:</p>
<p><span class="math display">\[\ln\mathcal{L}(\theta\,;\,x_1,\ldots,x_n) = \sum_{i=1}^n \ln f(x_i\mid\theta),\]</span></p>
<p>or the average log-likelihood:</p>
<p><span class="math display">\[\hat\ell = \frac1n \ln\mathcal{L}.\]</span></p>
<p>The method of maximum likelihood estimates &#952;0 by finding a value of &#952; that maximizes <span class="math inline">\(\scriptstyle\hat\ell(\theta;x)\)</span>. This method of estimation defines a maximum-likelihood estimator (MLE) of <span class="math inline">\(&#952;_0\)</span>:</p>
<p><span class="math display">\[\{ \hat\theta_\mathrm{mle}\} \subseteq \{ \underset{\theta\in\Theta}{\operatorname{arg\,max}}\ \hat\ell(\theta\,;\,x_1,\ldots,x_n) \},\]</span></p>
</dd>
<dt>Ground truth <code class="fold">@</code></dt>
<dd><p>Ground truth is a term used in various fields to refer to information provided by <strong>direct observation</strong> as opposed to information provided by inference.</p>
<p>&#20854;&#23454;&#23601;&#26159;&#22522;&#20934;&#20540;&#65292;&#24046;&#19981;&#37117;&#23601;&#26159; baseline&#12290;</p>
<p>In machine learning, the term &#8220;ground truth&#8221; refers to the accuracy of the training set&#8217;s classification for supervised learning techniques. This is used in statistical models to prove or disprove research hypotheses. The term &#8220;ground truthing&#8221; refers to the process of gathering the proper objective (provable) data for this test. Compare with gold standard.</p>
<p>Bayesian spam filtering is a common example of supervised learning. In this system, the algorithm is manually taught the differences between spam and non-spam. This depends on the ground truth of the messages used to train the algorithm &#8211; inaccuracies in the ground truth will correlate to inaccuracies in the resulting spam/non-spam verdicts.</p>
<dl>
<dt>Meteorology, <code>[,mi&#720;t&#618;&#601;'r&#594;l&#601;d&#658;&#618;]</code>, n. &#27668;&#35937;&#29366;&#24577;&#65292;&#27668;&#35937;&#23398; <code class="fold">@</code></dt>
<dd><p>In remote sensing, &#8220;ground truth&#8221; refers to information collected on location. Ground truth allows image data to be related to real features and materials on the ground. The collection of ground-truth data enables calibration of remote-sensing data, and aids in the interpretation and analysis of what is being sensed. Examples include cartography, meteorology, analysis of aerial photographs, satellite imagery and other techniques in which data are gathered at a distance.</p>
<p>More specifically, ground truth may refer to a process in which a pixel on a satellite image is compared to what is there in reality (at the present time) in order to verify the contents of the pixel on the image. In the case of a classified image, it allows supervised classification to help determine the accuracy of the classification performed by the remote sensing software and therefore minimize errors in the classification such as errors of commission and errors of omission.</p>
</dd>
<dt>Geographical Information Systems <code class="fold">@</code></dt>
<dd><p>Geographic information systems such as GIS, GPS, and GNSS, have become so wide-spread that the term &#8220;ground truth&#8221; has taken on special meaning in that context. If the location coordinates returned by a location method such as GPS are an estimate of a location, then the &#8220;ground truth&#8221; is the actual location on earth. A smart phone might return a set of estimated location coordinates such as 43.87870,-103.45901. The ground truth being estimated by those coordinates is the tip of George Washington&#8217;s nose on Mt. Rushmore. The accuracy of the estimate is the maximum distance between the location coordinates and the ground truth. We could say in this case that the estimate accuracy is 10 meters, meaning that the point on earth represented by the location coordinates is thought to be within 10 meters of George&#8217;s nose&#8212;the ground truth. In slang, the coordinates indicate where we think George Washington&#8217;s nose is located, and the ground truth is where it&#8217;s really at. In practice a smart phone or hand-held GPS unit is routinely able to estimate the ground truth within 6&#8211;10 meters. Specialized instruments can reduce GPS measurement error to under a centimeter</p>
</dd>
<dt>Military usage <code class="fold">@</code></dt>
<dd><p>US military slang uses &#8220;ground truth&#8221; to describe the reality of a tactical (&#25112;&#26415;&#30340;&#65307;&#31574;&#30053;&#30340;&#65307;&#21892;&#20110;&#31574;&#30053;&#30340;) situation - as opposed to intelligence reports and mission plans. The term appears in the title of the Iraq War documentary film The Ground Truth (2006), and also in military publications, for example Stars and Stripes saying: &#8220;Stripes decided to figure out what the ground truth was in Iraq.&#8221;</p>
</dd>
<dt>Etymology</dt>
<dd><p>The Oxford English Dictionary (s.v. &#8220;ground truth&#8221;) records the use of the word &#8220;Groundtruth&#8221; in the sense of a &#8220;fundamental truth&#8221; from Henry Ellison&#8217;s poem &#8220;The Siberian Exile&#8217;s Tale&#8221;, published in 1833.</p>
</dd>
</dl>
</dd>
<dt>Simpson&#8217;s paradox <code class="fold">@</code></dt>
<dd><p>Simpson&#8217;s paradox, or the Yule&#8211;Simpson effect, is a paradox in probability and statistics, in which a trend appears in different groups of data but disappears or reverses when these groups are combined. It is sometimes given the impersonal title reversal paradox or amalgamation paradox.</p>
<p>This result is often encountered in social-science and medical-science statistics, and is particularly confounding when frequency data is unduly given causal interpretations. The paradoxical elements disappear when causal relations are brought into consideration. Many statisticians believe that the mainstream public should be informed of the counter-intuitive results in statistics such as Simpson&#8217;s paradox.</p>
<dl>
<dt>UC Berkeley gender bias <code class="fold">@</code></dt>
<dd><p>One of the best-known examples of Simpson&#8217;s paradox is a study of gender bias among graduate school admissions to University of California, Berkeley. The admission figures for the fall of 1973 showed that men applying were more likely than women to be admitted, and the difference was so large that it was unlikely to be due to chance.</p>
<table style="width:46%;">
<colgroup>
<col width="11%" />
<col width="22%" />
<col width="12%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>Applicants</th>
<th align="left">Admitted</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Men</td>
<td>8442</td>
<td align="left">44%</td>
</tr>
<tr class="even">
<td>Women</td>
<td>4321</td>
<td align="left">35%</td>
</tr>
</tbody>
</table>
<p>But when examining the individual departments, it appeared that six out of 85 departments were significantly biased against men, whereas only four were significantly biased against women. In fact, the pooled and corrected data showed a &#8220;small but statistically significant bias in favor of women.&#8221; The data from the six largest departments is listed below.</p>
<div class="figure">
<img src="http://whudoc.qiniudn.com/2016/20160505203839.png" />

</div>
<p>The research paper by Bickel et al. concluded that women tended to apply to competitive departments with low rates of admission even among qualified applicants (such as in the English Department), whereas men tended to apply to less-competitive departments with high rates of admission among the qualified applicants (such as in engineering and chemistry). The conditions under which the admissions&#8217; frequency data from specific departments constitute a proper defense against charges of discrimination are formulated in the book Causality by Pearl.</p>
</dd>
</dl>
</dd>
<dt>Generating function <code class="fold">@</code></dt>
<dd><dl>
<dt>Ordinary generating function</dt>
<dd><span class="math display">\[G(a_n;x)=\sum_{n=0}^\infty a_nx^n.\]</span>
</dd>
<dt>Exponential generating function</dt>
<dd><span class="math display">\[\operatorname{EG}(a_n;x)=\sum _{n=0}^{\infty} a_n \frac{x^n}{n!}.\]</span>
</dd>
<dt>Poisson generating function</dt>
<dd><p><span class="math display">\[\operatorname{PG}(a_n;x)=\sum _{n=0}^{\infty} a_n e^{-x} \frac{x^n}{n!} = e^{-x}\, \operatorname{EG}(a_n;x).\]</span></p>
</dd>
<dt>Lambert series</dt>
<dd><p><span class="math display">\[\operatorname{LG}(a_n;x)=\sum _{n=1}^{\infty} a_n \frac{x^n}{1-x^n}.\]</span></p>
</dd>
</dl>
<p>TODO: <a href="https://en.wikipedia.org/wiki/Generating_function">Generating function - Wikipedia, the free encyclopedia</a></p>
</dd>
<dt>Moment-generating function (moment generating fuction) <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the moment-generating function of a random variable is <strong>an alternative specification of its probability distribution</strong>. Thus, it provides the basis of an alternative route to analytical results compared with working directly with pdf and CDF. There are particularly simple results for the moment-generating functions of distributions defined by the weighted sums of random variables. Note, however, that not all random variables have moment-generating functions.</p>
<p>In addition to univariate distributions, moment-generating functions can be defined for vector- or matrix-valued random variables, and can even be extended to more general cases.</p>
<p>The moment-generating function <strong>does not always exist</strong> even for real-valued arguments, <strong>unlike the characteristic function</strong>. There are relations between the behavior of the moment-generating function of a distribution and properties of the distribution, such as the existence of moments.</p>
<p>In probability theory and statistics, the moment-generating function of a random variable X is</p>
<p><span class="math display">\[M_X(t) := \mathbb{E}\!\left[e^{tX}\right], \quad t \in \mathbb{R},\]</span></p>
<p>wherever this expectation exists. In other terms, the moment-generating function can be interpreted as the expectation of the random variable <span class="math inline">\(e^{tX}\)</span>.</p>
<p><span class="math inline">\(M_X(0)\)</span> always exists and is equal to 1.</p>
<p>The reason for defining this function is that it can be used to find all the moments of the distribution. The series expansion of <span class="math inline">\(e^{tX}\)</span> is:</p>
<p><span class="math display">\[
    e^{t\,X} = 1 + t\,X + \frac{t^2\,X^2}{2!} + \frac{t^3\,X^3}{3!} + \cdots +\frac{t^n\,X^n}{n!} + \cdots.
\]</span></p>
<p>Hence:</p>
<p><span class="math display">\[
    \begin{align}
        M_X(t) = \mathbb{E}(e^{t\,X}) &amp;= 1 + t \,\mathbb{E}(X) + \frac{t^2 \,\mathbb{E}(X^2)}{2!} + \frac{t^3\,\mathbb{E}(X^3)}{3!}+\cdots + \frac{t^n\,\mathbb{E}(X^n)}{n!}+\cdots \\
                                      &amp; = 1 + tm_1 + \frac{t^2m_2}{2!} + \frac{t^3m_3}{3!}+\cdots + \frac{t^nm_n}{n!}+\cdots, \end{align}
\]</span></p>
<p>where <span class="math inline">\(m_n\)</span> is the nth moment.</p>
<table>
<colgroup>
<col width="29%" />
<col width="41%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th>Moment-generating function MX(t)</th>
<th>Characteristic function &#966;(t)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Bernoulli <span class="math inline">\(\, P(X=1)=p\)</span></td>
<td><span class="math inline">\(\, 1-p+pe^t\)</span></td>
<td><span class="math inline">\(\, 1-p+pe^{it}\)</span></td>
</tr>
<tr class="even">
<td align="left">Geometric <span class="math inline">\((1 - p)^{k-1}\,p\!\)</span></td>
<td><span class="math inline">\(\frac{p e^t}{1-(1-p) e^t}\!\)</span> <span class="math inline">\(\forall t&lt;-\ln(1-p)\!\)</span></td>
<td><span class="math inline">\(\frac{p e^{it}}{1-(1-p)\,e^{it}}\!\)</span></td>
</tr>
<tr class="odd">
<td align="left">Binomial B(n, p)</td>
<td><span class="math inline">\(\, (1-p+pe^t)^n\)</span></td>
<td><span class="math inline">\(\, (1-p+pe^{it})^n\)</span></td>
</tr>
<tr class="even">
<td align="left">Poisson Pois(&#955;)</td>
<td><span class="math inline">\(\, e^{\lambda(e^t-1)}\)</span></td>
<td><span class="math inline">\(\, e^{\lambda(e^{it}-1)}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Uniform (continuous) U(a, b)</td>
<td><span class="math inline">\(\frac{e^{tb} - e^{ta}}{t(b-a)}\)</span></td>
<td><span class="math inline">\(\frac{e^{itb} - e^{ita}}{it(b-a)}\)</span></td>
</tr>
<tr class="even">
<td align="left">Uniform (discrete) U(a, b)</td>
<td><span class="math inline">\(\, \frac{e^{at} - e^{(b+1)t}}{(b-a+1)(1-e^{t})}\)</span></td>
<td><span class="math inline">\(\, \frac{e^{ait} - e^{(b+1)it}}{(b-a+1)(1-e^{it})}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Normal N(&#956;, &#963;2)</td>
<td><span class="math inline">\(e^{t\mu + \frac{1}{2}\sigma^2t^2}\)</span></td>
<td><span class="math inline">\(e^{it\mu - \frac{1}{2}\sigma^2t^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">Chi-squared <span class="math inline">\(&#967;^2_k\)</span></td>
<td><span class="math inline">\((1 - 2t)^{-k/2}\)</span></td>
<td><span class="math inline">\((1 - 2it)^{-k/2}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Gamma &#915;(k, &#952;)</td>
<td><span class="math inline">\((1 - t\theta)^{-k}\)</span></td>
<td><span class="math inline">\((1 - it\theta)^{-k}\)</span></td>
</tr>
<tr class="even">
<td align="left">Exponential Exp(&#955;)</td>
<td><span class="math inline">\((1-t\lambda^{-1})^{-1}, \, (t&lt;\lambda)\)</span></td>
<td><span class="math inline">\((1 - it\lambda^{-1})^{-1}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Multivariate normal N(&#956;, &#931;)</td>
<td><span class="math inline">\(\, e^{t^\mathrm{T} \mu +\frac{1}{2} t^\mathrm{T} \Sigma t}\)</span></td>
<td><span class="math inline">\(e^{i t^\mathrm{T} \mu - \frac{1}{2} t^\mathrm{T} \Sigma t}\)</span></td>
</tr>
<tr class="even">
<td align="left">Degenerate &#948;a</td>
<td><span class="math inline">\(\, e^{ta}\)</span></td>
<td><span class="math inline">\(\, e^{ita}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Laplace L(&#956;, b)</td>
<td><span class="math inline">\(\, \frac{e^{t\mu}}{1 - b^2t^2}\)</span></td>
<td><span class="math inline">\(\, \frac{e^{it\mu}}{1 + b^2t^2}\)</span></td>
</tr>
<tr class="even">
<td align="left">Negative Binomial NB(r, p)</td>
<td><span class="math inline">\(\, \frac{(1-p)^r}{(1-pe^t)^r}\)</span></td>
<td><span class="math inline">\(\, \frac{(1-p)^r}{(1-pe^{it})^r}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Cauchy Cauchy(&#956;, &#952;)</td>
<td>does not exist</td>
<td><span class="math inline">\(\, e^{it\mu -\theta|t|}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Calculation</strong></p>
<p>The moment-generating function is the expectation of a function of the random variable, it can be written as:</p>
<ul>
<li><p>In the general case: <span class="math inline">\(M_X(t) = \int_{-\infty}^\infty e^{tx}\,dF(x)\)</span>, using the Riemann&#8211;Stieltjes integral, and where F is the cumulative distribution function.</p></li>
<li><p>For a discrete probability mass function, <span class="math inline">\(M_X(t)=\sum_{i=1}^\infty e^{tx_i}\, p_i\)</span></p></li>
<li><p>For a continuous probability density function, <span class="math inline">\(M_X(t) = \int_{-\infty}^\infty e^{tx} f(x)\,dx\)</span></p></li>
</ul>
<p>Note that for the case where X has a continuous probability density function &#402;(x), <span class="math inline">\(M_X(&#8722;t)\)</span> is the two-sided Laplace transform of &#402;(x).</p>
<p><span class="math display">\[
    \begin{align}
        M_X(t) &amp; = \int_{-\infty}^\infty e^{tx} f(x)\,dx \\
               &amp; = \int_{-\infty}^\infty \left( 1+ tx + \frac{t^2x^2}{2!} + \cdots + \frac{t^nx^n}{n!} + \cdots\right) f(x)\,dx \\
               &amp; = 1 + tm_1 + \frac{t^2m_2}{2!} +\cdots + \frac{t^nm_n}{n!} +\cdots,
    \end{align}
\]</span></p>
<p>where <span class="math inline">\(m_n\)</span> is the nth moment.</p>
<p><strong>Sum of independent random variables</strong></p>
<p>If <span class="math inline">\(S_n = \sum_{i=1}^{n} a_i X_i\)</span>, where the <span class="math inline">\(X_i\)</span> are independent random variables and the <span class="math inline">\(a_i\)</span> are constants, then the probability density function for <span class="math inline">\(S_n\)</span> is the convolution of the probability density functions of each of the <span class="math inline">\(X_i\)</span>, and the moment-generating function for <span class="math inline">\(S_n\)</span> is given by</p>
<p><span class="math display">\[
    M_{S_n}(t)=M_{X_1}(a_1t)M_{X_2}(a_2t)\cdots M_{X_n}(a_nt) \, .
\]</span></p>
<p><strong>Vector-valued random variables</strong></p>
<p>For vector-valued random variables X with real components, the moment-generating function is given by</p>
<p><span class="math display">\[
    M_X(t) = E\left( e^{\langle t, X \rangle}\right)
\]</span></p>
<p>where t is a vector and <span class="math inline">\(\langle \cdot, \cdot \rangle\)</span> is the dot product.</p>
<p><strong>Important properties</strong></p>
<p>Moment generating functions are positive and log-convex, with M(0) = 1.</p>
<p>An important property of the moment-generating function is that if two distributions have the same moment-generating function, then they are identical at almost all points. That is, if for all values of t,</p>
<p><span class="math display">\[M_X(t) = M_Y(t),\, \]</span></p>
<p>then</p>
<p><span class="math display">\[F_X(x) = F_Y(x) \, \]</span></p>
<p>for all values of x (or equivalently X and Y have the same distribution). This statement is not equivalent to the statement &#8220;if two distributions have the same moments, then they are identical at all points.&#8221; This is because in some cases, the moments exist and yet the moment-generating function does not, because the limit</p>
<p><span class="math display">\[
    \lim_{n \rightarrow \infty} \sum_{i=0}^n \frac{t^im_i}{i!}
\]</span></p>
<p>may not exist. The lognormal distribution is an example of when this occurs.</p>
</dd>
<dt>Characteristic function (probability theory) <code class="fold">@</code></dt>
<dd><p>In probability theory and statistics, the characteristic function of any real-valued random variable completely defines its probability distribution.</p>
<p>If a random variable admits a pdf, then the characteristic function is <strong>the inverse Fourier transform</strong> of the pdf. Thus it provides the basis of an alternative route to analytical results compared with working directly with probability density functions or cumulative distribution functions. There are particularly simple results for the characteristic functions of distributions defined by the weighted sums of random variables.</p>
<p>In addition to univariate distributions, characteristic functions can be defined for vector or matrix-valued random variables, and can also be extended to more generic cases.</p>
<p>&#36319; MGF &#19968;&#26679;&#65292;&#30456;&#27604; pdf &#26356; generalized&#65292;&#30456;&#27604; MGF &#23427;&#36824;&#24635;&#26159;&#23384;&#22312;&#12290;</p>
<p>The characteristic function <strong>always exists</strong> when treated as a function of a real-valued argument, unlike the moment-generating function. There are relations between the behavior of the characteristic function of a distribution and properties of the distribution, such as the existence of moments and the existence of a density function.</p>
<p>The characteristic function provides an alternative way for describing a random variable. Similar to the cumulative distribution function,</p>
<p><span class="math display">\[F_X(x) = \operatorname{E} \left [\mathbf{1}_{\{X\leq x\}} \right]\]</span></p>
<p>( where 1{X &#8804; x} is the indicator function &#8212; it is equal to 1 when X &#8804; x, and zero otherwise), which completely determines behavior and properties of the probability distribution of the random variable X, the characteristic function,</p>
<p><span class="math display">\[\varphi_X(t) = \operatorname{E} \left [ e^{itX} \right ],\]</span></p>
<p>also completely determines behavior and properties of the probability distribution of the random variable X. The two approaches are equivalent in the sense that knowing one of the functions it is always possible to find the other, yet they both provide different insight for understanding the features of the random variable. However, in particular cases, there can be differences in whether these functions can be represented as expressions involving simple standard functions.</p>
<p>If a random variable admits a density function, then the characteristic function is its dual, in the sense that each of them is a Fourier transform of the other. If a random variable has a moment-generating function, then the domain of the characteristic function can be extended to the complex plane, and</p>
<p><span class="math display">\[\varphi_X(-it) = M_X(t).\]</span></p>
<p>&#20613;&#31435;&#21494;&#21464;&#25442;&#26377;&#36825;&#26679;&#30340;&#24615;&#36136;&#65306;&#20004;&#20010;&#20989;&#25968;&#21367;&#31215;&#30340;&#21464;&#25442;&#31561;&#20110;&#21464;&#25442;&#30340;&#20056;&#31215;&#12290;&#22312;&#27010;&#29575;&#35770;&#20013;&#65292;&#23427;&#30340;&#21385;&#23475;&#20043;&#22788;&#20307;&#29616;&#22312;&#65306;</p>
<ul>
<li>&#20219;&#24847;&#20998;&#24067;&#36319;&#20182;&#30340;&#29305;&#24449;&#20989;&#25968;&#19968;&#19968;&#23545;&#24212;&#12290;</li>
<li>&#20004;&#20010;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#20043;&#21644;&#30340;&#29305;&#24449;&#20989;&#25968;&#23601;&#26159;&#20182;&#20204;&#20457;&#29305;&#24449;&#20989;&#25968;&#30340;&#31215;&#12290;</li>
<li>&#29305;&#24449;&#20989;&#25968;&#22312; 0 &#28857;&#38468;&#36817;&#25910;&#25947; &lt;==&gt; &#20998;&#24067;&#20989;&#25968;&#24369;&#25910;&#25947; (Levi continuous theroem)</li>
</ul>
<p>&#20004;&#20010;&#65292;&#20035;&#33267;&#22810;&#20010;&#29420;&#31435;&#38543;&#26426;&#21464;&#37327;&#20043;&#21644;&#30340;&#20998;&#24067;&#65292;&#25105;&#20204;&#21487;&#20197;&#37319;&#21462;&#36825;&#26679;&#30340;&#36335;&#24452;&#65306;</p>
<p><span class="math display">\[
    X_1 \sim F_1, \cdots, X_n \sim  F_n \\
    \Downarrow \\
    f_1(t) = Ee^{itX_1}, \cdots, f_n(t) = Ee^{itX_n}\\
    \Downarrow \\
    f(t) = Ee^{it(X_1+\cdots+X_n)}=f_1(t)\cdots f_n(t)\\
    \Downarrow \\
    \text{distribution of }  X_1 + \cdots + X_n
\]</span></p>
<p>&#36825;&#20010;&#27493;&#39588;&#22312;&#8220;&#29420;&#31435;&#21516;&#20998;&#24067;&#38543;&#26426;&#21464;&#37327;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#8221;&#30340;&#35777;&#26126;&#20013;&#36215;&#20102;&#20851;&#38190;&#20316;&#29992;&#12290;</p>
<p>&#24341;&#20837;&#29305;&#24449;&#20989;&#25968;&#26159;&#38750;&#24120;&#33258;&#28982;&#30340;&#20107;&#24773;&#65306;</p>
<ul>
<li>&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#36880;&#20010;&#27979;&#37327;&#20107;&#20214;&#31354;&#38388;&#20013;&#30340;&#21508;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#65288;&#25110;&#32773;&#20998;&#24067;&#20989;&#25968;&#65289;&#26159;&#26497;&#31471;&#22256;&#38590;&#30340;&#65292;&#30456;&#21453;&#65292;&#23545;&#22823;&#22810;&#25968;&#20998;&#24067;&#32780;&#35328;&#65292;&#30697;&#65288;&#24179;&#22343;&#20540;&#12289;&#26041;&#24046;&#20197;&#21450;&#21508;&#31181;&#39640;&#38454;&#30697;&#65289;&#24448;&#24448;&#26159;&#23481;&#26131;&#34987;&#27979;&#37327;&#30340;&#65307;</li>
<li>&#22312;&#38382;&#39064;&#21464;&#24471;&#22797;&#26434;&#20043;&#21518;&#65292;&#20877;&#26469;&#35745;&#31639;&#30697;&#65288;&#20363;&#22914;&#22343;&#20540;&#12289;&#26041;&#24046;&#31561;&#31561;&#65289;&#30340;&#26102;&#20505;&#65292;&#22914;&#26524;&#25105;&#20204;&#30693;&#36947;&#20998;&#24067;&#20989;&#25968;&#65292;&#37027;&#20040;&#25105;&#20204;&#35201;&#20570;&#30340;&#26159;&#27714;&#21644;&#19982;&#31215;&#20998;&#65292;&#32780;&#22914;&#26524;&#25105;&#20204;&#30693;&#36947;&#29305;&#24449;&#20989;&#25968;&#65292;&#22312;&#35745;&#31639;&#30697;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#35201;&#20570;&#30340;&#21482;&#26159;&#24494;&#20998;&#65292;&#32780;&#36890;&#24120;&#65292;&#27714;&#23548;&#20250;&#27604;&#30452;&#25509;&#31215;&#20998;&#26356;&#23481;&#26131;&#65292;&#32780;&#19988;&#21487;&#20197;&#38024;&#23545;&#21508;&#38454;&#30697;&#26377;&#26356;&#32479;&#19968;&#30340;&#24418;&#24335;&#12290;</li>
<li>&#32780;&#22240;&#20026;&#32771;&#34385;&#21040;&#36825;&#20004;&#20010;&#22240;&#32032;&#65292;&#20877;&#21152;&#19978; Fourier &#31354;&#38388;&#36319;&#23454;&#31354;&#38388;&#21487;&#20197;&#19968;&#19968;&#23545;&#24212;&#36215;&#26469;&#65292;&#25152;&#20197;&#22823;&#23478;&#23601;&#26356;&#21916;&#27426;&#29305;&#24449;&#20989;&#25968;&#20102;&#12290;</li>
</ul>
<p>&#25509;&#19979;&#26469;&#65292;Laplace &#21464;&#25442;&#34892;&#19981;&#34892;&#65311;</p>
<p>&#22312;&#24456;&#22810;&#26102;&#20505;&#24403;&#28982;&#20063;&#21487;&#20197;&#65292;&#24120;&#29992;&#30340;&#27597;&#20989;&#25968;&#25110;&#32773;&#29983;&#25104;&#30697;&#20989;&#25968; moment generating function &#23601;&#26159;&#36825;&#26679;&#30340;&#21464;&#25442;&#12290;&#32479;&#35745;&#29289;&#29702;&#23398;&#23478;&#24456;&#29087;&#24713;&#30340;&#12300;&#37197;&#20998;&#20989;&#25968;&#12301;&#20063;&#23601;&#26159;&#19968;&#20010;&#29305;&#24449;&#20989;&#25968;&#65306;&#65292;&#23427;&#23601;&#23545;&#24212;&#20110;&#24577;&#23494;&#24230; g(E) &#30340; Laplace &#21464;&#25442;&#12290;&#23545;&#29289;&#29702;&#23398;&#23478;&#32780;&#35328;&#65292;&#21916;&#27426;&#29992;&#36870;&#28201;&#24230;&#65288;Laplace&#65289;&#65292;&#25110;&#32773;&#21916;&#27426;&#29992;&#34394;&#26102;&#38388;&#65288;Fourier&#65289;&#36825;&#20854;&#23454;&#26159;&#19968;&#30721;&#20107;&#30340;&#65292;&#22914;&#26524;&#22312;&#36825;&#31181;&#26102;&#20505;&#29992;&#34394;&#26102;&#38388;&#26469;&#20889;&#65292;&#19968;&#20010;&#22909;&#22788;&#26159;&#26174;&#24471;&#39640;&#31471;&#22823;&#27668;&#65292;&#21478;&#19968;&#20010;&#22909;&#22788;&#26159;&#21487;&#20197;&#19982;&#36335;&#24452;&#31215;&#20998;&#32852;&#31995;&#36215;&#26469;&#65292;&#32780;&#19988;&#65292;Laplace &#21464;&#25442;&#29992;&#30340;&#26102;&#20505;&#24635;&#24471;&#35201;&#20889;&#12300;&#27491;&#21322;&#36724;&#12301;&#20043;&#31867;&#30340;&#19996;&#35199;&#65292;&#20889;&#36215;&#26469;&#22826;&#40635;&#28902;&#12290;</p>
<p>&#24863;&#35874; <span class="citation">@Andi</span> Wang &#30340;&#25351;&#25945;&#65292;&#29992; Laplace &#21464;&#25442;&#26356;&#20005;&#37325;&#30340;&#38382;&#39064;&#22312;&#20110;&#22914;&#26524; X &#26576;&#38454;&#30697;&#19981;&#23384;&#22312;&#65288; <span class="math inline">\(E|X|^k\)</span> = infinity&#65292;&#27604;&#22914;&#26607;&#35199;&#20998;&#24067;&#65289;&#65292;&#20250;&#26377;&#27597;&#20989;&#25968;&#21482;&#22312; 0 &#28857;&#26377;&#23450;&#20041;&#65292;&#20854;&#20182;&#22320;&#26041;&#22343;&#20026; infinity &#30340;&#24773;&#20917;&#12290;&#36825;&#26679;&#27597;&#20989;&#25968;&#26080;&#27861;&#19982;&#20998;&#24067;&#24314;&#31435; 1-1 &#23545;&#24212;&#20851;&#31995;&#12290;</p>
<p>refs and see also</p>
<ul>
<li><a href="http://www.zhihu.com/question/23686709">&#22914;&#20309;&#29702;&#35299;&#32479;&#35745;&#20013;&#30340;&#29305;&#24449;&#20989;&#25968;&#65311; - &#25968;&#23398; - &#30693;&#20046;</a></li>
</ul>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Jacobian_matrix">Jacobian matrix and determinant - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>In vector calculus, the Jacobian matrix (<code>/d&#658;&#7547;&#712;ko&#650;bi&#601;n/</code>, <code>/j&#7547;&#712;ko&#650;bi&#601;n/</code>) is the matrix of all <strong>first-order partial derivatives of a vector-valued function</strong>. When the matrix is a square matrix, both the matrix and its determinant are referred to as the Jacobian in literature.</p>
<p>&#23545;&#21521;&#37327;&#30340;&#19968;&#38454;&#20559;&#23548;&#12290;</p>
<p>Suppose f : &#8477;n &#8594; &#8477;m is a function which takes as input the vector x &#8712; &#8477;n and produces as output the vector f(x) &#8712; &#8477;m. Then the Jacobian matrix J of f is an m&#215;n matrix, usually defined and arranged as follows:</p>
<p>&#36825;&#20010;&#24418;&#24335;&#21644;&#25105;&#20204;&#24120;&#29992;&#24038;&#20056;&#26377;&#20851;&#12290;</p>
<p><span class="math display">\[
\mathbf J = \frac{d\mathbf f}{d\mathbf x} = \begin{bmatrix} \dfrac{\partial
\mathbf{f}}{\partial x_1} &amp; \cdots &amp; \dfrac{\partial \mathbf{f}}{\partial
x_n} \end{bmatrix} = \begin{bmatrix} \dfrac{\partial f_1}{\partial x_1} &amp;
\cdots &amp; \dfrac{\partial f_1}{\partial x_n}\\ \vdots &amp; \ddots &amp; \vdots\\
\dfrac{\partial f_m}{\partial x_1} &amp; \cdots &amp; \dfrac{\partial f_m}{\partial
x_n} \end{bmatrix}
\]</span></p>
<p>or, component-wise:</p>
<p><span class="math display">\[\mathbf J^{j}_{i} = \frac{\partial f_i}{\partial x_j} .\]</span></p>
<p>This matrix, whose entries are functions of x, is also denoted by Df, Jf, and &#8706;(f1,&#8230;,fm)/&#8706;(x1,&#8230;,xn). (Note that some literature defines the Jacobian as the transpose of the matrix given above.)</p>
<p>Consider the function f : &#8477;2 &#8594; &#8477;2 given by</p>
<p><span class="math display">\[\mathbf f(x, y) = \begin{bmatrix} x^2 y \\ 5 x + \sin y \end{bmatrix}.\]</span></p>
<p>Then we have</p>
<ul>
<li><span class="math inline">\(f_1(x, y) = x^2 y\)</span></li>
<li><span class="math inline">\(f_2(x, y) = 5 x + \sin y\)</span></li>
</ul>
<p>and the Jacobian matrix of F is</p>
<p><span class="math display">\[
\mathbf J_{\mathbf f}(x, y) = \begin{bmatrix} \dfrac{\partial f_1}{\partial
x} &amp; \dfrac{\partial f_1}{\partial y}\\[1em] \dfrac{\partial f_2}{\partial
x} &amp; \dfrac{\partial f_2}{\partial y} \end{bmatrix} = \begin{bmatrix} 2 x y
&amp; x^2 \\ 5 &amp; \cos y \end{bmatrix}
\]</span></p>
<p>and the Jacobian determinant is</p>
<p><span class="math display">\[\det(\mathbf J_{\mathbf f}(x, y)) = 2 x y \cos y - 5 x^2 .\]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Jacobian_determinant_and_distortion.svg/600px-Jacobian_determinant_and_distortion.svg.png" alt="A nonlinear map f : R2 &#8594; R2 sends a small square to a distorted parallelepiped close to the image of the square under the best linear approximation of f near the point." />
<p class="caption">A nonlinear map f : R2 &#8594; R2 sends a small square to a distorted parallelepiped close to the image of the square under the best linear approximation of f near the point.</p>
</div>
<p>If the Jacobian determinant at p is positive, then f preserves orientation near p; if it is negative, f reverses orientation. The absolute value of the Jacobian determinant at p gives us the factor by which the function f expands or shrinks volumes near p; this is why it occurs in the general substitution rule.</p>
<p>integral substitution: <span class="math inline">\(\int_{\varphi(a)}^{\varphi(b)} f(x)\,dx = \int_a^b f(\varphi(t))\varphi&#39;(t)\, dt.\)</span> <a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Hessian_matrix">Hessian matrix - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>Hessian, <code>['hesi&#601;n]</code></p>
<p>In mathematics, the Hessian matrix or Hessian is a <strong>square matrix of second-order partial derivatives of a scalar-valued function</strong>, or scalar field. It describes the local curvature of a function of many variables. The Hessian matrix was developed in the 19th century by the German mathematician Ludwig Otto Hesse and later named after him. Hesse originally used the term &#8220;functional determinants&#8221;.</p>
<p>Specifically, suppose f : &#8477;n &#8594; &#8477; is a function taking as input a vector x &#8712; &#8477;n and outputting a scalar f(x) &#8712; &#8477;; if all second partial derivatives of f exist and are continuous over the domain of the function, then the Hessian matrix H of f is a square n&#215;n matrix, usually defined and arranged as follows:</p>
<p><span class="math display">\[
\boldsymbol H = \begin{bmatrix} \dfrac{\partial^2 f}{\partial x_1^2} &amp;
\dfrac{\partial^2 f}{\partial x_1\,\partial x_2} &amp; \cdots &amp;
\dfrac{\partial^2 f}{\partial x_1\,\partial x_n} \\[2.2ex]
\dfrac{\partial^2 f}{\partial x_2\,\partial x_1} &amp; \dfrac{\partial^2
f}{\partial x_2^2} &amp; \cdots &amp; \dfrac{\partial^2 f}{\partial x_2\,\partial
x_n} \\[2.2ex] \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\[2.2ex]
\dfrac{\partial^2 f}{\partial x_n\,\partial x_1} &amp; \dfrac{\partial^2
f}{\partial x_n\,\partial x_2} &amp; \cdots &amp; \dfrac{\partial^2 f}{\partial
x_n^2} \end{bmatrix}.
\]</span></p>
<p>or, component-wise:</p>
<p><span class="math display">\[\boldsymbol H_{i,j} = \frac{\partial^2 f}{\partial x_i \partial x_j}.\]</span></p>
<p>The determinant of the above matrix is also sometimes referred to as the Hessian.</p>
<p>The Hessian matrix can be considered related to the Jacobian matrix by <span class="math inline">\(H(f)(x) = J(&#8711;f)(x)\)</span>.</p>
<p>The mixed derivatives of f are the entries off the main diagonal in the Hessian. Assuming that they are continuous, the order of differentiation does not matter (Clairaut&#8217;s theorem). For example,</p>
<p><span class="math display">\[
\frac {\partial}{\partial x_i} \left(\frac {\partial f }{\partial x_j}
\right) = \frac {\partial}{\partial x_j} \left(\frac {\partial f }{\partial
x_i} \right).
\]</span></p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Softmax_function">Softmax function - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>In mathematics, in particular probability theory and related fields, the softmax function, or normalized exponential, is a generalization of the logistic function that &#8220;squashes&#8221; a K-dimensional vector  of arbitrary real values to a K-dimensional vector () of real values in the range (0, 1) that add up to 1. The function is given by</p>
<p><span class="math display">\[\sigma(\mathbf{z})_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}}    for j = 1, ..., K.\]</span></p>
<p>The softmax function is the gradient-log-normalizer of the categorical probability distribution. For this reason, the softmax function is used in various probabilistic multiclass classification methods including multinomial logistic regression, multiclass linear discriminant analysis, naive Bayes classifiers and artificial neural networks. Specifically, in multinomial logistic regression and linear discriminant analysis, the input to the function is the result of K distinct linear functions, and the predicted probability for the j&#8217;th class given a sample vector x is:</p>
<p><span class="math display">\[P(y=j|\mathbf{x}) = \frac{e^{\mathbf{x}^\mathsf{T}\mathbf{w}_j}}{\sum_{k=1}^K e^{\mathbf{x}^\mathsf{T}\mathbf{w}_k}}\]</span></p>
<p>This can be seen as the composition of K linear functions <span class="math inline">\(\mathbf{x} \mapsto \mathbf{x}^\mathsf{T}\mathbf{w}_1, \ldots, \mathbf{x} \mapsto \mathbf{x}^\mathsf{T}\mathbf{w}_K\)</span> and the softmax function.</p>
<p>&#22312; softmax &#22238;&#24402;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#30340;&#26159;&#22810;&#20998;&#31867;&#38382;&#39064;&#65288;&#30456;&#23545;&#20110; logistic &#22238;&#24402;&#35299;&#20915;&#30340;&#20108;&#20998;&#31867;&#38382;&#39064;&#65289;&#65292;&#31867;&#26631; <span class="math inline">\(\textstyle y\)</span> &#21487;&#20197;&#21462; <span class="math inline">\(\textstyle k\)</span> &#20010;&#19981;&#21516;&#30340;&#20540;&#65288;&#32780;&#19981;&#26159; 2 &#20010;&#65289;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#35757;&#32451;&#38598; <span class="math inline">\(\{ (x^{(1)}, y^{(1)}), \ldots, (x^{(m)}, y^{(m)}) \}\)</span>&#65292;&#25105;&#20204;&#26377; <span class="math inline">\(y^{(i)} \in \{1, 2, \ldots, k\}\)</span>&#12290;&#65288;&#27880;&#24847;&#27492;&#22788;&#30340;&#31867;&#21035;&#19979;&#26631;&#20174; 1 &#24320;&#22987;&#65292;&#32780;&#19981;&#26159; 0&#65289;&#12290;&#20363;&#22914;&#65292;&#22312; MNIST &#25968;&#23383;&#35782;&#21035;&#20219;&#21153;&#20013;&#65292;&#25105;&#20204;&#26377; <span class="math inline">\(\textstyle k=10\)</span> &#20010;&#19981;&#21516;&#30340;&#31867;&#21035;&#12290;</p>
<p>&#25105;&#20204;&#30340;&#20195;&#20215;&#20989;&#25968;&#20026;&#65306;</p>
<p><span class="math display">\[
    \begin{align}
        J(\theta) = - \frac{1}{m} \left[ \sum_{i=1}^{m} \sum_{j=1}^{k}  1\left\{y^{(i)} = j\right\} \log \frac{e^{\theta_j^T x^{(i)}}}{\sum_{l=1}^k e^{ \theta_l^T x^{(i)} }}\right]
    \end{align}
\]</span></p>
<p>&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#19978;&#36848;&#20844;&#24335;&#26159; logistic &#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#30340;&#25512;&#24191;&#12290;logistic &#22238;&#24402;&#20195;&#20215;&#20989;&#25968;&#21487;&#20197;&#25913;&#20026;&#65306;</p>
<p><span class="math display">\[
    \begin{align}
        J(\theta) &amp;= -\frac{1}{m} \left[ \sum_{i=1}^m   (1-y^{(i)}) \log (1-h_\theta(x^{(i)})) + y^{(i)} \log h_\theta(x^{(i)}) \right] \\
                  &amp;= - \frac{1}{m} \left[ \sum_{i=1}^{m} \sum_{j=0}^{1} 1\left\{y^{(i)} = j\right\} \log p(y^{(i)} = j | x^{(i)} ; \theta) \right]
    \end{align}
\]</span></p>
<p>&#21487;&#20197;&#30475;&#21040;&#65292;Softmax &#20195;&#20215;&#20989;&#25968;&#19982; logistic &#20195;&#20215;&#20989;&#25968;&#22312;&#24418;&#24335;&#19978;&#38750;&#24120;&#31867;&#20284;&#65292;&#21482;&#26159;&#22312; Softmax &#25439;&#22833;&#20989;&#25968;&#20013;&#23545;&#31867;&#26631;&#35760;&#30340; <span class="math inline">\(\textstyle k\)</span> &#20010;&#21487;&#33021;&#20540;&#36827;&#34892;&#20102;&#32047;&#21152;&#12290;&#27880;&#24847;&#22312; Softmax &#22238;&#24402;&#20013;&#23558; <span class="math inline">\(\textstyle x\)</span> &#20998;&#31867;&#20026;&#31867;&#21035; <span class="math inline">\(\textstyle j\)</span> &#30340;&#27010;&#29575;&#20026;&#65306;</p>
<p><span class="math display">\[
    p(y^{(i)} = j | x^{(i)} ; \theta) = \frac{e^{\theta_j^T x^{(i)}}}{\sum_{l=1}^k e^{ \theta_l^T x^{(i)}} }
\]</span></p>
<p>&#23545;&#20110; <span class="math inline">\(\textstyle J(\theta)\)</span> &#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#38381;&#24335;&#35299;&#27861;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#36845;&#20195;&#30340;&#20248;&#21270;&#31639;&#27861;&#65288;&#20363;&#22914;&#26799;&#24230;&#19979;&#38477;&#27861;&#65292;&#25110; L-BFGS&#65289;&#12290;&#32463;&#36807;&#27714;&#23548;&#65292;&#25105;&#20204;&#24471;&#21040;&#26799;&#24230;&#20844;&#24335;&#22914;&#19979;&#65306;</p>
<p><span class="math display">\[
    \begin{align}
        \nabla_{\theta_j} J(\theta) = - \frac{1}{m} \sum_{i=1}^{m}{ \left[ x^{(i)} \left( 1\{ y^{(i)} = j\}  - p(y^{(i)} = j | x^{(i)}; \theta) \right) \right]  }
    \end{align}
\]</span></p>
<p><strong>Softmax &#22238;&#24402;&#19982; Logistic &#22238;&#24402;&#30340;&#20851;&#31995;</strong></p>
<p>&#24403;&#31867;&#21035;&#25968; <span class="math inline">\(\textstyle k = 2\)</span> &#26102;&#65292;softmax &#22238;&#24402;&#36864;&#21270;&#20026; logistic &#22238;&#24402;&#12290;&#36825;&#34920;&#26126; softmax &#22238;&#24402;&#26159; logistic &#22238;&#24402;&#30340;&#19968;&#33324;&#24418;&#24335;&#12290;&#20855;&#20307;&#22320;&#35828;&#65292;&#24403; <span class="math inline">\(\textstyle k = 2\)</span> &#26102;&#65292; softmax &#22238;&#24402;&#30340;&#20551;&#35774;&#20989;&#25968;&#20026;&#65306;</p>
<p><span class="math display">\[
\begin{align}
h_\theta(x) &amp;=
\frac{1}{ e^{\theta_1^Tx}  + e^{ \theta_2^T x^{(i)} } }
\begin{bmatrix}
e^{ \theta_1^T x } \\
e^{ \theta_2^T x }
\end{bmatrix}
\end{align}
\]</span></p>
<p>&#21033;&#29992; softmax &#22238;&#24402;&#21442;&#25968;&#20887;&#20313;&#30340;&#29305;&#28857;&#65292;&#25105;&#20204;&#20196; <span class="math inline">\(\textstyle \psi = \theta_1\)</span>&#65292;&#24182;&#19988;&#20174;&#20004;&#20010;&#21442;&#25968;&#21521;&#37327;&#20013;&#37117;&#20943;&#21435;&#21521;&#37327; <span class="math inline">\(\textstyle \theta_1\)</span>&#65292;&#24471;&#21040;:</p>
<p><span class="math display">\[
    \begin{align}
        h(x)
        &amp;=
            \frac{1}{ e^{\vec{0}^Tx}  + e^{ (\theta_2-\theta_1)^T x^{(i)} } }
            \begin{bmatrix}
            e^{ \vec{0}^T x } \\
            e^{ (\theta_2-\theta_1)^T x }
            \end{bmatrix} \\
        &amp;=
            \begin{bmatrix}
            \frac{1}{ 1 + e^{ (\theta_2-\theta_1)^T x^{(i)} } } \\
            \frac{e^{ (\theta_2-\theta_1)^T x }}{ 1 + e^{ (\theta_2-\theta_1)^T x^{(i)} } }
            \end{bmatrix} \\
        &amp;=
            \begin{bmatrix}
            \frac{1}{ 1  + e^{ (\theta_2-\theta_1)^T x^{(i)} } } \\
            1 - \frac{1}{ 1  + e^{ (\theta_2-\theta_1)^T x^{(i)} } } \\
            \end{bmatrix}
    \end{align}
\]</span></p>
<p>&#22240;&#27492;&#65292;&#29992; <span class="math inline">\(\textstyle \theta&#39;\)</span> &#26469;&#34920;&#31034; <span class="math inline">\(\textstyle \theta_2-\theta_1\)</span>&#65292;&#25105;&#20204;&#23601;&#20250;&#21457;&#29616; softmax &#22238;&#24402;&#22120;&#39044;&#27979;&#20854;&#20013;&#19968;&#20010;&#31867;&#21035;&#30340;&#27010;&#29575;&#20026; <span class="math inline">\(\textstyle \frac{1}{ 1 + e^{ (\theta&#39;)^T x^{(i)} } }\)</span>&#65292;&#21478;&#19968;&#20010;&#31867;&#21035;&#27010;&#29575;&#30340;&#20026; <span class="math inline">\(\textstyle 1 - \frac{1}{ 1 + e^{ (\theta&#39;)^T x^{(i)} } }\)</span>&#65292;&#36825;&#19982; logistic &#22238;&#24402;&#26159;&#19968;&#33268;&#30340;&#12290;</p>
<p>&#22312;&#31532;&#19968;&#20010;&#20363;&#23376;&#20013;&#65292;&#19977;&#20010;&#31867;&#21035;&#26159;&#20114;&#26021;&#30340;&#65292;&#22240;&#27492;&#26356;&#36866;&#20110;&#36873;&#25321; softmax &#22238;&#24402;&#20998;&#31867;&#22120; &#12290;&#32780;&#22312;&#31532;&#20108;&#20010;&#20363;&#23376;&#20013;&#65292;&#24314;&#31435;&#19977;&#20010;&#29420;&#31435;&#30340; logistic &#22238;&#24402;&#20998;&#31867;&#22120;&#26356;&#21152;&#21512;&#36866;&#12290;</p>
<p>&#26435;&#37325;&#34928;&#20943; weight decay</p>
<p>refs and see also</p>
<ul>
<li><a href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92">Softmax &#22238;&#24402; - Ufldl</a></li>
</ul>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Hyperbolic_function#Tanh">Hyperbolic function - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Hyperbolic_functions-2.svg/444px-Hyperbolic_functions-2.svg.png" alt="A ray through the unit hyperbola \scriptstyle x^2\ -\ y^2\ =\ 1 in the point \scriptstyle (\cosh\,a,\,\sinh\,a), where \scriptstyle a is twice the area between the ray, the hyperbola, and the \scriptstyle x-axis. For points on the hyperbola below the \scriptstyle x-axis, the area is considered negative (see animated version with comparison with the trigonometric (circular) functions)." />
<p class="caption">A ray through the unit hyperbola <span class="math inline">\(\scriptstyle x^2\ -\ y^2\ =\ 1\)</span> in the point <span class="math inline">\(\scriptstyle (\cosh\,a,\,\sinh\,a),\)</span> where <span class="math inline">\(\scriptstyle a\)</span> is twice the area between the ray, the hyperbola, and the <span class="math inline">\(\scriptstyle x-axis\)</span>. For points on the hyperbola below the <span class="math inline">\(\scriptstyle x-axis\)</span>, the area is considered negative (see animated version with comparison with the trigonometric (circular) functions).</p>
</div>
<p>hyperbola, <code>[ha&#618;'p&#604;:b&#601;l&#601;]</code>, n.&#21452;&#26354;&#32447;</p>
<p>In mathematics, hyperbolic functions are analogs of the ordinary trigonometric, or circular functions. The basic hyperbolic functions are the hyperbolic sine &#8220;sinh&#8221; (<code>/&#712;s&#618;nt&#643;/</code> or <code>/&#712;&#643;a&#618;n/</code>), and the hyperbolic cosine &#8220;cosh&#8221; (<code>/&#712;k&#594;&#643;/</code>), from which are derived the hyperbolic tangent &#8220;tanh&#8221; (<code>/&#712;t&#230;nt&#643;/</code> or <code>/&#712;&#952;&#230;n/</code>), hyperbolic cosecant &#8220;csch&#8221; or &#8220;cosech&#8221; (/&#712; ko&#650;&#643;&#603;k/ or <code>/&#712;ko&#650;s&#603;t&#643;/</code>), hyperbolic secant &#8220;sech&#8221; (<code>/&#712;&#643;&#603;k/</code> or <code>/&#712;s&#603;t&#643;/</code>), and hyperbolic cotangent &#8220;coth&#8221; (<code>/&#712;ko&#650;&#952;/</code> or <code>/&#712;k&#594;&#952;/</code>), corresponding to the derived trigonometric functions. The inverse hyperbolic functions are the area hyperbolic sine &#8220;arsinh&#8221; (also called &#8220;asinh&#8221; or sometimes &#8220;arcsinh&#8221;) and so on.</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Latent_variable_model">Latent variable model - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>latent, <code>['le&#618;t(&#601;)nt]</code>, adj.&#28508;&#22312;&#30340;&#65307;&#28508;&#20239;&#30340;&#65307;&#38544;&#34255;&#30340; n.&#38544;&#32422;&#30340;&#25351;&#21360;&#32593;&#32476;&#23384;&#22312;&#20294;&#30475;&#19981;&#35265;&#30340;&#65307;&#38544;&#24615;&#30340;&#65307;&#28508;&#20239;&#24615;</p>
<p>A <strong>latent variable model</strong> is a statistical model that relates a set of variables (so-called manifest variables) to a set of latent variables.</p>
<p>It is assumed that the responses on the indicators or manifest variables are the result of an individual&#8217;s position on the latent variable(s), and that the manifest variables have nothing in common after controlling for the latent variable (local independence).</p>
<p>Different types of the latent variable model can be grouped according to whether the manifest and latent variables are categorical or continuous:</p>
<table>
<colgroup>
<col width="26%" />
<col width="36%" />
<col width="36%" />
</colgroup>
<tbody>
<tr class="odd">
<td></td>
<td align="left">Manifest variables</td>
<td></td>
</tr>
<tr class="even">
<td>Latent variables</td>
<td align="left">Continuous</td>
<td>Categorical</td>
</tr>
</tbody>
</table>
<p>Continuous Factor analysis Item response theory</p>
<p>Categorical Latent profile analysis Latent class analysis &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;- &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8211; &#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Matrix_multiplication">Matrix multiplication - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Matrix_multiplication_row_column_correspondance.svg/450px-Matrix_multiplication_row_column_correspondance.svg.png" alt="Arithmetic process of multiplying numbers (solid lines) in row i in matrix A and column j in matrix B, then adding the terms (dashed lines) to obtain entry ij in the final matrix." />
<p class="caption">Arithmetic process of multiplying numbers (solid lines) in row i in matrix A and column j in matrix B, then adding the terms (dashed lines) to obtain entry ij in the final matrix.</p>
</div>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Matrix_multiplication_diagram_2.svg/470px-Matrix_multiplication_diagram_2.svg.png" />

</div>
<ul>
<li><p>Not commutative:</p></li>
<li><p>Distributive over matrix addition:</p>
<ul>
<li>Left distributivity</li>
<li>Right distributivity</li>
<li>Scalar multiplication is compatible with matrix multiplication</li>
</ul></li>
<li><p>Transpose</p>
<p><span class="math display">\[(\mathbf{AB})^\mathrm{T} = \mathbf{B}^\mathrm{T}\mathbf{A}^\mathrm{T}\]</span></p>
<p>where T denotes the transpose, the interchange of row i with column i in a matrix. This identity holds for any matrices over a commutative ring, but not for all rings in general. Note that A and B are reversed.</p></li>
<li><p>Complex conjugate</p>
<p>If A and B have complex entries, then</p>
<p><span class="math display">\[(\mathbf{AB})^\star = \mathbf{A}^\star\mathbf{B}^\star\]</span></p>
<p>where <code>*</code> denotes the complex conjugate of a matrix.</p></li>
</ul>
<p>refs and see also</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Kronecker_product">Kronecker product - Wikipedia, the free encyclopedia</a></li>
</ul>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Convolution">Convolution - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>The convolution of f and g is written f&#8727;g, using an asterisk or star. It is defined as the integral of the product of the two functions after one is reversed and shifted. As such, it is a particular kind of integral transform:</p>
<p><span class="math display">\[
    \begin{align}
        (f * g )(t)\ \ \, &amp;\stackrel{\mathrm{def}}{=}\ \int_{-\infty}^\infty f(\tau)\, g(t - \tau)\, d\tau \\
                          &amp;= \int_{-\infty}^\infty f(t-\tau)\, g(\tau)\, d\tau.
    \end{align}
\]</span></p>
<p>While the symbol t is used above, it need not represent the time domain. But in that context, the convolution formula can be described as a weighted average of the function f(&#964;) at the moment t where the weighting is given by g(&#8722;&#964;) simply shifted by amount t. As t changes, the weighting function emphasizes different parts of the input function.</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Spline_(mathematics)">Spline (mathematics) - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision and recall - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png" />

</div>
<p><a href="http://nlp.stanford.edu/IR-book/roc.html">Precision Recall vs ROC (Receiver Operating Characteristic)</a></p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/H-theorem">H-theorem - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">Entropy (information theory) - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><p>TODO</p>
</dd>
<dt><a href="https://en.wikipedia.org/wiki/Information_retrieval">Information retrieval - Wikipedia, the free encyclopedia</a> <code class="fold">@</code></dt>
<dd><dl>
<dt>Average precision <code class="fold">@</code></dt>
<dd><p>Precision and recall are single-value metrics based on the whole list of documents returned by the system. For systems that return a ranked sequence of documents, it is desirable to also consider the order in which the returned documents are presented. By computing a precision and recall at every position in the ranked sequence of documents, one can plot a <strong>precision-recall curve</strong>, plotting precision <span class="math inline">\({\displaystyle p(r)}\)</span> as a function of recall <span class="math inline">\({\displaystyle r}\)</span>. Average precision computes the average value of <span class="math inline">\({\displaystyle p(r)}\)</span> over the interval from <span class="math inline">\({\displaystyle r=0}\)</span> to <span class="math inline">\({\displaystyle r=1}\)</span>:</p>
<p><span class="math display">\[
    \operatorname {AveP} =\int _{0}^{1}p(r)dr
\]</span></p>
<p>That is the area under the precision-recall curve. This integral is in practice replaced with a finite sum over every position in the ranked sequence of documents:</p>
<p><span class="math display">\[
    \displaystyle \operatorname {AveP} =\sum _{k=1}^{n}P(k)\Delta r(k)
\]</span></p>
<p>where <span class="math inline">\({\displaystyle k}\)</span> is the rank in the sequence of retrieved documents, <span class="math inline">\({\displaystyle n}\)</span> is the number of retrieved documents, <span class="math inline">\({\displaystyle P(k)}\)</span> is the precision at cut-off <span class="math inline">\({\displaystyle k}\)</span> in the list, and <span class="math inline">\({\displaystyle \Delta r(k)}\)</span> is the change in recall from items <span class="math inline">\({\displaystyle k-1}\)</span> to <span class="math inline">\({\displaystyle k}\)</span>.</p>
<p>This finite sum is equivalent to:</p>
<p><span class="math display">\[
    \displaystyle \operatorname {AveP} ={\frac {\sum _{k=1}^{n}(P(k)\times \operatorname {rel} (k))}{\mbox{number of relevant documents}}}\!
\]</span></p>
<p>where <span class="math inline">\({\displaystyle \operatorname {rel} (k)}\)</span> is an indicator function equaling 1 if the item at rank <span class="math inline">\({\displaystyle k}\)</span> is a relevant document, zero otherwise. Note that the average is over all relevant documents and the relevant documents not retrieved get a precision score of zero.</p>
<p>Some authors choose to interpolate the <span class="math inline">\({\displaystyle p(r)}\)</span> function to reduce the impact of &#8220;wiggles&#8221; in the curve. For example, the PASCAL Visual Object Classes challenge (a benchmark for computer vision object detection) computes average precision by averaging the precision over a set of evenly spaced recall levels {0, 0.1, 0.2, &#8230; 1.0}:</p>
<p>AveP = 1 11 &#8721; r &#8712; { 0 , 0.1 , &#8230; , 1.0 } p interp ( r ) { ={}<em>{r{0,0.1,,1.0}}p</em>{ }(r)}</p>
<p>where p interp ( r ) {p_{ }(r)} is an interpolated precision that takes the maximum precision over all recalls greater than r {r} :</p>
<p>p interp ( r ) = max r ~ : r ~ &#8805; r &#8289; p ( r ~ ) {p_{ }(r)= _{{}:{}r}p({})} .</p>
<p>An alternative is to derive an analytical p ( r ) {p(r)} function by assuming a particular parametric distribution for the underlying decision values. For example, a binormal precision-recall curve can be obtained by assuming decision values in both classes to follow a Gaussian distribution.</p>
<p>&#19979;&#38754;&#36825;&#20010;&#35299;&#37322;&#20063;&#24456;&#28165;&#26970;&#65306;</p>
<dl>
<dt><a href="https://www.kaggle.com/c/FacebookRecruiting/forums/t/2002/alternate-explanation-of-mean-average-precision">Alternate explanation of Mean Average Precision - Facebook Recruiting Competition | Kaggle</a></dt>
<dd><p>this.</p>
</dd>
</dl>
<p><a href="http://www.cnblogs.com/ywl925/archive/2013/08/16/3262209.html">IR &#30340;&#35780;&#20215;&#25351;&#26631; - MAP,NDCG &#21644; MRR - ywl925 - &#21338;&#23458;&#22253;</a></p>
<p>refs and see also</p>
<ul>
<li><a href="https://www.kaggle.com/wiki/MeanAveragePrecision">Mean Average Precision | Kaggle</a></li>
<li><a href="http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-ranked-retrieval-results-1.html">Evaluation of ranked retrieval results</a></li>
<li><a href="http://nlp.stanford.edu/IR-book/roc.html">Precision Recall vs ROC (Receiver Operating Characteristic)</a></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<hr />
<p>refs and see also</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian inference - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Beta_function">Beta function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">Bias of an estimator - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">Bootstrapping (statistics) - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">Chi-squared distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Classical_definition_of_probability">Classical definition of probability - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Confidence_interval">Confidence interval - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Consistent_estimator">Consistent estimator - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Consistent_estimator">Consistent estimator - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Covariance">Covariance - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound">Cram&#233;r&#8211;Rao bound - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">Cumulative distribution function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Error_function">Error function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Estimator">Estimator - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant">Euler&#8211;Mascheroni constant - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Expected_value">Expected value - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/F-distribution">F-distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fiducial_inference">Fiducial inference - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gamma_distribution">Gamma distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gamma_function">Gamma function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Generalized_method_of_moments">Generalized method of moments - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ground_truth">Ground truth - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Homoscedasticity">Homoscedasticity - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hypergeometric_distribution">Hypergeometric distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">Independent and identically distributed random variables - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Joint_probability_distribution">Joint probability distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician">Law of the unconscious statistician - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Least_absolute_deviations">Least absolute deviations - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Least_squares">Least squares - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Linear_regression">Linear regression - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Marginal_distribution">Marginal distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Maximum_likelihood">Maximum likelihood - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Minimum_mean_square_error">Minimum mean square error - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Minimum-variance_unbiased_estimator">Minimum-variance unbiased estimator - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Moment_(mathematics)">Moment (mathematics) - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo method - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering">Naive Bayes spam filtering - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative binomial distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Nonlinear_regression">Nonlinear regression - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Nonparametric_regression">Nonparametric regression - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Nonparametric_regression">Nonparametric regression - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Observational_error#Systematic_versus_random_error">Observational error - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">Ordinary least squares - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pivotal_quantity">Pivotal quantity - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Poisson_limit_theorem">Poisson limit theorem - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probability">Probability - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probability_mass_function">Probability mass function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probability_space">Probability space - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Probability_theory">Probability theory - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Q-function">Q-function - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Regression_analysis">Regression analysis - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Residual_sum_of_squares">Residual sum of squares - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">Sampling (statistics) - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Standard_error">Standard error - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Standard_score">Standard score - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stanine">Stanine - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">Statistical hypothesis testing - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">Student&#8217;s t-distribution - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Survey_methodology">Survey methodology - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Tolerance_interval">Tolerance interval - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">Uniform distribution (continuous) - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Uniform_distribution_(discrete)">Uniform distribution (discrete) - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Variance">Variance - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Z-test">Z-test - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/T-statistic">t-statistic - Wikipedia, the free encyclopedia</a></li>
<li><a href="https://en.wikipedia.org/wiki/Generating_function">Generating function - Wikipedia, the free encyclopedia</a></li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Gamma (uppercase &#915;, lowercase &#947;; Greek: &#915;&#940;&#956;&#956;&#945; G&#225;mma) is the third letter of the Greek alphabet.<a href="#fnref1">&#8617;</a></p></li>
<li id="fn2"><p>In mathematics, a c&#224;dl&#224;g (French &#8220;continue &#224; droite, limite &#224; gauche&#8221;), <strong>RCLL (&#8220;right continuous with left limits&#8221;)</strong>, or corlol (&#8220;continuous on (the) right, limit on (the) left&#8221;) function is a function defined on the real numbers (or a subset of them) that is everywhere right-continuous and has left limits everywhere. C&#224;dl&#224;g functions are important in the study of stochastic processes that admit (or even require) jumps, unlike Brownian motion, which has continuous sample paths. The collection of c&#224;dl&#224;g functions on a given domain is known as Skorokhod space.</p>
<p>see more at <a href="https://en.wikipedia.org/wiki/C%C3%A0dl%C3%A0g">C&#224;dl&#224;g - Wikipedia, the free encyclopedia</a>.<a href="#fnref2">&#8617;</a></p></li>
<li id="fn3"><p><span class="math display">\[\binom{k+r-1}{k} = \frac{(k+r-1)!}{k!\,(r-1)!} = \frac{(k+r-1)(k+r-2)\dotsm(r)}{k!}.\]</span></p>
<p>see more at <a href="https://en.wikipedia.org/wiki/Binomial_coefficient">Binomial coefficient - Wikipedia, the free encyclopedia</a>.<a href="#fnref3">&#8617;</a></p></li>
<li id="fn4"><p>homoscedasticity<a href="#fnref4">&#8617;</a></p></li>
<li id="fn5"><p>In statistics, the bias (or bias function) of an estimator is the difference between this estimator&#8217;s expected value and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased. Otherwise the estimator is said to be biased. In statistics, &#8220;bias&#8221; is an objective statement about a function, and while not a desired property, it is not pejorative, unlike the ordinary English use of the term &#8220;bias&#8221;.<a href="#fnref5">&#8617;</a></p></li>
<li id="fn6"><p>In Bayesian statistics, a hyperparameter is a parameter of a prior distribution; the term is used to distinguish them from parameters of the model for the underlying system under analysis.</p>
<p>For example, if one is using a beta distribution to model the distribution of the parameter p of a Bernoulli distribution, then:</p>
<ul>
<li>p is a parameter of the underlying system (Bernoulli distribution), and</li>
<li>&#945; and &#946; are parameters of the prior distribution (beta distribution), hence hyperparameters.</li>
</ul>
<p>One may take a single value for a given hyperparameter, or one can iterate and take a probability distribution on the hyperparameter itself, called a hyperprior.</p>
<p>see more at <a href="https://en.wikipedia.org/wiki/Hyperparameter">Hyperparameter - Wikipedia, the free encyclopedia</a>.<a href="#fnref6">&#8617;</a></p></li>
<li id="fn7"><p><a href="https://en.wikipedia.org/wiki/Integration_by_substitution">Integration by substitution - Wikipedia, the free encyclopedia</a>.<a href="#fnref7">&#8617;</a></p></li>
</ol>
</div>
</div>
<script src="../lazyload.min.js"></script>
<script src="../jquery-3.0.0.min.js"></script>
<script src="../jquery.idTabs.min.js"></script>
<script src="../egg.min.js"></script>
<script src="../clipboard.min.js"></script>
<script src="../notes.js"></script>
</body>
</html>
