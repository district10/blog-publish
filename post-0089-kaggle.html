<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="generator" content="pandoc" />
  <meta name="author" content="TANG ZhiXiong; dvorak4tzx; district10" />
  <meta name="date" content="2016-03-07" />
  <title>Kaggle</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="jquery-ui.css" type="text/css" />
  <link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
  <link rel="stylesheet" href="main.css" type="text/css" />
  <link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
<style> pre { font-size: 80%; } </style>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title">Kaggle</h1>
<h3 class="date">2016-03-07</h3>
</div>
<div id="tocbox" class="pokerface">
    <div id="tocboxheader">&#xf03b;</div>
    <div id="tocboxbody">
        <ul>
        <li><a href="#kaggle">Kaggle</a><ul>
        <li><a href="#notes">Notes</a></li>
        <li><a href="#todo">TODO</a></li>
        </ul></li>
        </ul>
    </div>
</div>
<div id="navigator" class="pokerface"><a id="gotoindex" href="index.html" title="&#25353;&#19979;&#12304;h&#12305;&#33719;&#21462;&#39029;&#38754;&#24110;&#21161;&#12290;">&#xf015;</a></div>
<h1 id="kaggle">Kaggle</h1>
<div class="tzx-tabs">
<ul>
<li><a href="#p0line20">Kaggle Intro</a></li>
<li><a href="#p31line21">Prizes</a></li>
<li><a href="#p60line34">Evaluation</a></li>
<li><a href="#p31line42">Competition Rules</a></li>
<li><a href="#p26line24">Other Useful Info</a></li>
</ul>
<div id="p0line20">
<p>Kaggle is the world&#8217;s largest community of data scientists. They compete with each other to solve complex data science problems, and the top competitors are invited to work on the most interesting and sensitive business problems from some of the world&#8217;s biggest companies through Masters competitions.</p>
<p>Kaggle provides cutting-edge data science results to companies of all sizes. We have a proven track-record of solving real-world problems across a diverse array of industries including life sciences, financial services, energy, information technology, and retail.</p>
</div>
<div id="p31line21">
<p>The confidence to go forward and compete for some serious <code>$$$$$$</code>.</p>
</div>
<div id="p26line24">
<dl>
<dt><a href="https://www.kaggle.com/c/titanic/details/frequently-asked-questions">Frequently Asked Questions - Titanic: Machine Learning from Disaster | Kaggle</a></dt>
<dd>nil
</dd>
<dt><a href="https://www.kaggle.com/c/titanic/details/further-reading-watching">Further Reading / Watching - Titanic: Machine Learning from Disaster | Kaggle</a></dt>
<dd><p>readings</p>
<ol>
<li><a href="http://blog.kaggle.com/2013/01/17/getting-started-with-pandas-predicting-sat-scores-for-new-york-city-schools/">Getting Started with Pandas &#8211; Predicting SAT Scores for New York City Schools | no free hunch</a></li>
</ol>
</dd>
</dl>
</div>
<div id="p60line34">
<p>The historical data has been split into two groups, a &#8216;training set&#8217; and a &#8216;test set&#8217;. For the training set, we provide the outcome ( &#8216;ground truth&#8217; ) for each passenger. You will use this set to build your model to generate predictions for the test set.</p>
<p>For each passenger in the test set, you must predict whether or not they survived the sinking ( 0 for deceased, 1 for survived ). Your score is the percentage of passengers you correctly predict.</p>
<p>The Kaggle leaderboard has a public and private component. 50% of your predictions for the test set have been randomly assigned to the public leaderboard ( the same 50% for all users ). Your score on this public portion is what will appear on the leaderboard. At the end of the contest, we will reveal your score on the private 50% of the data, which will determine the final winner. This method prevents users from &#8216;overfitting&#8217; to the leaderboard.</p>
</div>
<div id="p31line42">
<ul>
<li>One account per participant: no private sharing outside teams</li>
<li>Privately sharing code or data outside of teams is not permitted. It&#8217;s okay to share code if made available to all participants on the forums.</li>
<li>Team Mergers: yeah, we can merge teams</li>
<li>Team Limits: nil</li>
<li>Submission Limits@ 10 entries/day, up to 5 final sumbissions for judging</li>
<li>Competition Timeline: start &#8211; merger/submission deadline, end date</li>
<li>This is a fun competition aimed at helping you get started with machine learning. While the Titanic dataset is publically available on the internet, looking up the answers defeats the entire purpose. So seriously, don&#8217;t do that.</li>
<li>Rules Acceptance: I accepted these rules at 7:06 am, Monday 7 March 2016 UTC.</li>
</ul>
</div>
</div>
<p>Tutorials</p>
<ol>
<li><a href="http://nbviewer.jupyter.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb" class="uri">http://nbviewer.jupyter.org/github/agconti/kaggle-titanic/blob/master/Titanic.ipynb</a></li>
<li><a href="http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb" class="uri">http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb</a></li>
<li><a href="http://nbviewer.jupyter.org/github/agconti/BlueBook/blob/master/BlueBook.ipynb" class="uri">http://nbviewer.jupyter.org/github/agconti/BlueBook/blob/master/BlueBook.ipynb</a></li>
<li><a href="https://github.com/wehrley/wehrley.github.io/blob/master/SOUPTONUTS.md" class="uri">https://github.com/wehrley/wehrley.github.io/blob/master/SOUPTONUTS.md</a></li>
</ol>
<!--
<div class="tzx-tabs">
* [](#)
* [](#)

<div id="">
</div>

~~~ {# .c}
~~~
</div>
-->
<h2 id="notes">Notes</h2>
<p>Let <span class="math inline">\((x1, x2, &#8230;, xn)\)</span> be an independent and identically distributed sample drawn from some distribution with an unknown density <span class="math inline">\(&#402;\)</span>. We are interested in estimating the shape of this function <span class="math inline">\(&#402;\)</span>. Its kernel density estimator is</p>
<p><span class="math display">\[\hat{f}_h(x) = \frac{1}{n}\sum_{i=1}^n K_h (x - x_i) = \frac{1}{nh} \sum_{i=1}^n K\Big(\frac{x-x_i}{h}\Big), \]</span></p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Kernel_density.svg/375px-Kernel_density.svg.png" alt="Kernel density estimation of 100 normally distributed random numbers using different smoothing bandwidths." />
<p class="caption">Kernel density estimation of 100 normally distributed random numbers using different smoothing bandwidths.</p>
</div>
<p>where <span class="math inline">\(K(&#8226;)\)</span> is the kernel &#8212; a non-negative function that integrates to one and has mean zero &#8212; and h &gt; 0 is a smoothing parameter called the bandwidth. A kernel with subscript h is called the scaled kernel and defined as <span class="math inline">\(Kh(x) = 1/h K(x/h)\)</span>. Intuitively one wants to choose h as small as the data allow, however there is always a trade-off between the bias of the estimator and its variance; more on the choice of bandwidth below.</p>
<div class="figure">
<img src="https://upload.wikimedia.org/wikipedia/en/thumb/4/41/Comparison_of_1D_histogram_and_KDE.png/750px-Comparison_of_1D_histogram_and_KDE.png" alt="Comparison of the histogram (left) and kernel density estimate (right) constructed using the same data. The 6 individual kernels are the red dashed curves, the kernel density estimate the blue curves. The data points are the rug plot on the horizontal axis." />
<p class="caption">Comparison of the histogram (left) and kernel density estimate (right) constructed using the same data. The 6 individual kernels are the red dashed curves, the kernel density estimate the blue curves. The data points are the rug plot on the horizontal axis.</p>
</div>
<h2 id="todo">TODO</h2>
<ol>
<li><a href="https://bitbucket.org/hrojas/learn-pandas">hrojas / Learn Pandas &#8212; Bitbucket</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/01%20-%20Lesson.ipynb">Learn Pandas 01</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/02%20-%20Lesson.ipynb">Learn Pandas 02</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/03%20-%20Lesson.ipynb">Learn Pandas 03</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/04%20-%20Lesson.ipynb">Learn Pandas 04</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/05%20-%20Lesson.ipynb">Learn Pandas 05</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/06%20-%20Lesson.ipynb">Learn Pandas 06</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/07%20-%20Lesson.ipynb">Learn Pandas 07</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/08%20-%20Lesson.ipynb">Learn Pandas 08</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/09%20-%20Lesson.ipynb">Learn Pandas 09</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/10%20-%20Lesson.ipynb">Learn Pandas 10</a></li>
<li><a href="http://nbviewer.jupyter.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/11%20-%20Lesson.ipynb">Learn Pandas 11</a></li>
<li><a href="https://pandasbootcamp.herokuapp.com/">Pandas Bootcamp</a></li>
</ol>
<hr />
<p>refs and see also</p>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">Kernel density estimation - Wikipedia, the free encyclopedia</a></li>
</ol>
<ul class="tzx-tags-group">
<li><a class="tzx-tag" href="tags.html/#kaggle">kaggle</a></li>
</ul>

<div class="tzx-changes"><select id="tzx-changes" title="&#21382;&#21490;&#29256;&#26412;">
<option value="https://raw.githubusercontent.com/district10/blog/5a7d1f7d62a5cd8a23e9aaa6609f69393870e372/_posts/post-0089-kaggle.md" title="10 insertions(+), 23 deletions(-)">1480428507</option>
<option value="https://raw.githubusercontent.com/district10/blog/b08a696f534c650b0d7fccc3b0b1d7d0d68c6d3d/_posts/post-0089-kaggle.md" title="163 insertions(+), 0 deletions(-)">1480083296</option>
</select></div>

<script>
var tzxFilename = "_posts/post-0089-kaggle.md";
var tzxChanges = [
    {
        hash: "5a7d1f7d62a5cd8a23e9aaa6609f69393870e372",
        datetime: "1480428507",
        insertions: 10,
        deletions: 23
    },
    {
        hash: "b08a696f534c650b0d7fccc3b0b1d7d0d68c6d3d",
        datetime: "1480083296",
        insertions: 163,
        deletions: 0
    },
];
</script>

<script type="text/javascript" src="jquery.min.js"></script>
<script type="text/javascript" src="jquery-ui.min.js"></script>
<script type="text/javascript" src="clappr.min.js"></script>
<script type="text/javascript" src="lazyload.min.js"></script>
<script type="text/javascript" src="egg.min.js"></script>
<script type="text/javascript" src="moment.min.js"></script>
<script type="text/javascript" src="clipboard.min.js"></script>
<script type="text/javascript" src="main.js"></script>
<hr style="color: #9ddcff;"/>
<div id="copyright">TANG ZhiXiong, 2017.  Generated by Pandoc on Travis CI. <a  href="https://github.com/district10/blog">Fork Me on GitHub.</a></div>
<div id="comments" class="comments-area">
    <div><span id="showDisqus" title="&#27426;&#36814;&#20132;&#27969;">&#12300;Load Disqus | &#21152;&#36733;&#35780;&#35770;&#12301;</span></div>
    <div id="disqus_thread"></div>
</div>
</body>
</html>
